{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team-Maverick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-590dd7a44c01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtensionArray\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAbstractMethodError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0m_not_implemented_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{} does not implement {}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\function.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m from pandas.util._validators import (validate_args, validate_kwargs,\n\u001b[0m\u001b[0;32m     23\u001b[0m                                      validate_args_and_kwargs)\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUnsupportedFunctionCall\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The folder for the image dataset\n",
    "img_folder=\"./celeba-dataset/img_align_celeba/\"\n",
    "main_folder = './celeba-dataset/'\n",
    "EXAMPLE_PIC = img_folder + '000005.jpg'\n",
    "\n",
    "TRAINING_SAMPLES = 10000\n",
    "VALIDATION_SAMPLES = 2000\n",
    "TEST_SAMPLES = 2000\n",
    "IMG_WIDTH = 178\n",
    "IMG_HEIGHT = 218\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df=pd.read_csv(\"./celeba-dataset/list_attr_celeba.csv\")\n",
    "img_df.set_index('image_id', inplace=True)\n",
    "img_df.replace(to_replace=-1, value=0, inplace=True) #replace -1 by 0\n",
    "img_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(img_df.columns):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot picture and attributes\n",
    "img = load_img(EXAMPLE_PIC)\n",
    "plt.grid(False)\n",
    "plt.imshow(img)\n",
    "img_df.loc[EXAMPLE_PIC.split('/')[-1]][['Smiling','Male','Young','Rosy_Cheeks']] #some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "for file in range (202587,202599):\n",
    "    img_name = mpimg.imread('./celeba-dataset/img_align_celeba/'+str(file)+'.jpg')\n",
    "    plt.imshow(img_name)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Female or Male')\n",
    "sns.countplot(y='Male', data=img_df, color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partition = pd.read_csv(main_folder + 'list_eval_partition.csv')\n",
    "df_partition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 -> TRAINING\n",
    "# 1 -> VALIDATION\n",
    "# 2 -> TEST\n",
    "df_partition['partition'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partition.set_index('image_id', inplace=True)\n",
    "df_par_attr = df_partition.join(img_df['Male'], how='inner')\n",
    "df_par_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reshape_img(fname):\n",
    "    img = load_img(fname)\n",
    "    x = img_to_array(img)/255.\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    return x\n",
    "\n",
    "\n",
    "def generate_df(partition, attr, num_samples):\n",
    "    '''\n",
    "    partition\n",
    "        0 -> train\n",
    "        1 -> validation\n",
    "        2 -> test\n",
    "    \n",
    "    '''\n",
    "    df_ = df_par_attr[(df_par_attr['partition'] == partition)&(df_par_attr[attr] == 0)].sample(int(num_samples/2))\n",
    "    df_ = pd.concat([df_, df_par_attr[(df_par_attr['partition'] == partition)& (df_par_attr[attr] == 1)].sample(int(num_samples/2))])\n",
    "\n",
    "    # for Train and Validation\n",
    "    if partition != 2:\n",
    "        x_ = np.array([load_reshape_img(img_folder + fname) for fname in df_.index])\n",
    "        x_ = x_.reshape(x_.shape[0], 218, 178, 3)\n",
    "        y_ = np_utils.to_categorical(df_[attr],2)\n",
    "    # for Test\n",
    "    else:\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        for index, target in df_.iterrows():\n",
    "            im = cv2.imread(img_folder + index)\n",
    "            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
    "            im = np.expand_dims(im, axis =0)\n",
    "            x_.append(im)\n",
    "            y_.append(target[attr])\n",
    "\n",
    "    return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen =  ImageDataGenerator(\n",
    "  #preprocessing_function=preprocess_input,\n",
    "  rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, \n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "# load one image and reshape\n",
    "img = load_img(img_folder+\"000005.jpg\")\n",
    "x = img_to_array(img)/255.\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# plot 10 augmented images of the loaded iamge\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.suptitle('Data Augmentation', fontsize=28)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow( batch.reshape(218, 178, 3))\n",
    "    \n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_df(0, 'Male', TRAINING_SAMPLES)\n",
    "\n",
    "# Train - Data Preparation - Data Augmentation with generators\n",
    "train_datagen =  ImageDataGenerator(preprocessing_function=preprocess_input, rotation_range=30,\n",
    "  width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,)\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "train_generator = train_datagen.flow( x_train, y_train, batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = generate_df(1, 'Male', VALIDATION_SAMPLES)\n",
    "\n",
    "'''\n",
    "# Validation - Data Preparation - Data Augmentation with generators\n",
    "valid_datagen = ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "valid_datagen.fit(x_valid)\n",
    "\n",
    "validation_generator = valid_datagen.flow(\n",
    "x_valid, y_valid,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3, 3), activation='relu',data_format=\"channels_last\", input_shape=(218,178,3)))\n",
    "print(model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "# Pooling Layer:\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "print(model.output_shape)\n",
    "\n",
    "# Dropout layer to avoid overfitting\n",
    "model.add(Dropout(0.25)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "# more info about loss functions: https://keras.io/losses\n",
    "# more infor about Optimizers: https://keras.io/optimizers\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.25, batch_size=16, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import InceptionV3 Model\n",
    "inc_model = InceptionV3(weights='/Users/akashfarasrami/Desktop/Spring2019/DS/celeba-dataset/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                        include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "print(\"number of layers:\", len(inc_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers\n",
    "x = inc_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the final model \n",
    "model_ = Model(inputs=inc_model.input, outputs=predictions)\n",
    "\n",
    "# Lock initial layers to do not be trained\n",
    "for layer in model_.layers[:52]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model\n",
    "model_.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.best.inc.male.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = model_.fit_generator(train_generator, validation_data = (x_valid, y_valid), steps_per_epoch= TRAINING_SAMPLES/BATCH_SIZE, epochs= NUM_EPOCHS, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss function value through epochs\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(hist.history['loss'], label = 'train')\n",
    "plt.plot(hist.history['val_loss'], label = 'valid')\n",
    "plt.legend()\n",
    "plt.title('Loss Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(hist.history['acc'], label = 'train')\n",
    "plt.plot(hist.history['val_acc'], label = 'valid')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the best model\n",
    "model_.load_weights('weights.best.inc.male.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "x_test, y_test = generate_df(2, 'Male', TEST_SAMPLES)\n",
    "\n",
    "# generate prediction\n",
    "model_predictions = [np.argmax(model_.predict(feature)) for feature in x_test ]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100 * np.sum(np.array(model_predictions)==y_test) / len(model_predictions)\n",
    "print('Model Evaluation')\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "print('f1_score:', f1_score(y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to name the prediction\n",
    "gender_target = {0: 'Female'\n",
    "                , 1: 'Male'}\n",
    "\n",
    "def img_to_display(filename):\n",
    "    # inspired on this kernel:\n",
    "    # https://www.kaggle.com/stassl/displaying-inline-images-in-pandas-dataframe\n",
    "    # credits to stassl :)\n",
    "    \n",
    "    i = Image.open(filename)\n",
    "    i.thumbnail((200, 200), Image.LANCZOS)\n",
    "    \n",
    "    with BytesIO() as buffer:\n",
    "        i.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "    \n",
    "\n",
    "def display_result(filename, prediction, target):\n",
    "    '''\n",
    "    Display the results in HTML\n",
    "    \n",
    "    '''\n",
    "\n",
    "    gender = 'Male'\n",
    "    gender_icon = \"https://i.imgur.com/nxWan2u.png\"\n",
    "        \n",
    "    if prediction[1] <= 0.5:\n",
    "        gender_icon = \"https://i.imgur.com/oAAb8rd.png\"\n",
    "        gender = 'Female'\n",
    "            \n",
    "    display_html = '''\n",
    "    <div style=\"overflow: auto;  border: 2px solid #D8D8D8;\n",
    "        padding: 5px; width: 420px;\" >\n",
    "        <img src=\"data:image/jpeg;base64,{}\" style=\"float: left;\" width=\"200\" height=\"200\">\n",
    "        <div style=\"padding: 10px 0px 0px 20px; overflow: auto;\">\n",
    "            <img src=\"{}\" style=\"float: left;\" width=\"40\" height=\"40\">\n",
    "            <h3 style=\"margin-left: 50px; margin-top: 2px;\">{}</h3>\n",
    "            <p style=\"margin-left: 50px; margin-top: -6px; font-size: 12px\">{} prob.</p>\n",
    "            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Real Target: {}</p>\n",
    "            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Filename: {}</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    '''.format(img_to_display(filename)\n",
    "               , gender_icon\n",
    "               , gender\n",
    "               , \"{0:.2f}%\".format(round(max(prediction)*100,2))\n",
    "               , gender_target[target]\n",
    "               , filename.split('/')[-1]\n",
    "               )\n",
    "\n",
    "    display(HTML(display_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_prediction(filename):\n",
    "    '''\n",
    "    predict the gender\n",
    "    \n",
    "    input:\n",
    "        filename: str of the file name\n",
    "        \n",
    "    return:\n",
    "        array of the prob of the targets.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    im = cv2.imread(filename)\n",
    "    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\n",
    "    im = np.expand_dims(im, axis =0)\n",
    "    \n",
    "    # prediction\n",
    "    result = model_.predict(im)\n",
    "    prediction = np.argmax(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select random images of the test partition\n",
    "df_to_test = df_par_attr[(df_par_attr['partition'] == 2)].sample(8)\n",
    "\n",
    "for index, target in df_to_test.iterrows():\n",
    "    result = gender_prediction(images_folder + index)\n",
    "    \n",
    "    #display result\n",
    "    display_result(images_folder + index, result[0], target['Male'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
