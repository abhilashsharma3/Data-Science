{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>121</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>140</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>135</td>\n",
       "      <td>138</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>134</td>\n",
       "      <td>137</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>136</td>\n",
       "      <td>138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LB     AC   FM     UC     DL   DS   DP  ASTV  MSTV  ALTV ...   Min  Max  \\\n",
       "0  120  0.000  0.0  0.000  0.000  0.0  0.0    73   0.5    43 ...    62  126   \n",
       "1  132  0.006  0.0  0.006  0.003  0.0  0.0    17   2.1     0 ...    68  198   \n",
       "2  133  0.003  0.0  0.008  0.003  0.0  0.0    16   2.1     0 ...    68  198   \n",
       "3  134  0.003  0.0  0.008  0.003  0.0  0.0    16   2.4     0 ...    53  170   \n",
       "4  132  0.007  0.0  0.008  0.000  0.0  0.0    16   2.4     0 ...    53  170   \n",
       "\n",
       "   Nmax  Nzeros  Mode  Mean  Median  Variance  Tendency  NSP  \n",
       "0     2       0   120   137     121        73         1    2  \n",
       "1     6       1   141   136     140        12         0    1  \n",
       "2     5       1   141   135     138        13         0    1  \n",
       "3    11       0   137   134     137        13         1    1  \n",
       "4     9       0   137   136     138        11         1    1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg=pd.read_csv(\"CTG_clean.csv\")\n",
    "ctg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_col=['LB','AC','FM','UC','DL','DS','DP','ASTV','MSTV','ALTV','Width','Min','Max','Nmax','Nzeros','Mode','Mean','Median','Variance','Tendency']\n",
    "X=ctg[feat_col]\n",
    "y=ctg['NSP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 20) (1700,) (426, 20) (426,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.35222005, -0.8223883 , -0.20320955, ..., -1.18164215,\n",
       "         1.87056871,  1.11298001],\n",
       "       [-0.1325256 ,  0.73013282, -0.20320955, ...,  0.13203796,\n",
       "        -0.23499819, -0.52452553],\n",
       "       [-0.03088439, -0.04612774, -0.20320955, ..., -0.00624416,\n",
       "        -0.2004807 , -0.52452553],\n",
       "       ...,\n",
       "       [ 0.68060404, -0.56363478, -0.20320955, ...,  0.96173066,\n",
       "        -0.51113811,  1.11298001],\n",
       "       [ 0.68060404, -0.56363478, -0.20320955, ...,  0.8925896 ,\n",
       "        -0.51113811,  1.11298001],\n",
       "       [ 0.88388645, -0.30488126, -0.16034157, ...,  0.47774325,\n",
       "        -0.61469058, -0.52452553]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.83344705\n",
      "Iteration 2, loss = 0.68572254\n",
      "Iteration 3, loss = 0.65782467\n",
      "Iteration 4, loss = 0.61695305\n",
      "Iteration 5, loss = 0.58118768\n",
      "Iteration 6, loss = 0.55012583\n",
      "Iteration 7, loss = 0.54948157\n",
      "Iteration 8, loss = 0.53677776\n",
      "Iteration 9, loss = 0.52172552\n",
      "Iteration 10, loss = 0.50637962\n",
      "Iteration 11, loss = 0.53062109\n",
      "Iteration 12, loss = 0.51875584\n",
      "Iteration 13, loss = 0.49270931\n",
      "Iteration 14, loss = 0.54355151\n",
      "Iteration 15, loss = 0.51495648\n",
      "Iteration 16, loss = 0.48508664\n",
      "Iteration 17, loss = 0.48778305\n",
      "Iteration 18, loss = 0.48336530\n",
      "Iteration 19, loss = 0.44797425\n",
      "Iteration 20, loss = 0.45984659\n",
      "Iteration 21, loss = 0.43765372\n",
      "Iteration 22, loss = 0.46350697\n",
      "Iteration 23, loss = 0.45566998\n",
      "Iteration 24, loss = 0.44087749\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79578869\n",
      "Iteration 2, loss = 0.60887554\n",
      "Iteration 3, loss = 0.57117236\n",
      "Iteration 4, loss = 0.50970871\n",
      "Iteration 5, loss = 0.47435884\n",
      "Iteration 6, loss = 0.46444541\n",
      "Iteration 7, loss = 0.46893613\n",
      "Iteration 8, loss = 0.45894796\n",
      "Iteration 9, loss = 0.45892206\n",
      "Iteration 10, loss = 0.44683535\n",
      "Iteration 11, loss = 0.45605377\n",
      "Iteration 12, loss = 0.45004009\n",
      "Iteration 13, loss = 0.42699798\n",
      "Iteration 14, loss = 0.45996200\n",
      "Iteration 15, loss = 0.43614311\n",
      "Iteration 16, loss = 0.42788575\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79189609\n",
      "Iteration 2, loss = 0.64667106\n",
      "Iteration 3, loss = 0.57645452\n",
      "Iteration 4, loss = 0.52358610\n",
      "Iteration 5, loss = 0.48908649\n",
      "Iteration 6, loss = 0.48961339\n",
      "Iteration 7, loss = 0.49049273\n",
      "Iteration 8, loss = 0.49021120\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79635611\n",
      "Iteration 2, loss = 0.65570719\n",
      "Iteration 3, loss = 0.63545174\n",
      "Iteration 4, loss = 0.60371229\n",
      "Iteration 5, loss = 0.56644450\n",
      "Iteration 6, loss = 0.54909053\n",
      "Iteration 7, loss = 0.51307937\n",
      "Iteration 8, loss = 0.50896820\n",
      "Iteration 9, loss = 0.50544856\n",
      "Iteration 10, loss = 0.49888896\n",
      "Iteration 11, loss = 0.48223325\n",
      "Iteration 12, loss = 0.47528459\n",
      "Iteration 13, loss = 0.47910060\n",
      "Iteration 14, loss = 0.50509432\n",
      "Iteration 15, loss = 0.50905194\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78474833\n",
      "Iteration 2, loss = 0.63924615\n",
      "Iteration 3, loss = 0.59084890\n",
      "Iteration 4, loss = 0.52271605\n",
      "Iteration 5, loss = 0.47067228\n",
      "Iteration 6, loss = 0.45816026\n",
      "Iteration 7, loss = 0.46113840\n",
      "Iteration 8, loss = 0.47256985\n",
      "Iteration 9, loss = 0.44149799\n",
      "Iteration 10, loss = 0.44282171\n",
      "Iteration 11, loss = 0.44891117\n",
      "Iteration 12, loss = 0.46300487\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79291401\n",
      "Iteration 2, loss = 0.63009377\n",
      "Iteration 3, loss = 0.56957161\n",
      "Iteration 4, loss = 0.51274304\n",
      "Iteration 5, loss = 0.46530844\n",
      "Iteration 6, loss = 0.44056412\n",
      "Iteration 7, loss = 0.44924881\n",
      "Iteration 8, loss = 0.44910646\n",
      "Iteration 9, loss = 0.44088187\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78238187\n",
      "Iteration 2, loss = 0.61969925\n",
      "Iteration 3, loss = 0.54478572\n",
      "Iteration 4, loss = 0.50996994\n",
      "Iteration 5, loss = 0.48764395\n",
      "Iteration 6, loss = 0.50252081\n",
      "Iteration 7, loss = 0.50079104\n",
      "Iteration 8, loss = 0.49105957\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79884197\n",
      "Iteration 2, loss = 0.68294144\n",
      "Iteration 3, loss = 0.66219167\n",
      "Iteration 4, loss = 0.62167930\n",
      "Iteration 5, loss = 0.57809923\n",
      "Iteration 6, loss = 0.54934738\n",
      "Iteration 7, loss = 0.52986978\n",
      "Iteration 8, loss = 0.49754849\n",
      "Iteration 9, loss = 0.48857827\n",
      "Iteration 10, loss = 0.51020520\n",
      "Iteration 11, loss = 0.48696456\n",
      "Iteration 12, loss = 0.46123751\n",
      "Iteration 13, loss = 0.47189608\n",
      "Iteration 14, loss = 0.47412479\n",
      "Iteration 15, loss = 0.45816663\n",
      "Iteration 16, loss = 0.46458091\n",
      "Iteration 17, loss = 0.48446100\n",
      "Iteration 18, loss = 0.49002834\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80023852\n",
      "Iteration 2, loss = 0.65570334\n",
      "Iteration 3, loss = 0.60639315\n",
      "Iteration 4, loss = 0.58048252\n",
      "Iteration 5, loss = 0.52755287\n",
      "Iteration 6, loss = 0.51674957\n",
      "Iteration 7, loss = 0.55742349\n",
      "Iteration 8, loss = 0.52944531\n",
      "Iteration 9, loss = 0.48853887\n",
      "Iteration 10, loss = 0.47585560\n",
      "Iteration 11, loss = 0.46509738\n",
      "Iteration 12, loss = 0.46222651\n",
      "Iteration 13, loss = 0.46235517\n",
      "Iteration 14, loss = 0.50320960\n",
      "Iteration 15, loss = 0.47141186\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79689216\n",
      "Iteration 2, loss = 0.63726505\n",
      "Iteration 3, loss = 0.58123711\n",
      "Iteration 4, loss = 0.53754849\n",
      "Iteration 5, loss = 0.50548201\n",
      "Iteration 6, loss = 0.51277036\n",
      "Iteration 7, loss = 0.47981817\n",
      "Iteration 8, loss = 0.47894382\n",
      "Iteration 9, loss = 0.48244370\n",
      "Iteration 10, loss = 0.48456609\n",
      "Iteration 11, loss = 0.47593736\n",
      "Iteration 12, loss = 0.46968264\n",
      "Iteration 13, loss = 0.47754525\n",
      "Iteration 14, loss = 0.47292959\n",
      "Iteration 15, loss = 0.46348803\n",
      "Iteration 16, loss = 0.46139639\n",
      "Iteration 17, loss = 0.46507690\n",
      "Iteration 18, loss = 0.45443635\n",
      "Iteration 19, loss = 0.48041575\n",
      "Iteration 20, loss = 0.45525179\n",
      "Iteration 21, loss = 0.45195142\n",
      "Iteration 22, loss = 0.44992080\n",
      "Iteration 23, loss = 0.46253721\n",
      "Iteration 24, loss = 0.44622259\n",
      "Iteration 25, loss = 0.45214176\n",
      "Iteration 26, loss = 0.45621262\n",
      "Iteration 27, loss = 0.45981044\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80314047\n",
      "Iteration 2, loss = 0.65677365\n",
      "Iteration 3, loss = 0.59160250\n",
      "Iteration 4, loss = 0.51677267\n",
      "Iteration 5, loss = 0.46682285\n",
      "Iteration 6, loss = 0.44872970\n",
      "Iteration 7, loss = 0.42877418\n",
      "Iteration 8, loss = 0.42256066\n",
      "Iteration 9, loss = 0.41689512\n",
      "Iteration 10, loss = 0.41798257\n",
      "Iteration 11, loss = 0.44189220\n",
      "Iteration 12, loss = 0.43268321\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[0.81775701 0.81775701 0.8364486  0.79439252 0.81775701 0.83962264\n",
      " 0.8056872  0.80094787 0.92417062 0.63507109]\n"
     ]
    }
   ],
   "source": [
    "ANN=MLPClassifier(hidden_layer_sizes=(30,), activation= 'logistic', \n",
    "                    solver='adam', alpha=1, learning_rate_init=0.02, random_state=1, verbose=True)\n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "acc_list = cross_val_score(ANN, X, y, cv=10, scoring='accuracy')\n",
    "print(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_cv=acc_list.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8089611568293329\n"
     ]
    }
   ],
   "source": [
    "print(acc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_ann=ANN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 2 1 1 1 1 1 3 1 2 2 2 3 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 3 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 3 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 2 1 1 1 1 1 1 1 1\n",
      " 2 1 1 2 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 3 1 1 2 3\n",
      " 1 1 1 1 1 1 2 1 1 1 3 3 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 3 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1\n",
      " 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 3 1 1 1 1 2 1 1 2 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pre_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=accuracy_score(y_test, y_pre_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8544600938967136\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.98829123\n",
      "Iteration 2, loss = 0.74660645\n",
      "Iteration 3, loss = 0.68379657\n",
      "Iteration 4, loss = 0.68555822\n",
      "Iteration 5, loss = 0.68057512\n",
      "Iteration 6, loss = 0.68062905\n",
      "Iteration 7, loss = 0.68031791\n",
      "Iteration 8, loss = 0.67950045\n",
      "Iteration 9, loss = 0.67916092\n",
      "Iteration 10, loss = 0.67971577\n",
      "Iteration 11, loss = 0.67887854\n",
      "Iteration 12, loss = 0.67861214\n",
      "Iteration 13, loss = 0.67846756\n",
      "Iteration 14, loss = 0.67846102\n",
      "Iteration 15, loss = 0.67818953\n",
      "Iteration 16, loss = 0.67828580\n",
      "Iteration 17, loss = 0.67815781\n",
      "Iteration 18, loss = 0.67854226\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98769346\n",
      "Iteration 2, loss = 0.73677572\n",
      "Iteration 3, loss = 0.68511416\n",
      "Iteration 4, loss = 0.68570428\n",
      "Iteration 5, loss = 0.68000894\n",
      "Iteration 6, loss = 0.74009660\n",
      "Iteration 7, loss = 0.70729808\n",
      "Iteration 8, loss = 0.68242401\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98968022\n",
      "Iteration 2, loss = 0.71755801\n",
      "Iteration 3, loss = 0.69024190\n",
      "Iteration 4, loss = 0.68476530\n",
      "Iteration 5, loss = 0.68113395\n",
      "Iteration 6, loss = 0.67967069\n",
      "Iteration 7, loss = 0.71004108\n",
      "Iteration 8, loss = 0.68909740\n",
      "Iteration 9, loss = 0.68555719\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.99044456\n",
      "Iteration 2, loss = 0.71468885\n",
      "Iteration 3, loss = 0.68082600\n",
      "Iteration 4, loss = 0.64025642\n",
      "Iteration 5, loss = 0.59851329\n",
      "Iteration 6, loss = 0.57394595\n",
      "Iteration 7, loss = 0.56311123\n",
      "Iteration 8, loss = 0.55666580\n",
      "Iteration 9, loss = 0.54010274\n",
      "Iteration 10, loss = 0.57278266\n",
      "Iteration 11, loss = 0.52449223\n",
      "Iteration 12, loss = 0.51522667\n",
      "Iteration 13, loss = 0.51767323\n",
      "Iteration 14, loss = 0.51643552\n",
      "Iteration 15, loss = 0.52223029\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.99425968\n",
      "Iteration 2, loss = 0.73822473\n",
      "Iteration 3, loss = 0.68624153\n",
      "Iteration 4, loss = 0.68567608\n",
      "Iteration 5, loss = 0.68074395\n",
      "Iteration 6, loss = 0.68024324\n",
      "Iteration 7, loss = 0.68169450\n",
      "Iteration 8, loss = 0.68023304\n",
      "Iteration 9, loss = 0.67949221\n",
      "Iteration 10, loss = 0.67976387\n",
      "Iteration 11, loss = 0.67965081\n",
      "Iteration 12, loss = 0.67938260\n",
      "Iteration 13, loss = 0.67903247\n",
      "Iteration 14, loss = 0.67882561\n",
      "Iteration 15, loss = 0.67893613\n",
      "Iteration 16, loss = 0.67900942\n",
      "Iteration 17, loss = 0.67862093\n",
      "Iteration 18, loss = 0.67881398\n",
      "Iteration 19, loss = 0.67835581\n",
      "Iteration 20, loss = 0.67831406\n",
      "Iteration 21, loss = 0.67929358\n",
      "Iteration 22, loss = 0.67844199\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98321252\n",
      "Iteration 2, loss = 0.71654370\n",
      "Iteration 3, loss = 0.68924918\n",
      "Iteration 4, loss = 0.66491112\n",
      "Iteration 5, loss = 0.62273958\n",
      "Iteration 6, loss = 0.59732757\n",
      "Iteration 7, loss = 0.56506226\n",
      "Iteration 8, loss = 0.53536607\n",
      "Iteration 9, loss = 0.53604624\n",
      "Iteration 10, loss = 0.54223812\n",
      "Iteration 11, loss = 0.51780852\n",
      "Iteration 12, loss = 0.51681039\n",
      "Iteration 13, loss = 0.51295767\n",
      "Iteration 14, loss = 0.51319111\n",
      "Iteration 15, loss = 0.53873190\n",
      "Iteration 16, loss = 0.54325561\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.99218158\n",
      "Iteration 2, loss = 0.72408168\n",
      "Iteration 3, loss = 0.69271846\n",
      "Iteration 4, loss = 0.68302206\n",
      "Iteration 5, loss = 0.68376405\n",
      "Iteration 6, loss = 0.68150478\n",
      "Iteration 7, loss = 0.68114137\n",
      "Iteration 8, loss = 0.68443951\n",
      "Iteration 9, loss = 0.68337412\n",
      "Iteration 10, loss = 0.68128219\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98661169\n",
      "Iteration 2, loss = 0.72474832\n",
      "Iteration 3, loss = 0.69023792\n",
      "Iteration 4, loss = 0.68366471\n",
      "Iteration 5, loss = 0.68311630\n",
      "Iteration 6, loss = 0.68150497\n",
      "Iteration 7, loss = 0.68129090\n",
      "Iteration 8, loss = 0.68096871\n",
      "Iteration 9, loss = 0.72481546\n",
      "Iteration 10, loss = 0.68665290\n",
      "Iteration 11, loss = 0.68825468\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98433681\n",
      "Iteration 2, loss = 0.72668419\n",
      "Iteration 3, loss = 0.69160811\n",
      "Iteration 4, loss = 0.68472817\n",
      "Iteration 5, loss = 0.68291504\n",
      "Iteration 6, loss = 0.68197562\n",
      "Iteration 7, loss = 0.68182442\n",
      "Iteration 8, loss = 0.68190691\n",
      "Iteration 9, loss = 0.68158680\n",
      "Iteration 10, loss = 0.68099233\n",
      "Iteration 11, loss = 0.70635048\n",
      "Iteration 12, loss = 0.69324207\n",
      "Iteration 13, loss = 0.68654219\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98654298\n",
      "Iteration 2, loss = 0.72235263\n",
      "Iteration 3, loss = 0.69439038\n",
      "Iteration 4, loss = 0.68328450\n",
      "Iteration 5, loss = 0.68446922\n",
      "Iteration 6, loss = 0.68119320\n",
      "Iteration 7, loss = 0.68191242\n",
      "Iteration 8, loss = 0.68071105\n",
      "Iteration 9, loss = 0.68089419\n",
      "Iteration 10, loss = 0.68157602\n",
      "Iteration 11, loss = 0.68188748\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90960451\n",
      "Iteration 2, loss = 0.67241286\n",
      "Iteration 3, loss = 0.63882689\n",
      "Iteration 4, loss = 0.61928855\n",
      "Iteration 5, loss = 0.60206924\n",
      "Iteration 6, loss = 0.59059275\n",
      "Iteration 7, loss = 0.57010799\n",
      "Iteration 8, loss = 0.55555970\n",
      "Iteration 9, loss = 0.55259193\n",
      "Iteration 10, loss = 0.54562580\n",
      "Iteration 11, loss = 0.53687220\n",
      "Iteration 12, loss = 0.53191282\n",
      "Iteration 13, loss = 0.53170203\n",
      "Iteration 14, loss = 0.53550297\n",
      "Iteration 15, loss = 0.53809019\n",
      "Iteration 16, loss = 0.52303038\n",
      "Iteration 17, loss = 0.51874157\n",
      "Iteration 18, loss = 0.51787264\n",
      "Iteration 19, loss = 0.52275398\n",
      "Iteration 20, loss = 0.55879107\n",
      "Iteration 21, loss = 0.52600254\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91701582\n",
      "Iteration 2, loss = 0.68942197\n",
      "Iteration 3, loss = 0.66515944\n",
      "Iteration 4, loss = 0.63006989\n",
      "Iteration 5, loss = 0.61018440\n",
      "Iteration 6, loss = 0.59932540\n",
      "Iteration 7, loss = 0.60625268\n",
      "Iteration 8, loss = 0.59072420\n",
      "Iteration 9, loss = 0.59992022\n",
      "Iteration 10, loss = 0.56486809\n",
      "Iteration 11, loss = 0.55062686\n",
      "Iteration 12, loss = 0.54142016\n",
      "Iteration 13, loss = 0.54141684\n",
      "Iteration 14, loss = 0.53454703\n",
      "Iteration 15, loss = 0.52756223\n",
      "Iteration 16, loss = 0.52388513\n",
      "Iteration 17, loss = 0.52506116\n",
      "Iteration 18, loss = 0.53466624\n",
      "Iteration 19, loss = 0.51846117\n",
      "Iteration 20, loss = 0.53657093\n",
      "Iteration 21, loss = 0.52423782\n",
      "Iteration 22, loss = 0.51879188\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91309364\n",
      "Iteration 2, loss = 0.64540546\n",
      "Iteration 3, loss = 0.64760085\n",
      "Iteration 4, loss = 0.61725118\n",
      "Iteration 5, loss = 0.59983437\n",
      "Iteration 6, loss = 0.58314002\n",
      "Iteration 7, loss = 0.57035185\n",
      "Iteration 8, loss = 0.56062906\n",
      "Iteration 9, loss = 0.54886091\n",
      "Iteration 10, loss = 0.54096300\n",
      "Iteration 11, loss = 0.54249352\n",
      "Iteration 12, loss = 0.53782133\n",
      "Iteration 13, loss = 0.52806496\n",
      "Iteration 14, loss = 0.52792457\n",
      "Iteration 15, loss = 0.52086711\n",
      "Iteration 16, loss = 0.52127511\n",
      "Iteration 17, loss = 0.53865288\n",
      "Iteration 18, loss = 0.55144614\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91810184\n",
      "Iteration 2, loss = 0.66635759\n",
      "Iteration 3, loss = 0.64139500\n",
      "Iteration 4, loss = 0.59854451\n",
      "Iteration 5, loss = 0.57064036\n",
      "Iteration 6, loss = 0.56678241\n",
      "Iteration 7, loss = 0.54115408\n",
      "Iteration 8, loss = 0.52843883\n",
      "Iteration 9, loss = 0.52748620\n",
      "Iteration 10, loss = 0.51522908\n",
      "Iteration 11, loss = 0.49024499\n",
      "Iteration 12, loss = 0.48481764\n",
      "Iteration 13, loss = 0.49287470\n",
      "Iteration 14, loss = 0.49708736\n",
      "Iteration 15, loss = 0.48034310\n",
      "Iteration 16, loss = 0.49757378\n",
      "Iteration 17, loss = 0.49022042\n",
      "Iteration 18, loss = 0.47672441\n",
      "Iteration 19, loss = 0.46588287\n",
      "Iteration 20, loss = 0.48221898\n",
      "Iteration 21, loss = 0.46627612\n",
      "Iteration 22, loss = 0.47298095\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91316856\n",
      "Iteration 2, loss = 0.67038298\n",
      "Iteration 3, loss = 0.63429694\n",
      "Iteration 4, loss = 0.61311940\n",
      "Iteration 5, loss = 0.57832501\n",
      "Iteration 6, loss = 0.55570768\n",
      "Iteration 7, loss = 0.52972168\n",
      "Iteration 8, loss = 0.52933287\n",
      "Iteration 9, loss = 0.51631193\n",
      "Iteration 10, loss = 0.49605703\n",
      "Iteration 11, loss = 0.49748983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.51726806\n",
      "Iteration 13, loss = 0.50086022\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89832367\n",
      "Iteration 2, loss = 0.65072130\n",
      "Iteration 3, loss = 0.62809839\n",
      "Iteration 4, loss = 0.60957025\n",
      "Iteration 5, loss = 0.60845689\n",
      "Iteration 6, loss = 0.57131364\n",
      "Iteration 7, loss = 0.55314518\n",
      "Iteration 8, loss = 0.53487633\n",
      "Iteration 9, loss = 0.52114424\n",
      "Iteration 10, loss = 0.52618744\n",
      "Iteration 11, loss = 0.51995168\n",
      "Iteration 12, loss = 0.50141529\n",
      "Iteration 13, loss = 0.53262945\n",
      "Iteration 14, loss = 0.52490566\n",
      "Iteration 15, loss = 0.50809055\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91057870\n",
      "Iteration 2, loss = 0.65057260\n",
      "Iteration 3, loss = 0.64604306\n",
      "Iteration 4, loss = 0.60811741\n",
      "Iteration 5, loss = 0.58863760\n",
      "Iteration 6, loss = 0.58839688\n",
      "Iteration 7, loss = 0.57050680\n",
      "Iteration 8, loss = 0.55698160\n",
      "Iteration 9, loss = 0.54456518\n",
      "Iteration 10, loss = 0.53856905\n",
      "Iteration 11, loss = 0.53589060\n",
      "Iteration 12, loss = 0.53143916\n",
      "Iteration 13, loss = 0.54463594\n",
      "Iteration 14, loss = 0.54701840\n",
      "Iteration 15, loss = 0.54596081\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90481771\n",
      "Iteration 2, loss = 0.64769979\n",
      "Iteration 3, loss = 0.64247778\n",
      "Iteration 4, loss = 0.59885335\n",
      "Iteration 5, loss = 0.57506057\n",
      "Iteration 6, loss = 0.53580420\n",
      "Iteration 7, loss = 0.52758478\n",
      "Iteration 8, loss = 0.52803484\n",
      "Iteration 9, loss = 0.50388118\n",
      "Iteration 10, loss = 0.51834919\n",
      "Iteration 11, loss = 0.47946839\n",
      "Iteration 12, loss = 0.48095326\n",
      "Iteration 13, loss = 0.48404122\n",
      "Iteration 14, loss = 0.48027680\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90244717\n",
      "Iteration 2, loss = 0.65748372\n",
      "Iteration 3, loss = 0.63327695\n",
      "Iteration 4, loss = 0.61017529\n",
      "Iteration 5, loss = 0.60010462\n",
      "Iteration 6, loss = 0.58779808\n",
      "Iteration 7, loss = 0.57456745\n",
      "Iteration 8, loss = 0.55911381\n",
      "Iteration 9, loss = 0.55533398\n",
      "Iteration 10, loss = 0.54626005\n",
      "Iteration 11, loss = 0.54843236\n",
      "Iteration 12, loss = 0.54856094\n",
      "Iteration 13, loss = 0.53674874\n",
      "Iteration 14, loss = 0.52895534\n",
      "Iteration 15, loss = 0.52735245\n",
      "Iteration 16, loss = 0.52611435\n",
      "Iteration 17, loss = 0.52151904\n",
      "Iteration 18, loss = 0.52259475\n",
      "Iteration 19, loss = 0.53108924\n",
      "Iteration 20, loss = 0.51523648\n",
      "Iteration 21, loss = 0.51539866\n",
      "Iteration 22, loss = 0.51451747\n",
      "Iteration 23, loss = 0.49466202\n",
      "Iteration 24, loss = 0.51753901\n",
      "Iteration 25, loss = 0.49936313\n",
      "Iteration 26, loss = 0.50025277\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90852564\n",
      "Iteration 2, loss = 0.69046900\n",
      "Iteration 3, loss = 0.69223228\n",
      "Iteration 4, loss = 0.65860518\n",
      "Iteration 5, loss = 0.62923928\n",
      "Iteration 6, loss = 0.61408250\n",
      "Iteration 7, loss = 0.59487229\n",
      "Iteration 8, loss = 0.58657678\n",
      "Iteration 9, loss = 0.57711683\n",
      "Iteration 10, loss = 0.55433430\n",
      "Iteration 11, loss = 0.54018347\n",
      "Iteration 12, loss = 0.51924025\n",
      "Iteration 13, loss = 0.51590495\n",
      "Iteration 14, loss = 0.50597192\n",
      "Iteration 15, loss = 0.50609487\n",
      "Iteration 16, loss = 0.50922151\n",
      "Iteration 17, loss = 0.51804541\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80863687\n",
      "Iteration 2, loss = 0.68597987\n",
      "Iteration 3, loss = 0.64838141\n",
      "Iteration 4, loss = 0.60826996\n",
      "Iteration 5, loss = 0.58221789\n",
      "Iteration 6, loss = 0.54769174\n",
      "Iteration 7, loss = 0.54424188\n",
      "Iteration 8, loss = 0.56136993\n",
      "Iteration 9, loss = 0.54489276\n",
      "Iteration 10, loss = 0.51455397\n",
      "Iteration 11, loss = 0.50495133\n",
      "Iteration 12, loss = 0.48868072\n",
      "Iteration 13, loss = 0.52086944\n",
      "Iteration 14, loss = 0.47871452\n",
      "Iteration 15, loss = 0.47199301\n",
      "Iteration 16, loss = 0.49449401\n",
      "Iteration 17, loss = 0.47574984\n",
      "Iteration 18, loss = 0.46191041\n",
      "Iteration 19, loss = 0.46175119\n",
      "Iteration 20, loss = 0.45947404\n",
      "Iteration 21, loss = 0.46806246\n",
      "Iteration 22, loss = 0.52044080\n",
      "Iteration 23, loss = 0.52762420\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80626023\n",
      "Iteration 2, loss = 0.69903228\n",
      "Iteration 3, loss = 0.69148640\n",
      "Iteration 4, loss = 0.68839166\n",
      "Iteration 5, loss = 0.68478000\n",
      "Iteration 6, loss = 0.67489311\n",
      "Iteration 7, loss = 0.66850918\n",
      "Iteration 8, loss = 0.66573572\n",
      "Iteration 9, loss = 0.65625457\n",
      "Iteration 10, loss = 0.64570079\n",
      "Iteration 11, loss = 0.63210493\n",
      "Iteration 12, loss = 0.61175870\n",
      "Iteration 13, loss = 0.59055895\n",
      "Iteration 14, loss = 0.57685504\n",
      "Iteration 15, loss = 0.56478371\n",
      "Iteration 16, loss = 0.55836898\n",
      "Iteration 17, loss = 0.54569449\n",
      "Iteration 18, loss = 0.52961334\n",
      "Iteration 19, loss = 0.52190663\n",
      "Iteration 20, loss = 0.51185004\n",
      "Iteration 21, loss = 0.53306726\n",
      "Iteration 22, loss = 0.55993296\n",
      "Iteration 23, loss = 0.53180756\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79846715\n",
      "Iteration 2, loss = 0.69593457\n",
      "Iteration 3, loss = 0.66257866\n",
      "Iteration 4, loss = 0.63599412\n",
      "Iteration 5, loss = 0.59286967\n",
      "Iteration 6, loss = 0.56332703\n",
      "Iteration 7, loss = 0.53698123\n",
      "Iteration 8, loss = 0.51469202\n",
      "Iteration 9, loss = 0.53052600\n",
      "Iteration 10, loss = 0.49686350\n",
      "Iteration 11, loss = 0.47457729\n",
      "Iteration 12, loss = 0.46677476\n",
      "Iteration 13, loss = 0.45086247\n",
      "Iteration 14, loss = 0.45967422\n",
      "Iteration 15, loss = 0.45118699\n",
      "Iteration 16, loss = 0.43894956\n",
      "Iteration 17, loss = 0.44314261\n",
      "Iteration 18, loss = 0.44164918\n",
      "Iteration 19, loss = 0.44453560\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79756513\n",
      "Iteration 2, loss = 0.68891277\n",
      "Iteration 3, loss = 0.67502933\n",
      "Iteration 4, loss = 0.65700775\n",
      "Iteration 5, loss = 0.62279400\n",
      "Iteration 6, loss = 0.58906440\n",
      "Iteration 7, loss = 0.57103905\n",
      "Iteration 8, loss = 0.55579799\n",
      "Iteration 9, loss = 0.55570398\n",
      "Iteration 10, loss = 0.53784568\n",
      "Iteration 11, loss = 0.52061802\n",
      "Iteration 12, loss = 0.51061047\n",
      "Iteration 13, loss = 0.51449218\n",
      "Iteration 14, loss = 0.54564772\n",
      "Iteration 15, loss = 0.50803920\n",
      "Iteration 16, loss = 0.50387464\n",
      "Iteration 17, loss = 0.49035190\n",
      "Iteration 18, loss = 0.47788819\n",
      "Iteration 19, loss = 0.48199439\n",
      "Iteration 20, loss = 0.47066637\n",
      "Iteration 21, loss = 0.47704331\n",
      "Iteration 22, loss = 0.47851465\n",
      "Iteration 23, loss = 0.52980702\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79046679\n",
      "Iteration 2, loss = 0.68604459\n",
      "Iteration 3, loss = 0.67633476\n",
      "Iteration 4, loss = 0.65056167\n",
      "Iteration 5, loss = 0.61282966\n",
      "Iteration 6, loss = 0.57944539\n",
      "Iteration 7, loss = 0.55132465\n",
      "Iteration 8, loss = 0.53404367\n",
      "Iteration 9, loss = 0.51135374\n",
      "Iteration 10, loss = 0.50686892\n",
      "Iteration 11, loss = 0.49778462\n",
      "Iteration 12, loss = 0.52772294\n",
      "Iteration 13, loss = 0.52651752\n",
      "Iteration 14, loss = 0.50276786\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79239998\n",
      "Iteration 2, loss = 0.68377281\n",
      "Iteration 3, loss = 0.67316219\n",
      "Iteration 4, loss = 0.66429322\n",
      "Iteration 5, loss = 0.64156712\n",
      "Iteration 6, loss = 0.59890021\n",
      "Iteration 7, loss = 0.56522492\n",
      "Iteration 8, loss = 0.54386708\n",
      "Iteration 9, loss = 0.53569426\n",
      "Iteration 10, loss = 0.52176808\n",
      "Iteration 11, loss = 0.50337182\n",
      "Iteration 12, loss = 0.51016463\n",
      "Iteration 13, loss = 0.52021574\n",
      "Iteration 14, loss = 0.49923694\n",
      "Iteration 15, loss = 0.51991944\n",
      "Iteration 16, loss = 0.50279338\n",
      "Iteration 17, loss = 0.50794222\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79736556\n",
      "Iteration 2, loss = 0.68271966\n",
      "Iteration 3, loss = 0.63725970\n",
      "Iteration 4, loss = 0.59236765\n",
      "Iteration 5, loss = 0.56404376\n",
      "Iteration 6, loss = 0.54942925\n",
      "Iteration 7, loss = 0.51945268\n",
      "Iteration 8, loss = 0.50140571\n",
      "Iteration 9, loss = 0.49198266\n",
      "Iteration 10, loss = 0.47917780\n",
      "Iteration 11, loss = 0.47499185\n",
      "Iteration 12, loss = 0.47896106\n",
      "Iteration 13, loss = 0.47929732\n",
      "Iteration 14, loss = 0.49273337\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79945096\n",
      "Iteration 2, loss = 0.68166739\n",
      "Iteration 3, loss = 0.63778560\n",
      "Iteration 4, loss = 0.61827745\n",
      "Iteration 5, loss = 0.58971115\n",
      "Iteration 6, loss = 0.57023511\n",
      "Iteration 7, loss = 0.56545767\n",
      "Iteration 8, loss = 0.55286605\n",
      "Iteration 9, loss = 0.52440147\n",
      "Iteration 10, loss = 0.53246175\n",
      "Iteration 11, loss = 0.49883513\n",
      "Iteration 12, loss = 0.50815360\n",
      "Iteration 13, loss = 0.50725046\n",
      "Iteration 14, loss = 0.49595123\n",
      "Iteration 15, loss = 0.49126401\n",
      "Iteration 16, loss = 0.47996133\n",
      "Iteration 17, loss = 0.49729551\n",
      "Iteration 18, loss = 0.48229427\n",
      "Iteration 19, loss = 0.47340751\n",
      "Iteration 20, loss = 0.48554143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, loss = 0.49750255\n",
      "Iteration 22, loss = 0.48278767\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80421944\n",
      "Iteration 2, loss = 0.69556319\n",
      "Iteration 3, loss = 0.63508689\n",
      "Iteration 4, loss = 0.60136980\n",
      "Iteration 5, loss = 0.56705510\n",
      "Iteration 6, loss = 0.56026065\n",
      "Iteration 7, loss = 0.54521050\n",
      "Iteration 8, loss = 0.51653276\n",
      "Iteration 9, loss = 0.53099250\n",
      "Iteration 10, loss = 0.53215730\n",
      "Iteration 11, loss = 0.57201324\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81396072\n",
      "Iteration 2, loss = 0.69835402\n",
      "Iteration 3, loss = 0.65881966\n",
      "Iteration 4, loss = 0.63602027\n",
      "Iteration 5, loss = 0.62415120\n",
      "Iteration 6, loss = 0.59683287\n",
      "Iteration 7, loss = 0.58884135\n",
      "Iteration 8, loss = 0.55863633\n",
      "Iteration 9, loss = 0.53738196\n",
      "Iteration 10, loss = 0.52868583\n",
      "Iteration 11, loss = 0.52292298\n",
      "Iteration 12, loss = 0.51330949\n",
      "Iteration 13, loss = 0.50593132\n",
      "Iteration 14, loss = 0.51054332\n",
      "Iteration 15, loss = 0.50225392\n",
      "Iteration 16, loss = 0.49876666\n",
      "Iteration 17, loss = 0.51652175\n",
      "Iteration 18, loss = 0.50747956\n",
      "Iteration 19, loss = 0.50343169\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73455284\n",
      "Iteration 2, loss = 0.66848311\n",
      "Iteration 3, loss = 0.63334089\n",
      "Iteration 4, loss = 0.59041755\n",
      "Iteration 5, loss = 0.53279249\n",
      "Iteration 6, loss = 0.50377341\n",
      "Iteration 7, loss = 0.47749173\n",
      "Iteration 8, loss = 0.45758769\n",
      "Iteration 9, loss = 0.47487770\n",
      "Iteration 10, loss = 0.46827117\n",
      "Iteration 11, loss = 0.48485302\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72683716\n",
      "Iteration 2, loss = 0.65105470\n",
      "Iteration 3, loss = 0.61629569\n",
      "Iteration 4, loss = 0.58718263\n",
      "Iteration 5, loss = 0.58146797\n",
      "Iteration 6, loss = 0.53095571\n",
      "Iteration 7, loss = 0.52172171\n",
      "Iteration 8, loss = 0.51467180\n",
      "Iteration 9, loss = 0.49693859\n",
      "Iteration 10, loss = 0.49149021\n",
      "Iteration 11, loss = 0.48392859\n",
      "Iteration 12, loss = 0.47170741\n",
      "Iteration 13, loss = 0.50525220\n",
      "Iteration 14, loss = 0.51286824\n",
      "Iteration 15, loss = 0.52675061\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73355503\n",
      "Iteration 2, loss = 0.66432900\n",
      "Iteration 3, loss = 0.62423785\n",
      "Iteration 4, loss = 0.59707194\n",
      "Iteration 5, loss = 0.58489024\n",
      "Iteration 6, loss = 0.54593775\n",
      "Iteration 7, loss = 0.51370759\n",
      "Iteration 8, loss = 0.51649678\n",
      "Iteration 9, loss = 0.52170524\n",
      "Iteration 10, loss = 0.47003355\n",
      "Iteration 11, loss = 0.48100532\n",
      "Iteration 12, loss = 0.47279748\n",
      "Iteration 13, loss = 0.47514467\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72780817\n",
      "Iteration 2, loss = 0.65281887\n",
      "Iteration 3, loss = 0.56753235\n",
      "Iteration 4, loss = 0.50367785\n",
      "Iteration 5, loss = 0.49106217\n",
      "Iteration 6, loss = 0.47864832\n",
      "Iteration 7, loss = 0.51105599\n",
      "Iteration 8, loss = 0.49707874\n",
      "Iteration 9, loss = 0.46374546\n",
      "Iteration 10, loss = 0.45273374\n",
      "Iteration 11, loss = 0.45658235\n",
      "Iteration 12, loss = 0.45369755\n",
      "Iteration 13, loss = 0.46318498\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71768017\n",
      "Iteration 2, loss = 0.65490217\n",
      "Iteration 3, loss = 0.59239914\n",
      "Iteration 4, loss = 0.54959424\n",
      "Iteration 5, loss = 0.50406089\n",
      "Iteration 6, loss = 0.48700051\n",
      "Iteration 7, loss = 0.46429364\n",
      "Iteration 8, loss = 0.45102204\n",
      "Iteration 9, loss = 0.43988054\n",
      "Iteration 10, loss = 0.42199419\n",
      "Iteration 11, loss = 0.43288203\n",
      "Iteration 12, loss = 0.43552525\n",
      "Iteration 13, loss = 0.43748651\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73207046\n",
      "Iteration 2, loss = 0.64970055\n",
      "Iteration 3, loss = 0.62299769\n",
      "Iteration 4, loss = 0.58049012\n",
      "Iteration 5, loss = 0.54909264\n",
      "Iteration 6, loss = 0.52287228\n",
      "Iteration 7, loss = 0.51613198\n",
      "Iteration 8, loss = 0.48354556\n",
      "Iteration 9, loss = 0.47912990\n",
      "Iteration 10, loss = 0.49103222\n",
      "Iteration 11, loss = 0.50865718\n",
      "Iteration 12, loss = 0.48256786\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72400151\n",
      "Iteration 2, loss = 0.62005341\n",
      "Iteration 3, loss = 0.56259378\n",
      "Iteration 4, loss = 0.51052390\n",
      "Iteration 5, loss = 0.50152237\n",
      "Iteration 6, loss = 0.48640323\n",
      "Iteration 7, loss = 0.46825103\n",
      "Iteration 8, loss = 0.46754280\n",
      "Iteration 9, loss = 0.46459385\n",
      "Iteration 10, loss = 0.49655106\n",
      "Iteration 11, loss = 0.51477515\n",
      "Iteration 12, loss = 0.50293797\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72083190\n",
      "Iteration 2, loss = 0.60221505\n",
      "Iteration 3, loss = 0.53428093\n",
      "Iteration 4, loss = 0.48580472\n",
      "Iteration 5, loss = 0.46493827\n",
      "Iteration 6, loss = 0.46005713\n",
      "Iteration 7, loss = 0.46971115\n",
      "Iteration 8, loss = 0.47321336\n",
      "Iteration 9, loss = 0.46808310\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73520440\n",
      "Iteration 2, loss = 0.62624189\n",
      "Iteration 3, loss = 0.55265824\n",
      "Iteration 4, loss = 0.50883715\n",
      "Iteration 5, loss = 0.48287527\n",
      "Iteration 6, loss = 0.46419187\n",
      "Iteration 7, loss = 0.46837661\n",
      "Iteration 8, loss = 0.47091552\n",
      "Iteration 9, loss = 0.46671237\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72973441\n",
      "Iteration 2, loss = 0.62806996\n",
      "Iteration 3, loss = 0.56444402\n",
      "Iteration 4, loss = 0.51607316\n",
      "Iteration 5, loss = 0.49484927\n",
      "Iteration 6, loss = 0.44385324\n",
      "Iteration 7, loss = 0.42722897\n",
      "Iteration 8, loss = 0.41891371\n",
      "Iteration 9, loss = 0.42276948\n",
      "Iteration 10, loss = 0.40308620\n",
      "Iteration 11, loss = 0.42377338\n",
      "Iteration 12, loss = 0.44663645\n",
      "Iteration 13, loss = 0.40580457\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72474897\n",
      "Iteration 2, loss = 0.65872369\n",
      "Iteration 3, loss = 0.63369336\n",
      "Iteration 4, loss = 0.61161851\n",
      "Iteration 5, loss = 0.59616135\n",
      "Iteration 6, loss = 0.58093554\n",
      "Iteration 7, loss = 0.55176529\n",
      "Iteration 8, loss = 0.54444522\n",
      "Iteration 9, loss = 0.57644643\n",
      "Iteration 10, loss = 0.54406509\n",
      "Iteration 11, loss = 0.52405633\n",
      "Iteration 12, loss = 0.50599662\n",
      "Iteration 13, loss = 0.48472266\n",
      "Iteration 14, loss = 0.51216690\n",
      "Iteration 15, loss = 0.49546165\n",
      "Iteration 16, loss = 0.46306759\n",
      "Iteration 17, loss = 0.46834937\n",
      "Iteration 18, loss = 0.46229290\n",
      "Iteration 19, loss = 0.48466111\n",
      "Iteration 20, loss = 0.47355102\n",
      "Iteration 21, loss = 0.50142879\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71597308\n",
      "Iteration 2, loss = 0.65041681\n",
      "Iteration 3, loss = 0.61663583\n",
      "Iteration 4, loss = 0.59404133\n",
      "Iteration 5, loss = 0.54876863\n",
      "Iteration 6, loss = 0.52614016\n",
      "Iteration 7, loss = 0.50491836\n",
      "Iteration 8, loss = 0.49772912\n",
      "Iteration 9, loss = 0.48998509\n",
      "Iteration 10, loss = 0.47660591\n",
      "Iteration 11, loss = 0.47664668\n",
      "Iteration 12, loss = 0.47472307\n",
      "Iteration 13, loss = 0.47799945\n",
      "Iteration 14, loss = 0.47970064\n",
      "Iteration 15, loss = 0.49862328\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70660214\n",
      "Iteration 2, loss = 0.61533443\n",
      "Iteration 3, loss = 0.57212111\n",
      "Iteration 4, loss = 0.52676669\n",
      "Iteration 5, loss = 0.50779896\n",
      "Iteration 6, loss = 0.47228888\n",
      "Iteration 7, loss = 0.46245929\n",
      "Iteration 8, loss = 0.44568350\n",
      "Iteration 9, loss = 0.46721099\n",
      "Iteration 10, loss = 0.46482120\n",
      "Iteration 11, loss = 0.45318524\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72121254\n",
      "Iteration 2, loss = 0.63740221\n",
      "Iteration 3, loss = 0.59164235\n",
      "Iteration 4, loss = 0.52895076\n",
      "Iteration 5, loss = 0.51273277\n",
      "Iteration 6, loss = 0.48696681\n",
      "Iteration 7, loss = 0.47259203\n",
      "Iteration 8, loss = 0.45713693\n",
      "Iteration 9, loss = 0.47569378\n",
      "Iteration 10, loss = 0.47210965\n",
      "Iteration 11, loss = 0.47474465\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72390242\n",
      "Iteration 2, loss = 0.64299746\n",
      "Iteration 3, loss = 0.63396061\n",
      "Iteration 4, loss = 0.60108133\n",
      "Iteration 5, loss = 0.57273284\n",
      "Iteration 6, loss = 0.55824085\n",
      "Iteration 7, loss = 0.54629126\n",
      "Iteration 8, loss = 0.51267528\n",
      "Iteration 9, loss = 0.50134640\n",
      "Iteration 10, loss = 0.51568294\n",
      "Iteration 11, loss = 0.49534294\n",
      "Iteration 12, loss = 0.49994399\n",
      "Iteration 13, loss = 0.49666190\n",
      "Iteration 14, loss = 0.47189245\n",
      "Iteration 15, loss = 0.46637054\n",
      "Iteration 16, loss = 0.52395567\n",
      "Iteration 17, loss = 0.49966173\n",
      "Iteration 18, loss = 0.48771116\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72105215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.62974869\n",
      "Iteration 3, loss = 0.56603298\n",
      "Iteration 4, loss = 0.54132225\n",
      "Iteration 5, loss = 0.52075991\n",
      "Iteration 6, loss = 0.48552457\n",
      "Iteration 7, loss = 0.47832435\n",
      "Iteration 8, loss = 0.46973899\n",
      "Iteration 9, loss = 0.45758809\n",
      "Iteration 10, loss = 0.46347989\n",
      "Iteration 11, loss = 0.45904177\n",
      "Iteration 12, loss = 0.45898965\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72842865\n",
      "Iteration 2, loss = 0.64519200\n",
      "Iteration 3, loss = 0.61518256\n",
      "Iteration 4, loss = 0.57593015\n",
      "Iteration 5, loss = 0.55153416\n",
      "Iteration 6, loss = 0.54208773\n",
      "Iteration 7, loss = 0.55266185\n",
      "Iteration 8, loss = 0.50702914\n",
      "Iteration 9, loss = 0.54972433\n",
      "Iteration 10, loss = 0.50164181\n",
      "Iteration 11, loss = 0.47285630\n",
      "Iteration 12, loss = 0.47894408\n",
      "Iteration 13, loss = 0.46811644\n",
      "Iteration 14, loss = 0.48679980\n",
      "Iteration 15, loss = 0.48524561\n",
      "Iteration 16, loss = 0.48395847\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72436501\n",
      "Iteration 2, loss = 0.65711528\n",
      "Iteration 3, loss = 0.63337565\n",
      "Iteration 4, loss = 0.59636177\n",
      "Iteration 5, loss = 0.55610069\n",
      "Iteration 6, loss = 0.53462620\n",
      "Iteration 7, loss = 0.54202208\n",
      "Iteration 8, loss = 0.50232213\n",
      "Iteration 9, loss = 0.50102428\n",
      "Iteration 10, loss = 0.49792856\n",
      "Iteration 11, loss = 0.48692291\n",
      "Iteration 12, loss = 0.49146059\n",
      "Iteration 13, loss = 0.47070842\n",
      "Iteration 14, loss = 0.47015308\n",
      "Iteration 15, loss = 0.47880921\n",
      "Iteration 16, loss = 0.47970126\n",
      "Iteration 17, loss = 0.52622308\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72718178\n",
      "Iteration 2, loss = 0.62730114\n",
      "Iteration 3, loss = 0.57575920\n",
      "Iteration 4, loss = 0.51591930\n",
      "Iteration 5, loss = 0.48968941\n",
      "Iteration 6, loss = 0.49018954\n",
      "Iteration 7, loss = 0.46163872\n",
      "Iteration 8, loss = 0.50413896\n",
      "Iteration 9, loss = 0.48299174\n",
      "Iteration 10, loss = 0.48177867\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72199097\n",
      "Iteration 2, loss = 0.63364779\n",
      "Iteration 3, loss = 0.54222516\n",
      "Iteration 4, loss = 0.50109647\n",
      "Iteration 5, loss = 0.49344936\n",
      "Iteration 6, loss = 0.47247447\n",
      "Iteration 7, loss = 0.44007282\n",
      "Iteration 8, loss = 0.44893127\n",
      "Iteration 9, loss = 0.44318256\n",
      "Iteration 10, loss = 0.42858339\n",
      "Iteration 11, loss = 0.41930566\n",
      "Iteration 12, loss = 0.42323128\n",
      "Iteration 13, loss = 0.41899717\n",
      "Iteration 14, loss = 0.41008713\n",
      "Iteration 15, loss = 0.42106274\n",
      "Iteration 16, loss = 0.42635576\n",
      "Iteration 17, loss = 0.40638553\n",
      "Iteration 18, loss = 0.39697757\n",
      "Iteration 19, loss = 0.40828271\n",
      "Iteration 20, loss = 0.44079790\n",
      "Iteration 21, loss = 0.41315106\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79578869\n",
      "Iteration 2, loss = 0.60887554\n",
      "Iteration 3, loss = 0.57117236\n",
      "Iteration 4, loss = 0.50970871\n",
      "Iteration 5, loss = 0.47435884\n",
      "Iteration 6, loss = 0.46444541\n",
      "Iteration 7, loss = 0.46893613\n",
      "Iteration 8, loss = 0.45894796\n",
      "Iteration 9, loss = 0.45892206\n",
      "Iteration 10, loss = 0.44683535\n",
      "Iteration 11, loss = 0.45605377\n",
      "Iteration 12, loss = 0.45004009\n",
      "Iteration 13, loss = 0.42699798\n",
      "Iteration 14, loss = 0.45996200\n",
      "Iteration 15, loss = 0.43614311\n",
      "Iteration 16, loss = 0.42788575\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79189609\n",
      "Iteration 2, loss = 0.64667106\n",
      "Iteration 3, loss = 0.57645452\n",
      "Iteration 4, loss = 0.52358610\n",
      "Iteration 5, loss = 0.48908649\n",
      "Iteration 6, loss = 0.48961339\n",
      "Iteration 7, loss = 0.49049273\n",
      "Iteration 8, loss = 0.49021120\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79635611\n",
      "Iteration 2, loss = 0.65570719\n",
      "Iteration 3, loss = 0.63545174\n",
      "Iteration 4, loss = 0.60371229\n",
      "Iteration 5, loss = 0.56644450\n",
      "Iteration 6, loss = 0.54909053\n",
      "Iteration 7, loss = 0.51307937\n",
      "Iteration 8, loss = 0.50896820\n",
      "Iteration 9, loss = 0.50544856\n",
      "Iteration 10, loss = 0.49888896\n",
      "Iteration 11, loss = 0.48223325\n",
      "Iteration 12, loss = 0.47528459\n",
      "Iteration 13, loss = 0.47910060\n",
      "Iteration 14, loss = 0.50509432\n",
      "Iteration 15, loss = 0.50905194\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78474833\n",
      "Iteration 2, loss = 0.63924615\n",
      "Iteration 3, loss = 0.59084890\n",
      "Iteration 4, loss = 0.52271605\n",
      "Iteration 5, loss = 0.47067228\n",
      "Iteration 6, loss = 0.45816026\n",
      "Iteration 7, loss = 0.46113840\n",
      "Iteration 8, loss = 0.47256985\n",
      "Iteration 9, loss = 0.44149799\n",
      "Iteration 10, loss = 0.44282171\n",
      "Iteration 11, loss = 0.44891117\n",
      "Iteration 12, loss = 0.46300487\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79291401\n",
      "Iteration 2, loss = 0.63009377\n",
      "Iteration 3, loss = 0.56957161\n",
      "Iteration 4, loss = 0.51274304\n",
      "Iteration 5, loss = 0.46530844\n",
      "Iteration 6, loss = 0.44056412\n",
      "Iteration 7, loss = 0.44924881\n",
      "Iteration 8, loss = 0.44910646\n",
      "Iteration 9, loss = 0.44088187\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78238187\n",
      "Iteration 2, loss = 0.61969925\n",
      "Iteration 3, loss = 0.54478572\n",
      "Iteration 4, loss = 0.50996994\n",
      "Iteration 5, loss = 0.48764395\n",
      "Iteration 6, loss = 0.50252081\n",
      "Iteration 7, loss = 0.50079104\n",
      "Iteration 8, loss = 0.49105957\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79884197\n",
      "Iteration 2, loss = 0.68294144\n",
      "Iteration 3, loss = 0.66219167\n",
      "Iteration 4, loss = 0.62167930\n",
      "Iteration 5, loss = 0.57809923\n",
      "Iteration 6, loss = 0.54934738\n",
      "Iteration 7, loss = 0.52986978\n",
      "Iteration 8, loss = 0.49754849\n",
      "Iteration 9, loss = 0.48857827\n",
      "Iteration 10, loss = 0.51020520\n",
      "Iteration 11, loss = 0.48696456\n",
      "Iteration 12, loss = 0.46123751\n",
      "Iteration 13, loss = 0.47189608\n",
      "Iteration 14, loss = 0.47412479\n",
      "Iteration 15, loss = 0.45816663\n",
      "Iteration 16, loss = 0.46458091\n",
      "Iteration 17, loss = 0.48446100\n",
      "Iteration 18, loss = 0.49002834\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80023852\n",
      "Iteration 2, loss = 0.65570334\n",
      "Iteration 3, loss = 0.60639315\n",
      "Iteration 4, loss = 0.58048252\n",
      "Iteration 5, loss = 0.52755287\n",
      "Iteration 6, loss = 0.51674957\n",
      "Iteration 7, loss = 0.55742349\n",
      "Iteration 8, loss = 0.52944531\n",
      "Iteration 9, loss = 0.48853887\n",
      "Iteration 10, loss = 0.47585560\n",
      "Iteration 11, loss = 0.46509738\n",
      "Iteration 12, loss = 0.46222651\n",
      "Iteration 13, loss = 0.46235517\n",
      "Iteration 14, loss = 0.50320960\n",
      "Iteration 15, loss = 0.47141186\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79689216\n",
      "Iteration 2, loss = 0.63726505\n",
      "Iteration 3, loss = 0.58123711\n",
      "Iteration 4, loss = 0.53754849\n",
      "Iteration 5, loss = 0.50548201\n",
      "Iteration 6, loss = 0.51277036\n",
      "Iteration 7, loss = 0.47981817\n",
      "Iteration 8, loss = 0.47894382\n",
      "Iteration 9, loss = 0.48244370\n",
      "Iteration 10, loss = 0.48456609\n",
      "Iteration 11, loss = 0.47593736\n",
      "Iteration 12, loss = 0.46968264\n",
      "Iteration 13, loss = 0.47754525\n",
      "Iteration 14, loss = 0.47292959\n",
      "Iteration 15, loss = 0.46348803\n",
      "Iteration 16, loss = 0.46139639\n",
      "Iteration 17, loss = 0.46507690\n",
      "Iteration 18, loss = 0.45443635\n",
      "Iteration 19, loss = 0.48041575\n",
      "Iteration 20, loss = 0.45525179\n",
      "Iteration 21, loss = 0.45195142\n",
      "Iteration 22, loss = 0.44992080\n",
      "Iteration 23, loss = 0.46253721\n",
      "Iteration 24, loss = 0.44622259\n",
      "Iteration 25, loss = 0.45214176\n",
      "Iteration 26, loss = 0.45621262\n",
      "Iteration 27, loss = 0.45981044\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80314047\n",
      "Iteration 2, loss = 0.65677365\n",
      "Iteration 3, loss = 0.59160250\n",
      "Iteration 4, loss = 0.51677267\n",
      "Iteration 5, loss = 0.46682285\n",
      "Iteration 6, loss = 0.44872970\n",
      "Iteration 7, loss = 0.42877418\n",
      "Iteration 8, loss = 0.42256066\n",
      "Iteration 9, loss = 0.41689512\n",
      "Iteration 10, loss = 0.41798257\n",
      "Iteration 11, loss = 0.44189220\n",
      "Iteration 12, loss = 0.43268321\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71161896\n",
      "Iteration 2, loss = 0.60626652\n",
      "Iteration 3, loss = 0.52885350\n",
      "Iteration 4, loss = 0.48921888\n",
      "Iteration 5, loss = 0.48803578\n",
      "Iteration 6, loss = 0.47656769\n",
      "Iteration 7, loss = 0.47110293\n",
      "Iteration 8, loss = 0.44305895\n",
      "Iteration 9, loss = 0.45921956\n",
      "Iteration 10, loss = 0.45760009\n",
      "Iteration 11, loss = 0.45855530\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68189633\n",
      "Iteration 2, loss = 0.53556102\n",
      "Iteration 3, loss = 0.47224261\n",
      "Iteration 4, loss = 0.45108648\n",
      "Iteration 5, loss = 0.44918002\n",
      "Iteration 6, loss = 0.43451812\n",
      "Iteration 7, loss = 0.46937745\n",
      "Iteration 8, loss = 0.46643859\n",
      "Iteration 9, loss = 0.48134027\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71501312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.63643624\n",
      "Iteration 3, loss = 0.56898708\n",
      "Iteration 4, loss = 0.51930765\n",
      "Iteration 5, loss = 0.52254802\n",
      "Iteration 6, loss = 0.48675080\n",
      "Iteration 7, loss = 0.48782648\n",
      "Iteration 8, loss = 0.48979419\n",
      "Iteration 9, loss = 0.48264045\n",
      "Iteration 10, loss = 0.48637408\n",
      "Iteration 11, loss = 0.49573420\n",
      "Iteration 12, loss = 0.48403609\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68095128\n",
      "Iteration 2, loss = 0.53862739\n",
      "Iteration 3, loss = 0.49142883\n",
      "Iteration 4, loss = 0.46372856\n",
      "Iteration 5, loss = 0.46381525\n",
      "Iteration 6, loss = 0.47423770\n",
      "Iteration 7, loss = 0.45775010\n",
      "Iteration 8, loss = 0.43976842\n",
      "Iteration 9, loss = 0.44250423\n",
      "Iteration 10, loss = 0.43499661\n",
      "Iteration 11, loss = 0.44500966\n",
      "Iteration 12, loss = 0.43395603\n",
      "Iteration 13, loss = 0.43904331\n",
      "Iteration 14, loss = 0.45554365\n",
      "Iteration 15, loss = 0.43976436\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70334788\n",
      "Iteration 2, loss = 0.59908070\n",
      "Iteration 3, loss = 0.54818468\n",
      "Iteration 4, loss = 0.50050518\n",
      "Iteration 5, loss = 0.48419424\n",
      "Iteration 6, loss = 0.45243954\n",
      "Iteration 7, loss = 0.48137372\n",
      "Iteration 8, loss = 0.46052222\n",
      "Iteration 9, loss = 0.46357988\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71074471\n",
      "Iteration 2, loss = 0.61791369\n",
      "Iteration 3, loss = 0.59025445\n",
      "Iteration 4, loss = 0.53544240\n",
      "Iteration 5, loss = 0.50465720\n",
      "Iteration 6, loss = 0.48838126\n",
      "Iteration 7, loss = 0.45898794\n",
      "Iteration 8, loss = 0.45194252\n",
      "Iteration 9, loss = 0.47154548\n",
      "Iteration 10, loss = 0.47515384\n",
      "Iteration 11, loss = 0.51007453\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70366538\n",
      "Iteration 2, loss = 0.60736707\n",
      "Iteration 3, loss = 0.52062049\n",
      "Iteration 4, loss = 0.48054410\n",
      "Iteration 5, loss = 0.48895842\n",
      "Iteration 6, loss = 0.47432791\n",
      "Iteration 7, loss = 0.47151992\n",
      "Iteration 8, loss = 0.45165917\n",
      "Iteration 9, loss = 0.46353255\n",
      "Iteration 10, loss = 0.48082667\n",
      "Iteration 11, loss = 0.46909033\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70989946\n",
      "Iteration 2, loss = 0.61386932\n",
      "Iteration 3, loss = 0.55392081\n",
      "Iteration 4, loss = 0.51044619\n",
      "Iteration 5, loss = 0.49163315\n",
      "Iteration 6, loss = 0.49073710\n",
      "Iteration 7, loss = 0.45496090\n",
      "Iteration 8, loss = 0.47021234\n",
      "Iteration 9, loss = 0.46010866\n",
      "Iteration 10, loss = 0.45987903\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70674836\n",
      "Iteration 2, loss = 0.63407646\n",
      "Iteration 3, loss = 0.58857607\n",
      "Iteration 4, loss = 0.56459897\n",
      "Iteration 5, loss = 0.50930278\n",
      "Iteration 6, loss = 0.50415668\n",
      "Iteration 7, loss = 0.50621038\n",
      "Iteration 8, loss = 0.48656872\n",
      "Iteration 9, loss = 0.49881331\n",
      "Iteration 10, loss = 0.47264983\n",
      "Iteration 11, loss = 0.45794971\n",
      "Iteration 12, loss = 0.45494032\n",
      "Iteration 13, loss = 0.47935269\n",
      "Iteration 14, loss = 0.47337305\n",
      "Iteration 15, loss = 0.49585052\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70310897\n",
      "Iteration 2, loss = 0.59915423\n",
      "Iteration 3, loss = 0.52948316\n",
      "Iteration 4, loss = 0.51409025\n",
      "Iteration 5, loss = 0.47267678\n",
      "Iteration 6, loss = 0.44850672\n",
      "Iteration 7, loss = 0.44750395\n",
      "Iteration 8, loss = 0.44109468\n",
      "Iteration 9, loss = 0.44759956\n",
      "Iteration 10, loss = 0.43864312\n",
      "Iteration 11, loss = 0.43213411\n",
      "Iteration 12, loss = 0.42285577\n",
      "Iteration 13, loss = 0.44130311\n",
      "Iteration 14, loss = 0.43084313\n",
      "Iteration 15, loss = 0.39975255\n",
      "Iteration 16, loss = 0.39461098\n",
      "Iteration 17, loss = 0.40033641\n",
      "Iteration 18, loss = 0.41677487\n",
      "Iteration 19, loss = 0.43698123\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72334328\n",
      "Iteration 2, loss = 0.63649594\n",
      "Iteration 3, loss = 0.57239187\n",
      "Iteration 4, loss = 0.51630795\n",
      "Iteration 5, loss = 0.48560953\n",
      "Iteration 6, loss = 0.47698366\n",
      "Iteration 7, loss = 0.47119639\n",
      "Iteration 8, loss = 0.45538088\n",
      "Iteration 9, loss = 0.44797075\n",
      "Iteration 10, loss = 0.45297609\n",
      "Iteration 11, loss = 0.46430675\n",
      "Iteration 12, loss = 0.48263513\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71394068\n",
      "Iteration 2, loss = 0.59691649\n",
      "Iteration 3, loss = 0.51741858\n",
      "Iteration 4, loss = 0.47797428\n",
      "Iteration 5, loss = 0.46793299\n",
      "Iteration 6, loss = 0.46643177\n",
      "Iteration 7, loss = 0.46340495\n",
      "Iteration 8, loss = 0.45826601\n",
      "Iteration 9, loss = 0.45697419\n",
      "Iteration 10, loss = 0.46901600\n",
      "Iteration 11, loss = 0.49510619\n",
      "Iteration 12, loss = 0.45307529\n",
      "Iteration 13, loss = 0.44849805\n",
      "Iteration 14, loss = 0.44845606\n",
      "Iteration 15, loss = 0.43347154\n",
      "Iteration 16, loss = 0.42829582\n",
      "Iteration 17, loss = 0.43683042\n",
      "Iteration 18, loss = 0.47332681\n",
      "Iteration 19, loss = 0.46362692\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71292134\n",
      "Iteration 2, loss = 0.58617228\n",
      "Iteration 3, loss = 0.52438859\n",
      "Iteration 4, loss = 0.48508910\n",
      "Iteration 5, loss = 0.45384544\n",
      "Iteration 6, loss = 0.45137921\n",
      "Iteration 7, loss = 0.43712988\n",
      "Iteration 8, loss = 0.45183956\n",
      "Iteration 9, loss = 0.44988113\n",
      "Iteration 10, loss = 0.42928232\n",
      "Iteration 11, loss = 0.46528387\n",
      "Iteration 12, loss = 0.48282764\n",
      "Iteration 13, loss = 0.47055749\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73304763\n",
      "Iteration 2, loss = 0.61745550\n",
      "Iteration 3, loss = 0.54210590\n",
      "Iteration 4, loss = 0.50033081\n",
      "Iteration 5, loss = 0.48297312\n",
      "Iteration 6, loss = 0.47674845\n",
      "Iteration 7, loss = 0.45223223\n",
      "Iteration 8, loss = 0.44316157\n",
      "Iteration 9, loss = 0.44262515\n",
      "Iteration 10, loss = 0.46781337\n",
      "Iteration 11, loss = 0.45930975\n",
      "Iteration 12, loss = 0.44205208\n",
      "Iteration 13, loss = 0.45223814\n",
      "Iteration 14, loss = 0.46156545\n",
      "Iteration 15, loss = 0.46268281\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73151723\n",
      "Iteration 2, loss = 0.64259311\n",
      "Iteration 3, loss = 0.60074984\n",
      "Iteration 4, loss = 0.56062822\n",
      "Iteration 5, loss = 0.52894609\n",
      "Iteration 6, loss = 0.48014948\n",
      "Iteration 7, loss = 0.47492826\n",
      "Iteration 8, loss = 0.45630722\n",
      "Iteration 9, loss = 0.46538960\n",
      "Iteration 10, loss = 0.45515930\n",
      "Iteration 11, loss = 0.43978588\n",
      "Iteration 12, loss = 0.45959025\n",
      "Iteration 13, loss = 0.46102338\n",
      "Iteration 14, loss = 0.46021850\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74734714\n",
      "Iteration 2, loss = 0.63265037\n",
      "Iteration 3, loss = 0.56143985\n",
      "Iteration 4, loss = 0.51121023\n",
      "Iteration 5, loss = 0.49123043\n",
      "Iteration 6, loss = 0.49534119\n",
      "Iteration 7, loss = 0.51343918\n",
      "Iteration 8, loss = 0.48985488\n",
      "Iteration 9, loss = 0.45853438\n",
      "Iteration 10, loss = 0.46024969\n",
      "Iteration 11, loss = 0.47390315\n",
      "Iteration 12, loss = 0.47551955\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75033451\n",
      "Iteration 2, loss = 0.65382235\n",
      "Iteration 3, loss = 0.59721398\n",
      "Iteration 4, loss = 0.54765466\n",
      "Iteration 5, loss = 0.53828673\n",
      "Iteration 6, loss = 0.52252666\n",
      "Iteration 7, loss = 0.49331793\n",
      "Iteration 8, loss = 0.47303941\n",
      "Iteration 9, loss = 0.46509482\n",
      "Iteration 10, loss = 0.46263224\n",
      "Iteration 11, loss = 0.50509407\n",
      "Iteration 12, loss = 0.49527471\n",
      "Iteration 13, loss = 0.48047774\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74551165\n",
      "Iteration 2, loss = 0.67276880\n",
      "Iteration 3, loss = 0.64703060\n",
      "Iteration 4, loss = 0.61333549\n",
      "Iteration 5, loss = 0.57251466\n",
      "Iteration 6, loss = 0.54893939\n",
      "Iteration 7, loss = 0.53330373\n",
      "Iteration 8, loss = 0.51709524\n",
      "Iteration 9, loss = 0.49892775\n",
      "Iteration 10, loss = 0.48764392\n",
      "Iteration 11, loss = 0.46670723\n",
      "Iteration 12, loss = 0.49804787\n",
      "Iteration 13, loss = 0.46778318\n",
      "Iteration 14, loss = 0.47488188\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74237759\n",
      "Iteration 2, loss = 0.64763624\n",
      "Iteration 3, loss = 0.60813283\n",
      "Iteration 4, loss = 0.55922309\n",
      "Iteration 5, loss = 0.53938352\n",
      "Iteration 6, loss = 0.51240365\n",
      "Iteration 7, loss = 0.52801097\n",
      "Iteration 8, loss = 0.49892854\n",
      "Iteration 9, loss = 0.50925078\n",
      "Iteration 10, loss = 0.51168371\n",
      "Iteration 11, loss = 0.53354694\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73338549\n",
      "Iteration 2, loss = 0.59898663\n",
      "Iteration 3, loss = 0.51496829\n",
      "Iteration 4, loss = 0.45576308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.41416455\n",
      "Iteration 6, loss = 0.43585175\n",
      "Iteration 7, loss = 0.43119809\n",
      "Iteration 8, loss = 0.41468548\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76105079\n",
      "Iteration 2, loss = 0.61511366\n",
      "Iteration 3, loss = 0.53546447\n",
      "Iteration 4, loss = 0.49390439\n",
      "Iteration 5, loss = 0.48724407\n",
      "Iteration 6, loss = 0.46517556\n",
      "Iteration 7, loss = 0.45796937\n",
      "Iteration 8, loss = 0.44005000\n",
      "Iteration 9, loss = 0.43322306\n",
      "Iteration 10, loss = 0.43736327\n",
      "Iteration 11, loss = 0.45104074\n",
      "Iteration 12, loss = 0.43698534\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75996784\n",
      "Iteration 2, loss = 0.60741234\n",
      "Iteration 3, loss = 0.53723997\n",
      "Iteration 4, loss = 0.47278686\n",
      "Iteration 5, loss = 0.49534520\n",
      "Iteration 6, loss = 0.48993228\n",
      "Iteration 7, loss = 0.48391522\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74336917\n",
      "Iteration 2, loss = 0.57183801\n",
      "Iteration 3, loss = 0.50742126\n",
      "Iteration 4, loss = 0.46729665\n",
      "Iteration 5, loss = 0.46929509\n",
      "Iteration 6, loss = 0.46373367\n",
      "Iteration 7, loss = 0.45102714\n",
      "Iteration 8, loss = 0.47446760\n",
      "Iteration 9, loss = 0.44692526\n",
      "Iteration 10, loss = 0.44590305\n",
      "Iteration 11, loss = 0.44664440\n",
      "Iteration 12, loss = 0.44611718\n",
      "Iteration 13, loss = 0.44922606\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77158257\n",
      "Iteration 2, loss = 0.61424767\n",
      "Iteration 3, loss = 0.54692052\n",
      "Iteration 4, loss = 0.50602368\n",
      "Iteration 5, loss = 0.48161239\n",
      "Iteration 6, loss = 0.47741321\n",
      "Iteration 7, loss = 0.45929788\n",
      "Iteration 8, loss = 0.45024385\n",
      "Iteration 9, loss = 0.45146512\n",
      "Iteration 10, loss = 0.44719493\n",
      "Iteration 11, loss = 0.44620334\n",
      "Iteration 12, loss = 0.45984878\n",
      "Iteration 13, loss = 0.44365372\n",
      "Iteration 14, loss = 0.45635401\n",
      "Iteration 15, loss = 0.45275498\n",
      "Iteration 16, loss = 0.45901822\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76800228\n",
      "Iteration 2, loss = 0.59863963\n",
      "Iteration 3, loss = 0.54135142\n",
      "Iteration 4, loss = 0.49442416\n",
      "Iteration 5, loss = 0.48607672\n",
      "Iteration 6, loss = 0.48297263\n",
      "Iteration 7, loss = 0.44936984\n",
      "Iteration 8, loss = 0.46328639\n",
      "Iteration 9, loss = 0.45674331\n",
      "Iteration 10, loss = 0.47295163\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76140985\n",
      "Iteration 2, loss = 0.61864400\n",
      "Iteration 3, loss = 0.57683322\n",
      "Iteration 4, loss = 0.53630186\n",
      "Iteration 5, loss = 0.51403585\n",
      "Iteration 6, loss = 0.48759974\n",
      "Iteration 7, loss = 0.49154519\n",
      "Iteration 8, loss = 0.51351041\n",
      "Iteration 9, loss = 0.48530108\n",
      "Iteration 10, loss = 0.46432615\n",
      "Iteration 11, loss = 0.46658177\n",
      "Iteration 12, loss = 0.47965306\n",
      "Iteration 13, loss = 0.46510731\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76897079\n",
      "Iteration 2, loss = 0.62236079\n",
      "Iteration 3, loss = 0.54480356\n",
      "Iteration 4, loss = 0.49933916\n",
      "Iteration 5, loss = 0.47965155\n",
      "Iteration 6, loss = 0.45971424\n",
      "Iteration 7, loss = 0.47884847\n",
      "Iteration 8, loss = 0.46599634\n",
      "Iteration 9, loss = 0.47135614\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77195097\n",
      "Iteration 2, loss = 0.63480435\n",
      "Iteration 3, loss = 0.56744376\n",
      "Iteration 4, loss = 0.52834776\n",
      "Iteration 5, loss = 0.50531397\n",
      "Iteration 6, loss = 0.50377291\n",
      "Iteration 7, loss = 0.49292480\n",
      "Iteration 8, loss = 0.50313257\n",
      "Iteration 9, loss = 0.48268667\n",
      "Iteration 10, loss = 0.46551175\n",
      "Iteration 11, loss = 0.46050335\n",
      "Iteration 12, loss = 0.46734197\n",
      "Iteration 13, loss = 0.48036677\n",
      "Iteration 14, loss = 0.50233075\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78459603\n",
      "Iteration 2, loss = 0.65907439\n",
      "Iteration 3, loss = 0.61252990\n",
      "Iteration 4, loss = 0.56655659\n",
      "Iteration 5, loss = 0.53044823\n",
      "Iteration 6, loss = 0.51787087\n",
      "Iteration 7, loss = 0.51279264\n",
      "Iteration 8, loss = 0.49765890\n",
      "Iteration 9, loss = 0.50673135\n",
      "Iteration 10, loss = 0.48759998\n",
      "Iteration 11, loss = 0.49012939\n",
      "Iteration 12, loss = 0.46968561\n",
      "Iteration 13, loss = 0.45524094\n",
      "Iteration 14, loss = 0.46068777\n",
      "Iteration 15, loss = 0.48698361\n",
      "Iteration 16, loss = 0.54289992\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77429360\n",
      "Iteration 2, loss = 0.60220759\n",
      "Iteration 3, loss = 0.51264694\n",
      "Iteration 4, loss = 0.46123131\n",
      "Iteration 5, loss = 0.43118712\n",
      "Iteration 6, loss = 0.43340405\n",
      "Iteration 7, loss = 0.44224466\n",
      "Iteration 8, loss = 0.40161996\n",
      "Iteration 9, loss = 0.42914907\n",
      "Iteration 10, loss = 0.40000681\n",
      "Iteration 11, loss = 0.41646222\n",
      "Iteration 12, loss = 0.41569160\n",
      "Iteration 13, loss = 0.40266806\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72241885\n",
      "Iteration 2, loss = 0.62195140\n",
      "Iteration 3, loss = 0.55383814\n",
      "Iteration 4, loss = 0.50979492\n",
      "Iteration 5, loss = 0.47759574\n",
      "Iteration 6, loss = 0.47092510\n",
      "Iteration 7, loss = 0.46082063\n",
      "Iteration 8, loss = 0.44946369\n",
      "Iteration 9, loss = 0.44891300\n",
      "Iteration 10, loss = 0.47326756\n",
      "Iteration 11, loss = 0.44061623\n",
      "Iteration 12, loss = 0.45629425\n",
      "Iteration 13, loss = 0.45889503\n",
      "Iteration 14, loss = 0.47805586\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71321926\n",
      "Iteration 2, loss = 0.63286383\n",
      "Iteration 3, loss = 0.59832933\n",
      "Iteration 4, loss = 0.57055358\n",
      "Iteration 5, loss = 0.53220915\n",
      "Iteration 6, loss = 0.49524632\n",
      "Iteration 7, loss = 0.48833225\n",
      "Iteration 8, loss = 0.47140435\n",
      "Iteration 9, loss = 0.48514496\n",
      "Iteration 10, loss = 0.46146481\n",
      "Iteration 11, loss = 0.45680802\n",
      "Iteration 12, loss = 0.45094018\n",
      "Iteration 13, loss = 0.46235561\n",
      "Iteration 14, loss = 0.46666531\n",
      "Iteration 15, loss = 0.49169286\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71828014\n",
      "Iteration 2, loss = 0.61755793\n",
      "Iteration 3, loss = 0.54959372\n",
      "Iteration 4, loss = 0.51418807\n",
      "Iteration 5, loss = 0.50624863\n",
      "Iteration 6, loss = 0.50232699\n",
      "Iteration 7, loss = 0.50641093\n",
      "Iteration 8, loss = 0.50155322\n",
      "Iteration 9, loss = 0.50660242\n",
      "Iteration 10, loss = 0.49151040\n",
      "Iteration 11, loss = 0.49652100\n",
      "Iteration 12, loss = 0.51373277\n",
      "Iteration 13, loss = 0.49634208\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72133539\n",
      "Iteration 2, loss = 0.62275740\n",
      "Iteration 3, loss = 0.56126282\n",
      "Iteration 4, loss = 0.50809300\n",
      "Iteration 5, loss = 0.47284471\n",
      "Iteration 6, loss = 0.45618557\n",
      "Iteration 7, loss = 0.46566592\n",
      "Iteration 8, loss = 0.49463360\n",
      "Iteration 9, loss = 0.47013362\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71532602\n",
      "Iteration 2, loss = 0.60506999\n",
      "Iteration 3, loss = 0.53211056\n",
      "Iteration 4, loss = 0.48601106\n",
      "Iteration 5, loss = 0.46025246\n",
      "Iteration 6, loss = 0.47197104\n",
      "Iteration 7, loss = 0.46166062\n",
      "Iteration 8, loss = 0.45637002\n",
      "Iteration 9, loss = 0.44984177\n",
      "Iteration 10, loss = 0.44689139\n",
      "Iteration 11, loss = 0.44816536\n",
      "Iteration 12, loss = 0.45454552\n",
      "Iteration 13, loss = 0.46323088\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69801401\n",
      "Iteration 2, loss = 0.58150685\n",
      "Iteration 3, loss = 0.52850973\n",
      "Iteration 4, loss = 0.49524418\n",
      "Iteration 5, loss = 0.48412709\n",
      "Iteration 6, loss = 0.47631121\n",
      "Iteration 7, loss = 0.45514742\n",
      "Iteration 8, loss = 0.47148411\n",
      "Iteration 9, loss = 0.47309310\n",
      "Iteration 10, loss = 0.52337203\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70611542\n",
      "Iteration 2, loss = 0.56012902\n",
      "Iteration 3, loss = 0.50193659\n",
      "Iteration 4, loss = 0.47028112\n",
      "Iteration 5, loss = 0.48017980\n",
      "Iteration 6, loss = 0.47252111\n",
      "Iteration 7, loss = 0.45285893\n",
      "Iteration 8, loss = 0.45619624\n",
      "Iteration 9, loss = 0.47190569\n",
      "Iteration 10, loss = 0.46150892\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71657073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.59602107\n",
      "Iteration 3, loss = 0.53261125\n",
      "Iteration 4, loss = 0.50821406\n",
      "Iteration 5, loss = 0.47329935\n",
      "Iteration 6, loss = 0.45415985\n",
      "Iteration 7, loss = 0.44193114\n",
      "Iteration 8, loss = 0.45624088\n",
      "Iteration 9, loss = 0.46595560\n",
      "Iteration 10, loss = 0.44502404\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72436271\n",
      "Iteration 2, loss = 0.59076566\n",
      "Iteration 3, loss = 0.51244169\n",
      "Iteration 4, loss = 0.46144420\n",
      "Iteration 5, loss = 0.45500521\n",
      "Iteration 6, loss = 0.48400987\n",
      "Iteration 7, loss = 0.47106326\n",
      "Iteration 8, loss = 0.46367634\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72080404\n",
      "Iteration 2, loss = 0.62493752\n",
      "Iteration 3, loss = 0.53814141\n",
      "Iteration 4, loss = 0.48977464\n",
      "Iteration 5, loss = 0.45436807\n",
      "Iteration 6, loss = 0.44111202\n",
      "Iteration 7, loss = 0.41676460\n",
      "Iteration 8, loss = 0.42779709\n",
      "Iteration 9, loss = 0.42613838\n",
      "Iteration 10, loss = 0.41331773\n",
      "Iteration 11, loss = 0.39961592\n",
      "Iteration 12, loss = 0.39899669\n",
      "Iteration 13, loss = 0.41512613\n",
      "Iteration 14, loss = 0.47572025\n",
      "Iteration 15, loss = 0.42802735\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69799656\n",
      "Iteration 2, loss = 0.57304931\n",
      "Iteration 3, loss = 0.49899778\n",
      "Iteration 4, loss = 0.44824720\n",
      "Iteration 5, loss = 0.46153508\n",
      "Iteration 6, loss = 0.43501059\n",
      "Iteration 7, loss = 0.43125765\n",
      "Iteration 8, loss = 0.44365649\n",
      "Iteration 9, loss = 0.43114009\n",
      "Iteration 10, loss = 0.42863835\n",
      "Iteration 11, loss = 0.42469668\n",
      "Iteration 12, loss = 0.42227028\n",
      "Iteration 13, loss = 0.44132229\n",
      "Iteration 14, loss = 0.45422795\n",
      "Iteration 15, loss = 0.46147323\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69080348\n",
      "Iteration 2, loss = 0.56396003\n",
      "Iteration 3, loss = 0.48939954\n",
      "Iteration 4, loss = 0.46016517\n",
      "Iteration 5, loss = 0.47878235\n",
      "Iteration 6, loss = 0.44145085\n",
      "Iteration 7, loss = 0.44182045\n",
      "Iteration 8, loss = 0.43431721\n",
      "Iteration 9, loss = 0.43308520\n",
      "Iteration 10, loss = 0.44450519\n",
      "Iteration 11, loss = 0.44593459\n",
      "Iteration 12, loss = 0.45483632\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69088292\n",
      "Iteration 2, loss = 0.56332798\n",
      "Iteration 3, loss = 0.50048399\n",
      "Iteration 4, loss = 0.47964218\n",
      "Iteration 5, loss = 0.48143567\n",
      "Iteration 6, loss = 0.47072287\n",
      "Iteration 7, loss = 0.47481981\n",
      "Iteration 8, loss = 0.48332700\n",
      "Iteration 9, loss = 0.46476469\n",
      "Iteration 10, loss = 0.48603559\n",
      "Iteration 11, loss = 0.47301625\n",
      "Iteration 12, loss = 0.47056451\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69753158\n",
      "Iteration 2, loss = 0.56004712\n",
      "Iteration 3, loss = 0.50074172\n",
      "Iteration 4, loss = 0.47777314\n",
      "Iteration 5, loss = 0.46223451\n",
      "Iteration 6, loss = 0.45579703\n",
      "Iteration 7, loss = 0.43184144\n",
      "Iteration 8, loss = 0.43041439\n",
      "Iteration 9, loss = 0.42370818\n",
      "Iteration 10, loss = 0.46675604\n",
      "Iteration 11, loss = 0.46472542\n",
      "Iteration 12, loss = 0.46543762\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69931011\n",
      "Iteration 2, loss = 0.58776905\n",
      "Iteration 3, loss = 0.51663415\n",
      "Iteration 4, loss = 0.49418746\n",
      "Iteration 5, loss = 0.46289796\n",
      "Iteration 6, loss = 0.44952024\n",
      "Iteration 7, loss = 0.45494527\n",
      "Iteration 8, loss = 0.48582461\n",
      "Iteration 9, loss = 0.44128006\n",
      "Iteration 10, loss = 0.47534479\n",
      "Iteration 11, loss = 0.47126854\n",
      "Iteration 12, loss = 0.47782197\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69881325\n",
      "Iteration 2, loss = 0.59313859\n",
      "Iteration 3, loss = 0.53863068\n",
      "Iteration 4, loss = 0.50728733\n",
      "Iteration 5, loss = 0.47405720\n",
      "Iteration 6, loss = 0.47182630\n",
      "Iteration 7, loss = 0.46949240\n",
      "Iteration 8, loss = 0.47242512\n",
      "Iteration 9, loss = 0.46790898\n",
      "Iteration 10, loss = 0.46707812\n",
      "Iteration 11, loss = 0.46402630\n",
      "Iteration 12, loss = 0.48900013\n",
      "Iteration 13, loss = 0.49335502\n",
      "Iteration 14, loss = 0.51315883\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69638325\n",
      "Iteration 2, loss = 0.56636419\n",
      "Iteration 3, loss = 0.50579217\n",
      "Iteration 4, loss = 0.47917489\n",
      "Iteration 5, loss = 0.46609221\n",
      "Iteration 6, loss = 0.46383131\n",
      "Iteration 7, loss = 0.43922386\n",
      "Iteration 8, loss = 0.44349345\n",
      "Iteration 9, loss = 0.45484837\n",
      "Iteration 10, loss = 0.44189034\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68586539\n",
      "Iteration 2, loss = 0.54645848\n",
      "Iteration 3, loss = 0.48068424\n",
      "Iteration 4, loss = 0.48430166\n",
      "Iteration 5, loss = 0.47726335\n",
      "Iteration 6, loss = 0.45951808\n",
      "Iteration 7, loss = 0.44605692\n",
      "Iteration 8, loss = 0.47727932\n",
      "Iteration 9, loss = 0.47131700\n",
      "Iteration 10, loss = 0.46713155\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69995541\n",
      "Iteration 2, loss = 0.58605759\n",
      "Iteration 3, loss = 0.52567711\n",
      "Iteration 4, loss = 0.50182954\n",
      "Iteration 5, loss = 0.47261547\n",
      "Iteration 6, loss = 0.47871130\n",
      "Iteration 7, loss = 0.47921505\n",
      "Iteration 8, loss = 0.51150804\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69491988\n",
      "Iteration 2, loss = 0.58644689\n",
      "Iteration 3, loss = 0.48950546\n",
      "Iteration 4, loss = 0.45932516\n",
      "Iteration 5, loss = 0.45690064\n",
      "Iteration 6, loss = 0.42900356\n",
      "Iteration 7, loss = 0.41949648\n",
      "Iteration 8, loss = 0.42988124\n",
      "Iteration 9, loss = 0.40928848\n",
      "Iteration 10, loss = 0.43224078\n",
      "Iteration 11, loss = 0.40602482\n",
      "Iteration 12, loss = 0.45087752\n",
      "Iteration 13, loss = 0.45543580\n",
      "Iteration 14, loss = 0.42041833\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81698216\n",
      "Iteration 2, loss = 0.65580797\n",
      "Iteration 3, loss = 0.57920137\n",
      "Iteration 4, loss = 0.49642815\n",
      "Iteration 5, loss = 0.46999520\n",
      "Iteration 6, loss = 0.45841508\n",
      "Iteration 7, loss = 0.45732622\n",
      "Iteration 8, loss = 0.46470734\n",
      "Iteration 9, loss = 0.46992696\n",
      "Iteration 10, loss = 0.43482414\n",
      "Iteration 11, loss = 0.45769343\n",
      "Iteration 12, loss = 0.43726789\n",
      "Iteration 13, loss = 0.45125538\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82309828\n",
      "Iteration 2, loss = 0.65706616\n",
      "Iteration 3, loss = 0.58900685\n",
      "Iteration 4, loss = 0.52833330\n",
      "Iteration 5, loss = 0.47569250\n",
      "Iteration 6, loss = 0.45860223\n",
      "Iteration 7, loss = 0.49298207\n",
      "Iteration 8, loss = 0.48967735\n",
      "Iteration 9, loss = 0.50191545\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81043845\n",
      "Iteration 2, loss = 0.66411704\n",
      "Iteration 3, loss = 0.62083764\n",
      "Iteration 4, loss = 0.56862310\n",
      "Iteration 5, loss = 0.52008855\n",
      "Iteration 6, loss = 0.48902283\n",
      "Iteration 7, loss = 0.47844902\n",
      "Iteration 8, loss = 0.47200491\n",
      "Iteration 9, loss = 0.46232618\n",
      "Iteration 10, loss = 0.45913970\n",
      "Iteration 11, loss = 0.45614289\n",
      "Iteration 12, loss = 0.55079130\n",
      "Iteration 13, loss = 0.50979780\n",
      "Iteration 14, loss = 0.47577159\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81975752\n",
      "Iteration 2, loss = 0.65331183\n",
      "Iteration 3, loss = 0.59066825\n",
      "Iteration 4, loss = 0.52964910\n",
      "Iteration 5, loss = 0.47630102\n",
      "Iteration 6, loss = 0.46031831\n",
      "Iteration 7, loss = 0.46795517\n",
      "Iteration 8, loss = 0.45606852\n",
      "Iteration 9, loss = 0.46760184\n",
      "Iteration 10, loss = 0.46973465\n",
      "Iteration 11, loss = 0.48011158\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82156609\n",
      "Iteration 2, loss = 0.68792021\n",
      "Iteration 3, loss = 0.66508682\n",
      "Iteration 4, loss = 0.60630158\n",
      "Iteration 5, loss = 0.54924513\n",
      "Iteration 6, loss = 0.50574447\n",
      "Iteration 7, loss = 0.49277637\n",
      "Iteration 8, loss = 0.47492077\n",
      "Iteration 9, loss = 0.45966607\n",
      "Iteration 10, loss = 0.46448637\n",
      "Iteration 11, loss = 0.49645409\n",
      "Iteration 12, loss = 0.48892214\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80592864\n",
      "Iteration 2, loss = 0.64950603\n",
      "Iteration 3, loss = 0.61478636\n",
      "Iteration 4, loss = 0.56632878\n",
      "Iteration 5, loss = 0.53201917\n",
      "Iteration 6, loss = 0.52936635\n",
      "Iteration 7, loss = 0.52598926\n",
      "Iteration 8, loss = 0.50106906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.47068473\n",
      "Iteration 10, loss = 0.49195356\n",
      "Iteration 11, loss = 0.47974592\n",
      "Iteration 12, loss = 0.47196349\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80110239\n",
      "Iteration 2, loss = 0.65172749\n",
      "Iteration 3, loss = 0.59050255\n",
      "Iteration 4, loss = 0.53262012\n",
      "Iteration 5, loss = 0.51283051\n",
      "Iteration 6, loss = 0.50155121\n",
      "Iteration 7, loss = 0.49663574\n",
      "Iteration 8, loss = 0.46514836\n",
      "Iteration 9, loss = 0.46920076\n",
      "Iteration 10, loss = 0.46207308\n",
      "Iteration 11, loss = 0.44645422\n",
      "Iteration 12, loss = 0.45458854\n",
      "Iteration 13, loss = 0.45610621\n",
      "Iteration 14, loss = 0.46205424\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81676808\n",
      "Iteration 2, loss = 0.66953737\n",
      "Iteration 3, loss = 0.61551012\n",
      "Iteration 4, loss = 0.51618360\n",
      "Iteration 5, loss = 0.46972075\n",
      "Iteration 6, loss = 0.46924139\n",
      "Iteration 7, loss = 0.47076515\n",
      "Iteration 8, loss = 0.46232316\n",
      "Iteration 9, loss = 0.45828546\n",
      "Iteration 10, loss = 0.46566248\n",
      "Iteration 11, loss = 0.45632647\n",
      "Iteration 12, loss = 0.46587483\n",
      "Iteration 13, loss = 0.45407943\n",
      "Iteration 14, loss = 0.46725761\n",
      "Iteration 15, loss = 0.47928669\n",
      "Iteration 16, loss = 0.47134030\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79370241\n",
      "Iteration 2, loss = 0.63816679\n",
      "Iteration 3, loss = 0.55908559\n",
      "Iteration 4, loss = 0.50592627\n",
      "Iteration 5, loss = 0.49244617\n",
      "Iteration 6, loss = 0.46752188\n",
      "Iteration 7, loss = 0.45712107\n",
      "Iteration 8, loss = 0.46316637\n",
      "Iteration 9, loss = 0.45584713\n",
      "Iteration 10, loss = 0.49978815\n",
      "Iteration 11, loss = 0.47337475\n",
      "Iteration 12, loss = 0.48940243\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80494441\n",
      "Iteration 2, loss = 0.62289686\n",
      "Iteration 3, loss = 0.55575717\n",
      "Iteration 4, loss = 0.48641668\n",
      "Iteration 5, loss = 0.47521928\n",
      "Iteration 6, loss = 0.44508078\n",
      "Iteration 7, loss = 0.42870205\n",
      "Iteration 8, loss = 0.42418688\n",
      "Iteration 9, loss = 0.40835649\n",
      "Iteration 10, loss = 0.40623611\n",
      "Iteration 11, loss = 0.40091182\n",
      "Iteration 12, loss = 0.40459163\n",
      "Iteration 13, loss = 0.40991202\n",
      "Iteration 14, loss = 0.42261400\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77802015\n",
      "Iteration 2, loss = 0.65709604\n",
      "Iteration 3, loss = 0.59390968\n",
      "Iteration 4, loss = 0.53156068\n",
      "Iteration 5, loss = 0.49264988\n",
      "Iteration 6, loss = 0.46175632\n",
      "Iteration 7, loss = 0.47310200\n",
      "Iteration 8, loss = 0.45343419\n",
      "Iteration 9, loss = 0.47250473\n",
      "Iteration 10, loss = 0.43958231\n",
      "Iteration 11, loss = 0.45165350\n",
      "Iteration 12, loss = 0.46798012\n",
      "Iteration 13, loss = 0.47847524\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77383426\n",
      "Iteration 2, loss = 0.65875565\n",
      "Iteration 3, loss = 0.61045535\n",
      "Iteration 4, loss = 0.53502388\n",
      "Iteration 5, loss = 0.48230027\n",
      "Iteration 6, loss = 0.48318196\n",
      "Iteration 7, loss = 0.49652109\n",
      "Iteration 8, loss = 0.47095837\n",
      "Iteration 9, loss = 0.44880504\n",
      "Iteration 10, loss = 0.47059357\n",
      "Iteration 11, loss = 0.45276888\n",
      "Iteration 12, loss = 0.46131138\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76412945\n",
      "Iteration 2, loss = 0.66763865\n",
      "Iteration 3, loss = 0.63409680\n",
      "Iteration 4, loss = 0.56897504\n",
      "Iteration 5, loss = 0.51589566\n",
      "Iteration 6, loss = 0.49720637\n",
      "Iteration 7, loss = 0.52488524\n",
      "Iteration 8, loss = 0.52446906\n",
      "Iteration 9, loss = 0.50120631\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76236057\n",
      "Iteration 2, loss = 0.63330764\n",
      "Iteration 3, loss = 0.55704348\n",
      "Iteration 4, loss = 0.49645388\n",
      "Iteration 5, loss = 0.45851395\n",
      "Iteration 6, loss = 0.46089718\n",
      "Iteration 7, loss = 0.46762356\n",
      "Iteration 8, loss = 0.48261197\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74461622\n",
      "Iteration 2, loss = 0.61977752\n",
      "Iteration 3, loss = 0.54143744\n",
      "Iteration 4, loss = 0.49261462\n",
      "Iteration 5, loss = 0.48147535\n",
      "Iteration 6, loss = 0.47789012\n",
      "Iteration 7, loss = 0.49003657\n",
      "Iteration 8, loss = 0.46410866\n",
      "Iteration 9, loss = 0.46765116\n",
      "Iteration 10, loss = 0.46124053\n",
      "Iteration 11, loss = 0.46639780\n",
      "Iteration 12, loss = 0.46078111\n",
      "Iteration 13, loss = 0.46512257\n",
      "Iteration 14, loss = 0.45268844\n",
      "Iteration 15, loss = 0.45620829\n",
      "Iteration 16, loss = 0.44777606\n",
      "Iteration 17, loss = 0.44973507\n",
      "Iteration 18, loss = 0.46411960\n",
      "Iteration 19, loss = 0.45234080\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74317579\n",
      "Iteration 2, loss = 0.63731912\n",
      "Iteration 3, loss = 0.58380282\n",
      "Iteration 4, loss = 0.52283040\n",
      "Iteration 5, loss = 0.49036058\n",
      "Iteration 6, loss = 0.49714247\n",
      "Iteration 7, loss = 0.47865318\n",
      "Iteration 8, loss = 0.46417289\n",
      "Iteration 9, loss = 0.45428255\n",
      "Iteration 10, loss = 0.46038809\n",
      "Iteration 11, loss = 0.46990274\n",
      "Iteration 12, loss = 0.48381182\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74508390\n",
      "Iteration 2, loss = 0.60713252\n",
      "Iteration 3, loss = 0.53580768\n",
      "Iteration 4, loss = 0.48679723\n",
      "Iteration 5, loss = 0.46269848\n",
      "Iteration 6, loss = 0.48596654\n",
      "Iteration 7, loss = 0.46827922\n",
      "Iteration 8, loss = 0.47081494\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74608855\n",
      "Iteration 2, loss = 0.63958598\n",
      "Iteration 3, loss = 0.56539061\n",
      "Iteration 4, loss = 0.49952826\n",
      "Iteration 5, loss = 0.46971695\n",
      "Iteration 6, loss = 0.46760403\n",
      "Iteration 7, loss = 0.46024926\n",
      "Iteration 8, loss = 0.47420688\n",
      "Iteration 9, loss = 0.45522761\n",
      "Iteration 10, loss = 0.47374069\n",
      "Iteration 11, loss = 0.47470467\n",
      "Iteration 12, loss = 0.46650816\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74645881\n",
      "Iteration 2, loss = 0.62122478\n",
      "Iteration 3, loss = 0.53712860\n",
      "Iteration 4, loss = 0.50422072\n",
      "Iteration 5, loss = 0.47573541\n",
      "Iteration 6, loss = 0.47971333\n",
      "Iteration 7, loss = 0.46962087\n",
      "Iteration 8, loss = 0.48813159\n",
      "Iteration 9, loss = 0.47064524\n",
      "Iteration 10, loss = 0.45314773\n",
      "Iteration 11, loss = 0.45927134\n",
      "Iteration 12, loss = 0.48694990\n",
      "Iteration 13, loss = 0.46843268\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74828409\n",
      "Iteration 2, loss = 0.63525212\n",
      "Iteration 3, loss = 0.57164441\n",
      "Iteration 4, loss = 0.50898428\n",
      "Iteration 5, loss = 0.44714802\n",
      "Iteration 6, loss = 0.44238088\n",
      "Iteration 7, loss = 0.42686934\n",
      "Iteration 8, loss = 0.41497540\n",
      "Iteration 9, loss = 0.39900205\n",
      "Iteration 10, loss = 0.39166288\n",
      "Iteration 11, loss = 0.41765588\n",
      "Iteration 12, loss = 0.40681524\n",
      "Iteration 13, loss = 0.40476731\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69557617\n",
      "Iteration 2, loss = 0.59132510\n",
      "Iteration 3, loss = 0.52491603\n",
      "Iteration 4, loss = 0.49053167\n",
      "Iteration 5, loss = 0.46134608\n",
      "Iteration 6, loss = 0.46288810\n",
      "Iteration 7, loss = 0.45900605\n",
      "Iteration 8, loss = 0.44506312\n",
      "Iteration 9, loss = 0.45544595\n",
      "Iteration 10, loss = 0.44284956\n",
      "Iteration 11, loss = 0.44027084\n",
      "Iteration 12, loss = 0.45786140\n",
      "Iteration 13, loss = 0.45342423\n",
      "Iteration 14, loss = 0.46001839\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71287472\n",
      "Iteration 2, loss = 0.61555076\n",
      "Iteration 3, loss = 0.59177519\n",
      "Iteration 4, loss = 0.53514695\n",
      "Iteration 5, loss = 0.48532251\n",
      "Iteration 6, loss = 0.48525889\n",
      "Iteration 7, loss = 0.46741697\n",
      "Iteration 8, loss = 0.44460586\n",
      "Iteration 9, loss = 0.45993705\n",
      "Iteration 10, loss = 0.46978865\n",
      "Iteration 11, loss = 0.46126667\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69834373\n",
      "Iteration 2, loss = 0.58394069\n",
      "Iteration 3, loss = 0.50288908\n",
      "Iteration 4, loss = 0.46681248\n",
      "Iteration 5, loss = 0.46802199\n",
      "Iteration 6, loss = 0.49213782\n",
      "Iteration 7, loss = 0.46665062\n",
      "Iteration 8, loss = 0.46184830\n",
      "Iteration 9, loss = 0.44277777\n",
      "Iteration 10, loss = 0.45840104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.46511373\n",
      "Iteration 12, loss = 0.46185465\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69435486\n",
      "Iteration 2, loss = 0.56929539\n",
      "Iteration 3, loss = 0.49583115\n",
      "Iteration 4, loss = 0.47081226\n",
      "Iteration 5, loss = 0.46015707\n",
      "Iteration 6, loss = 0.49496965\n",
      "Iteration 7, loss = 0.46576471\n",
      "Iteration 8, loss = 0.47580831\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69055091\n",
      "Iteration 2, loss = 0.58777795\n",
      "Iteration 3, loss = 0.53508468\n",
      "Iteration 4, loss = 0.50277163\n",
      "Iteration 5, loss = 0.46204817\n",
      "Iteration 6, loss = 0.46033214\n",
      "Iteration 7, loss = 0.46755455\n",
      "Iteration 8, loss = 0.47805796\n",
      "Iteration 9, loss = 0.44878374\n",
      "Iteration 10, loss = 0.43207118\n",
      "Iteration 11, loss = 0.44688987\n",
      "Iteration 12, loss = 0.44596276\n",
      "Iteration 13, loss = 0.44038215\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68830131\n",
      "Iteration 2, loss = 0.57895916\n",
      "Iteration 3, loss = 0.52021417\n",
      "Iteration 4, loss = 0.48774821\n",
      "Iteration 5, loss = 0.47836882\n",
      "Iteration 6, loss = 0.46774632\n",
      "Iteration 7, loss = 0.45030165\n",
      "Iteration 8, loss = 0.47790715\n",
      "Iteration 9, loss = 0.46393706\n",
      "Iteration 10, loss = 0.44921045\n",
      "Iteration 11, loss = 0.44277603\n",
      "Iteration 12, loss = 0.44795313\n",
      "Iteration 13, loss = 0.44180708\n",
      "Iteration 14, loss = 0.44401280\n",
      "Iteration 15, loss = 0.44832538\n",
      "Iteration 16, loss = 0.44564763\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69766592\n",
      "Iteration 2, loss = 0.59419714\n",
      "Iteration 3, loss = 0.54176513\n",
      "Iteration 4, loss = 0.50110025\n",
      "Iteration 5, loss = 0.46574875\n",
      "Iteration 6, loss = 0.45554461\n",
      "Iteration 7, loss = 0.44351279\n",
      "Iteration 8, loss = 0.43935030\n",
      "Iteration 9, loss = 0.46615562\n",
      "Iteration 10, loss = 0.50025266\n",
      "Iteration 11, loss = 0.46779415\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69546938\n",
      "Iteration 2, loss = 0.63357526\n",
      "Iteration 3, loss = 0.57038178\n",
      "Iteration 4, loss = 0.51504067\n",
      "Iteration 5, loss = 0.48073228\n",
      "Iteration 6, loss = 0.47418942\n",
      "Iteration 7, loss = 0.47116721\n",
      "Iteration 8, loss = 0.45630970\n",
      "Iteration 9, loss = 0.51389302\n",
      "Iteration 10, loss = 0.54453036\n",
      "Iteration 11, loss = 0.52313922\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68380936\n",
      "Iteration 2, loss = 0.59482519\n",
      "Iteration 3, loss = 0.55272829\n",
      "Iteration 4, loss = 0.51082966\n",
      "Iteration 5, loss = 0.48848148\n",
      "Iteration 6, loss = 0.49764500\n",
      "Iteration 7, loss = 0.46646099\n",
      "Iteration 8, loss = 0.47772390\n",
      "Iteration 9, loss = 0.52614684\n",
      "Iteration 10, loss = 0.47280169\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.68922210\n",
      "Iteration 2, loss = 0.59302811\n",
      "Iteration 3, loss = 0.50331619\n",
      "Iteration 4, loss = 0.43963963\n",
      "Iteration 5, loss = 0.43155925\n",
      "Iteration 6, loss = 0.41178628\n",
      "Iteration 7, loss = 0.41153043\n",
      "Iteration 8, loss = 0.40430555\n",
      "Iteration 9, loss = 0.39415371\n",
      "Iteration 10, loss = 0.45509117\n",
      "Iteration 11, loss = 0.44111118\n",
      "Iteration 12, loss = 0.44848138\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74994459\n",
      "Iteration 2, loss = 0.63374824\n",
      "Iteration 3, loss = 0.55298606\n",
      "Iteration 4, loss = 0.51017081\n",
      "Iteration 5, loss = 0.48799152\n",
      "Iteration 6, loss = 0.51406521\n",
      "Iteration 7, loss = 0.50423774\n",
      "Iteration 8, loss = 0.46894337\n",
      "Iteration 9, loss = 0.45724320\n",
      "Iteration 10, loss = 0.45754084\n",
      "Iteration 11, loss = 0.46192590\n",
      "Iteration 12, loss = 0.46120130\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72054008\n",
      "Iteration 2, loss = 0.58058218\n",
      "Iteration 3, loss = 0.49366185\n",
      "Iteration 4, loss = 0.47357215\n",
      "Iteration 5, loss = 0.46751240\n",
      "Iteration 6, loss = 0.45666435\n",
      "Iteration 7, loss = 0.44802405\n",
      "Iteration 8, loss = 0.44574348\n",
      "Iteration 9, loss = 0.45718980\n",
      "Iteration 10, loss = 0.44372710\n",
      "Iteration 11, loss = 0.43295211\n",
      "Iteration 12, loss = 0.43117111\n",
      "Iteration 13, loss = 0.44733847\n",
      "Iteration 14, loss = 0.45472288\n",
      "Iteration 15, loss = 0.44774302\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72228514\n",
      "Iteration 2, loss = 0.58373902\n",
      "Iteration 3, loss = 0.52123023\n",
      "Iteration 4, loss = 0.49709849\n",
      "Iteration 5, loss = 0.49897234\n",
      "Iteration 6, loss = 0.51496169\n",
      "Iteration 7, loss = 0.50000867\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72405237\n",
      "Iteration 2, loss = 0.57979039\n",
      "Iteration 3, loss = 0.49230929\n",
      "Iteration 4, loss = 0.47326794\n",
      "Iteration 5, loss = 0.45431149\n",
      "Iteration 6, loss = 0.47375014\n",
      "Iteration 7, loss = 0.47108995\n",
      "Iteration 8, loss = 0.46341120\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72965862\n",
      "Iteration 2, loss = 0.61544880\n",
      "Iteration 3, loss = 0.56937883\n",
      "Iteration 4, loss = 0.56733342\n",
      "Iteration 5, loss = 0.52636226\n",
      "Iteration 6, loss = 0.49702680\n",
      "Iteration 7, loss = 0.50294809\n",
      "Iteration 8, loss = 0.47377427\n",
      "Iteration 9, loss = 0.46516942\n",
      "Iteration 10, loss = 0.46505336\n",
      "Iteration 11, loss = 0.48352708\n",
      "Iteration 12, loss = 0.50776248\n",
      "Iteration 13, loss = 0.48086172\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74022564\n",
      "Iteration 2, loss = 0.59349223\n",
      "Iteration 3, loss = 0.51846741\n",
      "Iteration 4, loss = 0.49141196\n",
      "Iteration 5, loss = 0.49508585\n",
      "Iteration 6, loss = 0.49526373\n",
      "Iteration 7, loss = 0.48034574\n",
      "Iteration 8, loss = 0.46764440\n",
      "Iteration 9, loss = 0.46269582\n",
      "Iteration 10, loss = 0.48251849\n",
      "Iteration 11, loss = 0.47803307\n",
      "Iteration 12, loss = 0.48697502\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75119866\n",
      "Iteration 2, loss = 0.61097183\n",
      "Iteration 3, loss = 0.53579607\n",
      "Iteration 4, loss = 0.49773255\n",
      "Iteration 5, loss = 0.47962935\n",
      "Iteration 6, loss = 0.47490431\n",
      "Iteration 7, loss = 0.50666491\n",
      "Iteration 8, loss = 0.46793071\n",
      "Iteration 9, loss = 0.45815714\n",
      "Iteration 10, loss = 0.46549075\n",
      "Iteration 11, loss = 0.46165252\n",
      "Iteration 12, loss = 0.45701989\n",
      "Iteration 13, loss = 0.47048691\n",
      "Iteration 14, loss = 0.47137871\n",
      "Iteration 15, loss = 0.45220651\n",
      "Iteration 16, loss = 0.46234861\n",
      "Iteration 17, loss = 0.47986536\n",
      "Iteration 18, loss = 0.48215213\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75171088\n",
      "Iteration 2, loss = 0.60198396\n",
      "Iteration 3, loss = 0.54194705\n",
      "Iteration 4, loss = 0.52058773\n",
      "Iteration 5, loss = 0.50687346\n",
      "Iteration 6, loss = 0.48534887\n",
      "Iteration 7, loss = 0.48983929\n",
      "Iteration 8, loss = 0.47090294\n",
      "Iteration 9, loss = 0.47853227\n",
      "Iteration 10, loss = 0.48883975\n",
      "Iteration 11, loss = 0.46484846\n",
      "Iteration 12, loss = 0.46285005\n",
      "Iteration 13, loss = 0.45999245\n",
      "Iteration 14, loss = 0.45506553\n",
      "Iteration 15, loss = 0.45968143\n",
      "Iteration 16, loss = 0.47216654\n",
      "Iteration 17, loss = 0.46612053\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74621359\n",
      "Iteration 2, loss = 0.60548043\n",
      "Iteration 3, loss = 0.52019659\n",
      "Iteration 4, loss = 0.48885415\n",
      "Iteration 5, loss = 0.47503167\n",
      "Iteration 6, loss = 0.48733980\n",
      "Iteration 7, loss = 0.46464241\n",
      "Iteration 8, loss = 0.47043398\n",
      "Iteration 9, loss = 0.46706149\n",
      "Iteration 10, loss = 0.48392455\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71589195\n",
      "Iteration 2, loss = 0.53714032\n",
      "Iteration 3, loss = 0.45846755\n",
      "Iteration 4, loss = 0.43195417\n",
      "Iteration 5, loss = 0.41356546\n",
      "Iteration 6, loss = 0.42762726\n",
      "Iteration 7, loss = 0.43137222\n",
      "Iteration 8, loss = 0.42113865\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76656965\n",
      "Iteration 2, loss = 0.57286979\n",
      "Iteration 3, loss = 0.50541925\n",
      "Iteration 4, loss = 0.45643820\n",
      "Iteration 5, loss = 0.45155129\n",
      "Iteration 6, loss = 0.44837790\n",
      "Iteration 7, loss = 0.42552332\n",
      "Iteration 8, loss = 0.42492558\n",
      "Iteration 9, loss = 0.41774406\n",
      "Iteration 10, loss = 0.42802058\n",
      "Iteration 11, loss = 0.45099522\n",
      "Iteration 12, loss = 0.42719648\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76873688\n",
      "Iteration 2, loss = 0.58491641\n",
      "Iteration 3, loss = 0.51623033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.47343820\n",
      "Iteration 5, loss = 0.47834355\n",
      "Iteration 6, loss = 0.49355322\n",
      "Iteration 7, loss = 0.48341070\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77244853\n",
      "Iteration 2, loss = 0.59358605\n",
      "Iteration 3, loss = 0.52641921\n",
      "Iteration 4, loss = 0.48387029\n",
      "Iteration 5, loss = 0.48246166\n",
      "Iteration 6, loss = 0.47515197\n",
      "Iteration 7, loss = 0.46887561\n",
      "Iteration 8, loss = 0.46429462\n",
      "Iteration 9, loss = 0.47121670\n",
      "Iteration 10, loss = 0.46147402\n",
      "Iteration 11, loss = 0.46146926\n",
      "Iteration 12, loss = 0.45444808\n",
      "Iteration 13, loss = 0.45635966\n",
      "Iteration 14, loss = 0.44607041\n",
      "Iteration 15, loss = 0.44536651\n",
      "Iteration 16, loss = 0.47506500\n",
      "Iteration 17, loss = 0.47164612\n",
      "Iteration 18, loss = 0.44454634\n",
      "Iteration 19, loss = 0.44700104\n",
      "Iteration 20, loss = 0.46865428\n",
      "Iteration 21, loss = 0.45902587\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75037563\n",
      "Iteration 2, loss = 0.56511648\n",
      "Iteration 3, loss = 0.50244478\n",
      "Iteration 4, loss = 0.47343405\n",
      "Iteration 5, loss = 0.47281343\n",
      "Iteration 6, loss = 0.46367044\n",
      "Iteration 7, loss = 0.46009048\n",
      "Iteration 8, loss = 0.47046534\n",
      "Iteration 9, loss = 0.47408312\n",
      "Iteration 10, loss = 0.47619504\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75472954\n",
      "Iteration 2, loss = 0.60368807\n",
      "Iteration 3, loss = 0.54969506\n",
      "Iteration 4, loss = 0.51447743\n",
      "Iteration 5, loss = 0.49606869\n",
      "Iteration 6, loss = 0.47538663\n",
      "Iteration 7, loss = 0.48698635\n",
      "Iteration 8, loss = 0.47132576\n",
      "Iteration 9, loss = 0.46706132\n",
      "Iteration 10, loss = 0.45405772\n",
      "Iteration 11, loss = 0.43741750\n",
      "Iteration 12, loss = 0.43653574\n",
      "Iteration 13, loss = 0.44258727\n",
      "Iteration 14, loss = 0.45515601\n",
      "Iteration 15, loss = 0.45377147\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76974551\n",
      "Iteration 2, loss = 0.56934035\n",
      "Iteration 3, loss = 0.49603250\n",
      "Iteration 4, loss = 0.46774067\n",
      "Iteration 5, loss = 0.49141542\n",
      "Iteration 6, loss = 0.46046614\n",
      "Iteration 7, loss = 0.45193734\n",
      "Iteration 8, loss = 0.45399244\n",
      "Iteration 9, loss = 0.45537145\n",
      "Iteration 10, loss = 0.44046587\n",
      "Iteration 11, loss = 0.44545538\n",
      "Iteration 12, loss = 0.45555312\n",
      "Iteration 13, loss = 0.49527765\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75719137\n",
      "Iteration 2, loss = 0.56913882\n",
      "Iteration 3, loss = 0.50601697\n",
      "Iteration 4, loss = 0.49520287\n",
      "Iteration 5, loss = 0.47708246\n",
      "Iteration 6, loss = 0.49628164\n",
      "Iteration 7, loss = 0.46622419\n",
      "Iteration 8, loss = 0.45918503\n",
      "Iteration 9, loss = 0.45870641\n",
      "Iteration 10, loss = 0.46614161\n",
      "Iteration 11, loss = 0.44909046\n",
      "Iteration 12, loss = 0.45845751\n",
      "Iteration 13, loss = 0.46866256\n",
      "Iteration 14, loss = 0.46768369\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75006708\n",
      "Iteration 2, loss = 0.58028378\n",
      "Iteration 3, loss = 0.53343064\n",
      "Iteration 4, loss = 0.48462525\n",
      "Iteration 5, loss = 0.48978611\n",
      "Iteration 6, loss = 0.50152729\n",
      "Iteration 7, loss = 0.47562448\n",
      "Iteration 8, loss = 0.45648704\n",
      "Iteration 9, loss = 0.45991098\n",
      "Iteration 10, loss = 0.46421953\n",
      "Iteration 11, loss = 0.44892335\n",
      "Iteration 12, loss = 0.43864929\n",
      "Iteration 13, loss = 0.46517399\n",
      "Iteration 14, loss = 0.50059786\n",
      "Iteration 15, loss = 0.49418492\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76518297\n",
      "Iteration 2, loss = 0.60663577\n",
      "Iteration 3, loss = 0.52692420\n",
      "Iteration 4, loss = 0.48897874\n",
      "Iteration 5, loss = 0.46345055\n",
      "Iteration 6, loss = 0.48177734\n",
      "Iteration 7, loss = 0.47935233\n",
      "Iteration 8, loss = 0.45994849\n",
      "Iteration 9, loss = 0.45909742\n",
      "Iteration 10, loss = 0.46056147\n",
      "Iteration 11, loss = 0.45111592\n",
      "Iteration 12, loss = 0.45361087\n",
      "Iteration 13, loss = 0.44335307\n",
      "Iteration 14, loss = 0.45163348\n",
      "Iteration 15, loss = 0.45986938\n",
      "Iteration 16, loss = 0.47444243\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76720662\n",
      "Iteration 2, loss = 0.61705085\n",
      "Iteration 3, loss = 0.51590782\n",
      "Iteration 4, loss = 0.45518595\n",
      "Iteration 5, loss = 0.42190505\n",
      "Iteration 6, loss = 0.43670137\n",
      "Iteration 7, loss = 0.42860204\n",
      "Iteration 8, loss = 0.42650466\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75647964\n",
      "Iteration 2, loss = 0.63687579\n",
      "Iteration 3, loss = 0.57480918\n",
      "Iteration 4, loss = 0.51664433\n",
      "Iteration 5, loss = 0.49187346\n",
      "Iteration 6, loss = 0.47066181\n",
      "Iteration 7, loss = 0.45812309\n",
      "Iteration 8, loss = 0.44424617\n",
      "Iteration 9, loss = 0.46313199\n",
      "Iteration 10, loss = 0.46715081\n",
      "Iteration 11, loss = 0.47246762\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76581191\n",
      "Iteration 2, loss = 0.64548540\n",
      "Iteration 3, loss = 0.59325086\n",
      "Iteration 4, loss = 0.53332955\n",
      "Iteration 5, loss = 0.50547084\n",
      "Iteration 6, loss = 0.48487523\n",
      "Iteration 7, loss = 0.51973231\n",
      "Iteration 8, loss = 0.47111493\n",
      "Iteration 9, loss = 0.47628364\n",
      "Iteration 10, loss = 0.47709958\n",
      "Iteration 11, loss = 0.44936386\n",
      "Iteration 12, loss = 0.47021919\n",
      "Iteration 13, loss = 0.46387908\n",
      "Iteration 14, loss = 0.45081208\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76018330\n",
      "Iteration 2, loss = 0.62874698\n",
      "Iteration 3, loss = 0.58361600\n",
      "Iteration 4, loss = 0.51304858\n",
      "Iteration 5, loss = 0.47652522\n",
      "Iteration 6, loss = 0.46992072\n",
      "Iteration 7, loss = 0.46591959\n",
      "Iteration 8, loss = 0.45527807\n",
      "Iteration 9, loss = 0.47483400\n",
      "Iteration 10, loss = 0.48055763\n",
      "Iteration 11, loss = 0.47530998\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78007294\n",
      "Iteration 2, loss = 0.67488642\n",
      "Iteration 3, loss = 0.64274082\n",
      "Iteration 4, loss = 0.61169414\n",
      "Iteration 5, loss = 0.56752271\n",
      "Iteration 6, loss = 0.54732300\n",
      "Iteration 7, loss = 0.52927360\n",
      "Iteration 8, loss = 0.49911887\n",
      "Iteration 9, loss = 0.49694889\n",
      "Iteration 10, loss = 0.48055982\n",
      "Iteration 11, loss = 0.48548932\n",
      "Iteration 12, loss = 0.47950197\n",
      "Iteration 13, loss = 0.51060834\n",
      "Iteration 14, loss = 0.49799888\n",
      "Iteration 15, loss = 0.52105132\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74987760\n",
      "Iteration 2, loss = 0.64836304\n",
      "Iteration 3, loss = 0.58861633\n",
      "Iteration 4, loss = 0.52454963\n",
      "Iteration 5, loss = 0.50880511\n",
      "Iteration 6, loss = 0.47704650\n",
      "Iteration 7, loss = 0.48168836\n",
      "Iteration 8, loss = 0.45584952\n",
      "Iteration 9, loss = 0.46876264\n",
      "Iteration 10, loss = 0.50104594\n",
      "Iteration 11, loss = 0.47657833\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76493127\n",
      "Iteration 2, loss = 0.63105001\n",
      "Iteration 3, loss = 0.55646229\n",
      "Iteration 4, loss = 0.51181036\n",
      "Iteration 5, loss = 0.47822068\n",
      "Iteration 6, loss = 0.46512965\n",
      "Iteration 7, loss = 0.48052020\n",
      "Iteration 8, loss = 0.49588970\n",
      "Iteration 9, loss = 0.49029125\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76298797\n",
      "Iteration 2, loss = 0.64282599\n",
      "Iteration 3, loss = 0.59120333\n",
      "Iteration 4, loss = 0.53475280\n",
      "Iteration 5, loss = 0.51046016\n",
      "Iteration 6, loss = 0.49422674\n",
      "Iteration 7, loss = 0.49541599\n",
      "Iteration 8, loss = 0.47048090\n",
      "Iteration 9, loss = 0.48843163\n",
      "Iteration 10, loss = 0.47047010\n",
      "Iteration 11, loss = 0.46179068\n",
      "Iteration 12, loss = 0.46511452\n",
      "Iteration 13, loss = 0.44617292\n",
      "Iteration 14, loss = 0.46840271\n",
      "Iteration 15, loss = 0.49398659\n",
      "Iteration 16, loss = 0.48413050\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75903905\n",
      "Iteration 2, loss = 0.65742335\n",
      "Iteration 3, loss = 0.59327530\n",
      "Iteration 4, loss = 0.53482681\n",
      "Iteration 5, loss = 0.52078239\n",
      "Iteration 6, loss = 0.48787532\n",
      "Iteration 7, loss = 0.51003555\n",
      "Iteration 8, loss = 0.51283027\n",
      "Iteration 9, loss = 0.45770850\n",
      "Iteration 10, loss = 0.44423827\n",
      "Iteration 11, loss = 0.45962591\n",
      "Iteration 12, loss = 0.44723323\n",
      "Iteration 13, loss = 0.44153663\n",
      "Iteration 14, loss = 0.45056033\n",
      "Iteration 15, loss = 0.44350900\n",
      "Iteration 16, loss = 0.44794483\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75725768\n",
      "Iteration 2, loss = 0.60045578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.54448136\n",
      "Iteration 4, loss = 0.51677436\n",
      "Iteration 5, loss = 0.50846306\n",
      "Iteration 6, loss = 0.47735529\n",
      "Iteration 7, loss = 0.48306826\n",
      "Iteration 8, loss = 0.49328012\n",
      "Iteration 9, loss = 0.48945611\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75177106\n",
      "Iteration 2, loss = 0.61457855\n",
      "Iteration 3, loss = 0.53898187\n",
      "Iteration 4, loss = 0.50128228\n",
      "Iteration 5, loss = 0.46850583\n",
      "Iteration 6, loss = 0.45401820\n",
      "Iteration 7, loss = 0.43930936\n",
      "Iteration 8, loss = 0.43325256\n",
      "Iteration 9, loss = 0.44729522\n",
      "Iteration 10, loss = 0.44895511\n",
      "Iteration 11, loss = 0.44011559\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83339777\n",
      "Iteration 2, loss = 0.59959597\n",
      "Iteration 3, loss = 0.50434130\n",
      "Iteration 4, loss = 0.50484608\n",
      "Iteration 5, loss = 0.47149861\n",
      "Iteration 6, loss = 0.44911697\n",
      "Iteration 7, loss = 0.44523059\n",
      "Iteration 8, loss = 0.46380314\n",
      "Iteration 9, loss = 0.43295430\n",
      "Iteration 10, loss = 0.44030229\n",
      "Iteration 11, loss = 0.47401236\n",
      "Iteration 12, loss = 0.46116735\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86347627\n",
      "Iteration 2, loss = 0.64212692\n",
      "Iteration 3, loss = 0.55859714\n",
      "Iteration 4, loss = 0.51069064\n",
      "Iteration 5, loss = 0.50669731\n",
      "Iteration 6, loss = 0.48818119\n",
      "Iteration 7, loss = 0.45747984\n",
      "Iteration 8, loss = 0.46164145\n",
      "Iteration 9, loss = 0.48040698\n",
      "Iteration 10, loss = 0.47301677\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84261345\n",
      "Iteration 2, loss = 0.66950405\n",
      "Iteration 3, loss = 0.59790802\n",
      "Iteration 4, loss = 0.54019647\n",
      "Iteration 5, loss = 0.49633758\n",
      "Iteration 6, loss = 0.46637675\n",
      "Iteration 7, loss = 0.45535447\n",
      "Iteration 8, loss = 0.46229509\n",
      "Iteration 9, loss = 0.48151495\n",
      "Iteration 10, loss = 0.49020360\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87105727\n",
      "Iteration 2, loss = 0.65154124\n",
      "Iteration 3, loss = 0.55592526\n",
      "Iteration 4, loss = 0.50059423\n",
      "Iteration 5, loss = 0.45739916\n",
      "Iteration 6, loss = 0.44871699\n",
      "Iteration 7, loss = 0.45128676\n",
      "Iteration 8, loss = 0.45640938\n",
      "Iteration 9, loss = 0.47495771\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86937153\n",
      "Iteration 2, loss = 0.69678898\n",
      "Iteration 3, loss = 0.68757174\n",
      "Iteration 4, loss = 0.64071740\n",
      "Iteration 5, loss = 0.60178225\n",
      "Iteration 6, loss = 0.58098099\n",
      "Iteration 7, loss = 0.54580005\n",
      "Iteration 8, loss = 0.53000800\n",
      "Iteration 9, loss = 0.50409191\n",
      "Iteration 10, loss = 0.54230467\n",
      "Iteration 11, loss = 0.48520069\n",
      "Iteration 12, loss = 0.46479564\n",
      "Iteration 13, loss = 0.47747675\n",
      "Iteration 14, loss = 0.47771943\n",
      "Iteration 15, loss = 0.46975103\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88627428\n",
      "Iteration 2, loss = 0.66503975\n",
      "Iteration 3, loss = 0.59658789\n",
      "Iteration 4, loss = 0.57913434\n",
      "Iteration 5, loss = 0.53300426\n",
      "Iteration 6, loss = 0.49831403\n",
      "Iteration 7, loss = 0.50936188\n",
      "Iteration 8, loss = 0.50234950\n",
      "Iteration 9, loss = 0.50067049\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85426459\n",
      "Iteration 2, loss = 0.62692343\n",
      "Iteration 3, loss = 0.55446720\n",
      "Iteration 4, loss = 0.50869595\n",
      "Iteration 5, loss = 0.48351200\n",
      "Iteration 6, loss = 0.47334026\n",
      "Iteration 7, loss = 0.48518583\n",
      "Iteration 8, loss = 0.48896177\n",
      "Iteration 9, loss = 0.48562640\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89829849\n",
      "Iteration 2, loss = 0.67625518\n",
      "Iteration 3, loss = 0.60430853\n",
      "Iteration 4, loss = 0.55095161\n",
      "Iteration 5, loss = 0.52045670\n",
      "Iteration 6, loss = 0.49418282\n",
      "Iteration 7, loss = 0.48461188\n",
      "Iteration 8, loss = 0.46736049\n",
      "Iteration 9, loss = 0.46490183\n",
      "Iteration 10, loss = 0.47012435\n",
      "Iteration 11, loss = 0.49604084\n",
      "Iteration 12, loss = 0.49064904\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85772283\n",
      "Iteration 2, loss = 0.67743244\n",
      "Iteration 3, loss = 0.62404062\n",
      "Iteration 4, loss = 0.58576990\n",
      "Iteration 5, loss = 0.54163663\n",
      "Iteration 6, loss = 0.51503164\n",
      "Iteration 7, loss = 0.51927305\n",
      "Iteration 8, loss = 0.50570281\n",
      "Iteration 9, loss = 0.51621807\n",
      "Iteration 10, loss = 0.48800543\n",
      "Iteration 11, loss = 0.47152279\n",
      "Iteration 12, loss = 0.48104876\n",
      "Iteration 13, loss = 0.49740709\n",
      "Iteration 14, loss = 0.50019088\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87156678\n",
      "Iteration 2, loss = 0.64189796\n",
      "Iteration 3, loss = 0.57351991\n",
      "Iteration 4, loss = 0.49978028\n",
      "Iteration 5, loss = 0.46175036\n",
      "Iteration 6, loss = 0.43452741\n",
      "Iteration 7, loss = 0.44256576\n",
      "Iteration 8, loss = 0.42933559\n",
      "Iteration 9, loss = 0.44593957\n",
      "Iteration 10, loss = 0.44628606\n",
      "Iteration 11, loss = 0.43930634\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80264372\n",
      "Iteration 2, loss = 0.60305580\n",
      "Iteration 3, loss = 0.52895339\n",
      "Iteration 4, loss = 0.50087461\n",
      "Iteration 5, loss = 0.48320322\n",
      "Iteration 6, loss = 0.46398114\n",
      "Iteration 7, loss = 0.46442656\n",
      "Iteration 8, loss = 0.45393513\n",
      "Iteration 9, loss = 0.44437716\n",
      "Iteration 10, loss = 0.44697695\n",
      "Iteration 11, loss = 0.44996511\n",
      "Iteration 12, loss = 0.45688777\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80221721\n",
      "Iteration 2, loss = 0.61646575\n",
      "Iteration 3, loss = 0.53361946\n",
      "Iteration 4, loss = 0.49684247\n",
      "Iteration 5, loss = 0.48649872\n",
      "Iteration 6, loss = 0.48591656\n",
      "Iteration 7, loss = 0.48917982\n",
      "Iteration 8, loss = 0.45656066\n",
      "Iteration 9, loss = 0.47254618\n",
      "Iteration 10, loss = 0.47665246\n",
      "Iteration 11, loss = 0.46255268\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80154121\n",
      "Iteration 2, loss = 0.61805361\n",
      "Iteration 3, loss = 0.56051012\n",
      "Iteration 4, loss = 0.53776821\n",
      "Iteration 5, loss = 0.48768327\n",
      "Iteration 6, loss = 0.47234305\n",
      "Iteration 7, loss = 0.47405185\n",
      "Iteration 8, loss = 0.47118297\n",
      "Iteration 9, loss = 0.47010809\n",
      "Iteration 10, loss = 0.46836527\n",
      "Iteration 11, loss = 0.48350456\n",
      "Iteration 12, loss = 0.49104364\n",
      "Iteration 13, loss = 0.49984037\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80047842\n",
      "Iteration 2, loss = 0.58295857\n",
      "Iteration 3, loss = 0.53575120\n",
      "Iteration 4, loss = 0.50139741\n",
      "Iteration 5, loss = 0.50477656\n",
      "Iteration 6, loss = 0.48399255\n",
      "Iteration 7, loss = 0.47780106\n",
      "Iteration 8, loss = 0.45309165\n",
      "Iteration 9, loss = 0.46318752\n",
      "Iteration 10, loss = 0.47444167\n",
      "Iteration 11, loss = 0.47877856\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78494529\n",
      "Iteration 2, loss = 0.60060526\n",
      "Iteration 3, loss = 0.53748294\n",
      "Iteration 4, loss = 0.51003342\n",
      "Iteration 5, loss = 0.50146960\n",
      "Iteration 6, loss = 0.47989584\n",
      "Iteration 7, loss = 0.45393504\n",
      "Iteration 8, loss = 0.45419689\n",
      "Iteration 9, loss = 0.45898430\n",
      "Iteration 10, loss = 0.45309886\n",
      "Iteration 11, loss = 0.44378071\n",
      "Iteration 12, loss = 0.49444392\n",
      "Iteration 13, loss = 0.48356025\n",
      "Iteration 14, loss = 0.47015740\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82031344\n",
      "Iteration 2, loss = 0.63690194\n",
      "Iteration 3, loss = 0.57474407\n",
      "Iteration 4, loss = 0.52553594\n",
      "Iteration 5, loss = 0.48766414\n",
      "Iteration 6, loss = 0.49149653\n",
      "Iteration 7, loss = 0.49990400\n",
      "Iteration 8, loss = 0.49932383\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81987214\n",
      "Iteration 2, loss = 0.61349764\n",
      "Iteration 3, loss = 0.55803951\n",
      "Iteration 4, loss = 0.51626035\n",
      "Iteration 5, loss = 0.50741701\n",
      "Iteration 6, loss = 0.52350436\n",
      "Iteration 7, loss = 0.50539015\n",
      "Iteration 8, loss = 0.51542440\n",
      "Iteration 9, loss = 0.49509567\n",
      "Iteration 10, loss = 0.49048430\n",
      "Iteration 11, loss = 0.49532750\n",
      "Iteration 12, loss = 0.49891649\n",
      "Iteration 13, loss = 0.49716170\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81509828\n",
      "Iteration 2, loss = 0.61575762\n",
      "Iteration 3, loss = 0.56630953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.51583383\n",
      "Iteration 5, loss = 0.48023317\n",
      "Iteration 6, loss = 0.51647506\n",
      "Iteration 7, loss = 0.50081315\n",
      "Iteration 8, loss = 0.49851736\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84019791\n",
      "Iteration 2, loss = 0.61239544\n",
      "Iteration 3, loss = 0.56554612\n",
      "Iteration 4, loss = 0.53109145\n",
      "Iteration 5, loss = 0.51130918\n",
      "Iteration 6, loss = 0.50566336\n",
      "Iteration 7, loss = 0.48130586\n",
      "Iteration 8, loss = 0.48968090\n",
      "Iteration 9, loss = 0.49301905\n",
      "Iteration 10, loss = 0.47027445\n",
      "Iteration 11, loss = 0.47608179\n",
      "Iteration 12, loss = 0.48666763\n",
      "Iteration 13, loss = 0.47880048\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79234502\n",
      "Iteration 2, loss = 0.55058385\n",
      "Iteration 3, loss = 0.47980345\n",
      "Iteration 4, loss = 0.46281989\n",
      "Iteration 5, loss = 0.43161423\n",
      "Iteration 6, loss = 0.42282862\n",
      "Iteration 7, loss = 0.42250263\n",
      "Iteration 8, loss = 0.44360871\n",
      "Iteration 9, loss = 0.40696091\n",
      "Iteration 10, loss = 0.41123738\n",
      "Iteration 11, loss = 0.42679226\n",
      "Iteration 12, loss = 0.45179973\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81544333\n",
      "Iteration 2, loss = 0.62399367\n",
      "Iteration 3, loss = 0.56823576\n",
      "Iteration 4, loss = 0.49645000\n",
      "Iteration 5, loss = 0.46590125\n",
      "Iteration 6, loss = 0.44477044\n",
      "Iteration 7, loss = 0.44659035\n",
      "Iteration 8, loss = 0.47094112\n",
      "Iteration 9, loss = 0.43501187\n",
      "Iteration 10, loss = 0.45841703\n",
      "Iteration 11, loss = 0.43833049\n",
      "Iteration 12, loss = 0.45774779\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80729711\n",
      "Iteration 2, loss = 0.64098962\n",
      "Iteration 3, loss = 0.57790287\n",
      "Iteration 4, loss = 0.52395567\n",
      "Iteration 5, loss = 0.48247172\n",
      "Iteration 6, loss = 0.46459626\n",
      "Iteration 7, loss = 0.44900973\n",
      "Iteration 8, loss = 0.45836842\n",
      "Iteration 9, loss = 0.46756203\n",
      "Iteration 10, loss = 0.47262759\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79321307\n",
      "Iteration 2, loss = 0.60019771\n",
      "Iteration 3, loss = 0.52196122\n",
      "Iteration 4, loss = 0.49507114\n",
      "Iteration 5, loss = 0.48216137\n",
      "Iteration 6, loss = 0.46437571\n",
      "Iteration 7, loss = 0.45042481\n",
      "Iteration 8, loss = 0.47463956\n",
      "Iteration 9, loss = 0.46905091\n",
      "Iteration 10, loss = 0.44234373\n",
      "Iteration 11, loss = 0.44174168\n",
      "Iteration 12, loss = 0.47039758\n",
      "Iteration 13, loss = 0.48161972\n",
      "Iteration 14, loss = 0.46534642\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81812214\n",
      "Iteration 2, loss = 0.63589836\n",
      "Iteration 3, loss = 0.55825553\n",
      "Iteration 4, loss = 0.49524220\n",
      "Iteration 5, loss = 0.46971975\n",
      "Iteration 6, loss = 0.46419686\n",
      "Iteration 7, loss = 0.45446205\n",
      "Iteration 8, loss = 0.45589817\n",
      "Iteration 9, loss = 0.45480474\n",
      "Iteration 10, loss = 0.43977199\n",
      "Iteration 11, loss = 0.44749397\n",
      "Iteration 12, loss = 0.46334091\n",
      "Iteration 13, loss = 0.46171729\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81824756\n",
      "Iteration 2, loss = 0.63403592\n",
      "Iteration 3, loss = 0.57732176\n",
      "Iteration 4, loss = 0.53114704\n",
      "Iteration 5, loss = 0.49282008\n",
      "Iteration 6, loss = 0.47670162\n",
      "Iteration 7, loss = 0.45743082\n",
      "Iteration 8, loss = 0.44180711\n",
      "Iteration 9, loss = 0.43440361\n",
      "Iteration 10, loss = 0.44039078\n",
      "Iteration 11, loss = 0.44761760\n",
      "Iteration 12, loss = 0.45516669\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80788624\n",
      "Iteration 2, loss = 0.65226124\n",
      "Iteration 3, loss = 0.57769193\n",
      "Iteration 4, loss = 0.53899166\n",
      "Iteration 5, loss = 0.50775308\n",
      "Iteration 6, loss = 0.51320474\n",
      "Iteration 7, loss = 0.50304920\n",
      "Iteration 8, loss = 0.50363913\n",
      "Iteration 9, loss = 0.48172077\n",
      "Iteration 10, loss = 0.46838684\n",
      "Iteration 11, loss = 0.47115238\n",
      "Iteration 12, loss = 0.47642030\n",
      "Iteration 13, loss = 0.47449370\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81638861\n",
      "Iteration 2, loss = 0.62562933\n",
      "Iteration 3, loss = 0.54639880\n",
      "Iteration 4, loss = 0.50366983\n",
      "Iteration 5, loss = 0.50809200\n",
      "Iteration 6, loss = 0.47906315\n",
      "Iteration 7, loss = 0.47012318\n",
      "Iteration 8, loss = 0.46099112\n",
      "Iteration 9, loss = 0.48396625\n",
      "Iteration 10, loss = 0.46685832\n",
      "Iteration 11, loss = 0.48379980\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80113433\n",
      "Iteration 2, loss = 0.63221991\n",
      "Iteration 3, loss = 0.58313635\n",
      "Iteration 4, loss = 0.55380855\n",
      "Iteration 5, loss = 0.50844511\n",
      "Iteration 6, loss = 0.48995514\n",
      "Iteration 7, loss = 0.48742562\n",
      "Iteration 8, loss = 0.46036635\n",
      "Iteration 9, loss = 0.46222533\n",
      "Iteration 10, loss = 0.44953340\n",
      "Iteration 11, loss = 0.44122682\n",
      "Iteration 12, loss = 0.45118350\n",
      "Iteration 13, loss = 0.45370916\n",
      "Iteration 14, loss = 0.45091193\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82170529\n",
      "Iteration 2, loss = 0.61963433\n",
      "Iteration 3, loss = 0.54879009\n",
      "Iteration 4, loss = 0.50925546\n",
      "Iteration 5, loss = 0.48975961\n",
      "Iteration 6, loss = 0.51403232\n",
      "Iteration 7, loss = 0.50124923\n",
      "Iteration 8, loss = 0.49140499\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81589574\n",
      "Iteration 2, loss = 0.62000021\n",
      "Iteration 3, loss = 0.58122483\n",
      "Iteration 4, loss = 0.52761699\n",
      "Iteration 5, loss = 0.49532395\n",
      "Iteration 6, loss = 0.49276590\n",
      "Iteration 7, loss = 0.45072184\n",
      "Iteration 8, loss = 0.42970599\n",
      "Iteration 9, loss = 0.45135165\n",
      "Iteration 10, loss = 0.42224705\n",
      "Iteration 11, loss = 0.42007764\n",
      "Iteration 12, loss = 0.42617331\n",
      "Iteration 13, loss = 0.41539804\n",
      "Iteration 14, loss = 0.41717589\n",
      "Iteration 15, loss = 0.40711531\n",
      "Iteration 16, loss = 0.40185085\n",
      "Iteration 17, loss = 0.38997482\n",
      "Iteration 18, loss = 0.41387167\n",
      "Iteration 19, loss = 0.43579720\n",
      "Iteration 20, loss = 0.46942062\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80838259\n",
      "Iteration 2, loss = 0.64575904\n",
      "Iteration 3, loss = 0.55108322\n",
      "Iteration 4, loss = 0.51262545\n",
      "Iteration 5, loss = 0.46634440\n",
      "Iteration 6, loss = 0.44840678\n",
      "Iteration 7, loss = 0.43729972\n",
      "Iteration 8, loss = 0.45557962\n",
      "Iteration 9, loss = 0.45285654\n",
      "Iteration 10, loss = 0.45817883\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81028691\n",
      "Iteration 2, loss = 0.64768377\n",
      "Iteration 3, loss = 0.57910921\n",
      "Iteration 4, loss = 0.51812649\n",
      "Iteration 5, loss = 0.49622750\n",
      "Iteration 6, loss = 0.47437665\n",
      "Iteration 7, loss = 0.46496732\n",
      "Iteration 8, loss = 0.46174708\n",
      "Iteration 9, loss = 0.48041062\n",
      "Iteration 10, loss = 0.46767934\n",
      "Iteration 11, loss = 0.46731968\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80944991\n",
      "Iteration 2, loss = 0.62443310\n",
      "Iteration 3, loss = 0.54112161\n",
      "Iteration 4, loss = 0.49395889\n",
      "Iteration 5, loss = 0.48342749\n",
      "Iteration 6, loss = 0.47028467\n",
      "Iteration 7, loss = 0.46200946\n",
      "Iteration 8, loss = 0.47009586\n",
      "Iteration 9, loss = 0.46912937\n",
      "Iteration 10, loss = 0.46269856\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83681308\n",
      "Iteration 2, loss = 0.64347809\n",
      "Iteration 3, loss = 0.57468145\n",
      "Iteration 4, loss = 0.51535052\n",
      "Iteration 5, loss = 0.49694021\n",
      "Iteration 6, loss = 0.47358952\n",
      "Iteration 7, loss = 0.49470630\n",
      "Iteration 8, loss = 0.50000710\n",
      "Iteration 9, loss = 0.50642711\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82527025\n",
      "Iteration 2, loss = 0.62747461\n",
      "Iteration 3, loss = 0.54464785\n",
      "Iteration 4, loss = 0.52139422\n",
      "Iteration 5, loss = 0.50175508\n",
      "Iteration 6, loss = 0.47749208\n",
      "Iteration 7, loss = 0.46159880\n",
      "Iteration 8, loss = 0.43624861\n",
      "Iteration 9, loss = 0.46635923\n",
      "Iteration 10, loss = 0.46475215\n",
      "Iteration 11, loss = 0.47866678\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83245484\n",
      "Iteration 2, loss = 0.65783777\n",
      "Iteration 3, loss = 0.59608893\n",
      "Iteration 4, loss = 0.56039143\n",
      "Iteration 5, loss = 0.52685478\n",
      "Iteration 6, loss = 0.52013088\n",
      "Iteration 7, loss = 0.51769359\n",
      "Iteration 8, loss = 0.52112090\n",
      "Iteration 9, loss = 0.48246235\n",
      "Iteration 10, loss = 0.50224302\n",
      "Iteration 11, loss = 0.49017642\n",
      "Iteration 12, loss = 0.52014429\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.84377080\n",
      "Iteration 2, loss = 0.68797257\n",
      "Iteration 3, loss = 0.63680393\n",
      "Iteration 4, loss = 0.58245913\n",
      "Iteration 5, loss = 0.51963091\n",
      "Iteration 6, loss = 0.48935017\n",
      "Iteration 7, loss = 0.49321598\n",
      "Iteration 8, loss = 0.48752236\n",
      "Iteration 9, loss = 0.46765936\n",
      "Iteration 10, loss = 0.49127335\n",
      "Iteration 11, loss = 0.49454072\n",
      "Iteration 12, loss = 0.48081422\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82470224\n",
      "Iteration 2, loss = 0.63472383\n",
      "Iteration 3, loss = 0.57004384\n",
      "Iteration 4, loss = 0.52068373\n",
      "Iteration 5, loss = 0.49704921\n",
      "Iteration 6, loss = 0.49748968\n",
      "Iteration 7, loss = 0.48757059\n",
      "Iteration 8, loss = 0.48307942\n",
      "Iteration 9, loss = 0.50273384\n",
      "Iteration 10, loss = 0.50995365\n",
      "Iteration 11, loss = 0.48186340\n",
      "Iteration 12, loss = 0.47819963\n",
      "Iteration 13, loss = 0.48985991\n",
      "Iteration 14, loss = 0.50814147\n",
      "Iteration 15, loss = 0.51736453\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83059814\n",
      "Iteration 2, loss = 0.67715211\n",
      "Iteration 3, loss = 0.61147844\n",
      "Iteration 4, loss = 0.56261469\n",
      "Iteration 5, loss = 0.51545606\n",
      "Iteration 6, loss = 0.51424739\n",
      "Iteration 7, loss = 0.49431147\n",
      "Iteration 8, loss = 0.49465497\n",
      "Iteration 9, loss = 0.48947284\n",
      "Iteration 10, loss = 0.47418812\n",
      "Iteration 11, loss = 0.47353243\n",
      "Iteration 12, loss = 0.46774222\n",
      "Iteration 13, loss = 0.47037418\n",
      "Iteration 14, loss = 0.48168470\n",
      "Iteration 15, loss = 0.48077640\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83116168\n",
      "Iteration 2, loss = 0.64839957\n",
      "Iteration 3, loss = 0.56909587\n",
      "Iteration 4, loss = 0.50152231\n",
      "Iteration 5, loss = 0.48562611\n",
      "Iteration 6, loss = 0.47174658\n",
      "Iteration 7, loss = 0.46776329\n",
      "Iteration 8, loss = 0.45441525\n",
      "Iteration 9, loss = 0.48243994\n",
      "Iteration 10, loss = 0.46221952\n",
      "Iteration 11, loss = 0.45970853\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78478902\n",
      "Iteration 2, loss = 0.62540608\n",
      "Iteration 3, loss = 0.55778486\n",
      "Iteration 4, loss = 0.51445348\n",
      "Iteration 5, loss = 0.48121618\n",
      "Iteration 6, loss = 0.46927866\n",
      "Iteration 7, loss = 0.46872890\n",
      "Iteration 8, loss = 0.48863512\n",
      "Iteration 9, loss = 0.47505164\n",
      "Iteration 10, loss = 0.45325114\n",
      "Iteration 11, loss = 0.45358130\n",
      "Iteration 12, loss = 0.45379576\n",
      "Iteration 13, loss = 0.45511761\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79301650\n",
      "Iteration 2, loss = 0.60824834\n",
      "Iteration 3, loss = 0.54581958\n",
      "Iteration 4, loss = 0.52141828\n",
      "Iteration 5, loss = 0.51287945\n",
      "Iteration 6, loss = 0.46800953\n",
      "Iteration 7, loss = 0.49090842\n",
      "Iteration 8, loss = 0.50521109\n",
      "Iteration 9, loss = 0.46592029\n",
      "Iteration 10, loss = 0.45627046\n",
      "Iteration 11, loss = 0.45567560\n",
      "Iteration 12, loss = 0.47368855\n",
      "Iteration 13, loss = 0.46639987\n",
      "Iteration 14, loss = 0.50181622\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78457679\n",
      "Iteration 2, loss = 0.61296360\n",
      "Iteration 3, loss = 0.53825811\n",
      "Iteration 4, loss = 0.50216825\n",
      "Iteration 5, loss = 0.50241496\n",
      "Iteration 6, loss = 0.47666355\n",
      "Iteration 7, loss = 0.47734075\n",
      "Iteration 8, loss = 0.46894506\n",
      "Iteration 9, loss = 0.46363233\n",
      "Iteration 10, loss = 0.45307758\n",
      "Iteration 11, loss = 0.46104712\n",
      "Iteration 12, loss = 0.43648336\n",
      "Iteration 13, loss = 0.44819758\n",
      "Iteration 14, loss = 0.44696442\n",
      "Iteration 15, loss = 0.43814372\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80775366\n",
      "Iteration 2, loss = 0.67925764\n",
      "Iteration 3, loss = 0.58153929\n",
      "Iteration 4, loss = 0.52449829\n",
      "Iteration 5, loss = 0.51293641\n",
      "Iteration 6, loss = 0.48728416\n",
      "Iteration 7, loss = 0.46731115\n",
      "Iteration 8, loss = 0.45833079\n",
      "Iteration 9, loss = 0.44924134\n",
      "Iteration 10, loss = 0.47418765\n",
      "Iteration 11, loss = 0.47467481\n",
      "Iteration 12, loss = 0.48249497\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80895840\n",
      "Iteration 2, loss = 0.66250045\n",
      "Iteration 3, loss = 0.57170753\n",
      "Iteration 4, loss = 0.51475650\n",
      "Iteration 5, loss = 0.50016037\n",
      "Iteration 6, loss = 0.49912189\n",
      "Iteration 7, loss = 0.50369687\n",
      "Iteration 8, loss = 0.50396035\n",
      "Iteration 9, loss = 0.46848443\n",
      "Iteration 10, loss = 0.47348330\n",
      "Iteration 11, loss = 0.47422518\n",
      "Iteration 12, loss = 0.46374012\n",
      "Iteration 13, loss = 0.47318906\n",
      "Iteration 14, loss = 0.47038510\n",
      "Iteration 15, loss = 0.48391314\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83680454\n",
      "Iteration 2, loss = 0.70072836\n",
      "Iteration 3, loss = 0.65378710\n",
      "Iteration 4, loss = 0.58802475\n",
      "Iteration 5, loss = 0.55284369\n",
      "Iteration 6, loss = 0.52885924\n",
      "Iteration 7, loss = 0.52464245\n",
      "Iteration 8, loss = 0.51020862\n",
      "Iteration 9, loss = 0.50578073\n",
      "Iteration 10, loss = 0.48707020\n",
      "Iteration 11, loss = 0.51234769\n",
      "Iteration 12, loss = 0.49491202\n",
      "Iteration 13, loss = 0.49220085\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83832562\n",
      "Iteration 2, loss = 0.68610137\n",
      "Iteration 3, loss = 0.63688337\n",
      "Iteration 4, loss = 0.57941394\n",
      "Iteration 5, loss = 0.54966791\n",
      "Iteration 6, loss = 0.51069555\n",
      "Iteration 7, loss = 0.50969571\n",
      "Iteration 8, loss = 0.51477852\n",
      "Iteration 9, loss = 0.49258798\n",
      "Iteration 10, loss = 0.49581958\n",
      "Iteration 11, loss = 0.47097737\n",
      "Iteration 12, loss = 0.51253286\n",
      "Iteration 13, loss = 0.51161222\n",
      "Iteration 14, loss = 0.49506398\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82783845\n",
      "Iteration 2, loss = 0.65908768\n",
      "Iteration 3, loss = 0.58632080\n",
      "Iteration 4, loss = 0.54252738\n",
      "Iteration 5, loss = 0.53930019\n",
      "Iteration 6, loss = 0.49718555\n",
      "Iteration 7, loss = 0.49479853\n",
      "Iteration 8, loss = 0.49545037\n",
      "Iteration 9, loss = 0.48012209\n",
      "Iteration 10, loss = 0.47187500\n",
      "Iteration 11, loss = 0.46195166\n",
      "Iteration 12, loss = 0.45164552\n",
      "Iteration 13, loss = 0.46757499\n",
      "Iteration 14, loss = 0.49838092\n",
      "Iteration 15, loss = 0.48862241\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83594010\n",
      "Iteration 2, loss = 0.65373584\n",
      "Iteration 3, loss = 0.59300012\n",
      "Iteration 4, loss = 0.52903482\n",
      "Iteration 5, loss = 0.50990433\n",
      "Iteration 6, loss = 0.51690113\n",
      "Iteration 7, loss = 0.51610922\n",
      "Iteration 8, loss = 0.52224755\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82137454\n",
      "Iteration 2, loss = 0.63709938\n",
      "Iteration 3, loss = 0.56915715\n",
      "Iteration 4, loss = 0.52180864\n",
      "Iteration 5, loss = 0.46596505\n",
      "Iteration 6, loss = 0.43873115\n",
      "Iteration 7, loss = 0.43478497\n",
      "Iteration 8, loss = 0.43160780\n",
      "Iteration 9, loss = 0.43515289\n",
      "Iteration 10, loss = 0.44458150\n",
      "Iteration 11, loss = 0.42533670\n",
      "Iteration 12, loss = 0.42284637\n",
      "Iteration 13, loss = 0.44148965\n",
      "Iteration 14, loss = 0.40530331\n",
      "Iteration 15, loss = 0.43670153\n",
      "Iteration 16, loss = 0.43104716\n",
      "Iteration 17, loss = 0.45761321\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76530722\n",
      "Iteration 2, loss = 0.62282287\n",
      "Iteration 3, loss = 0.55644730\n",
      "Iteration 4, loss = 0.49221918\n",
      "Iteration 5, loss = 0.47804621\n",
      "Iteration 6, loss = 0.46115597\n",
      "Iteration 7, loss = 0.44446067\n",
      "Iteration 8, loss = 0.46611153\n",
      "Iteration 9, loss = 0.45580277\n",
      "Iteration 10, loss = 0.46136703\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76665555\n",
      "Iteration 2, loss = 0.59542881\n",
      "Iteration 3, loss = 0.57624878\n",
      "Iteration 4, loss = 0.50731504\n",
      "Iteration 5, loss = 0.47419242\n",
      "Iteration 6, loss = 0.48944836\n",
      "Iteration 7, loss = 0.46574108\n",
      "Iteration 8, loss = 0.46852423\n",
      "Iteration 9, loss = 0.46697455\n",
      "Iteration 10, loss = 0.45697122\n",
      "Iteration 11, loss = 0.45446808\n",
      "Iteration 12, loss = 0.45049716\n",
      "Iteration 13, loss = 0.46551700\n",
      "Iteration 14, loss = 0.45277087\n",
      "Iteration 15, loss = 0.46148246\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78281756\n",
      "Iteration 2, loss = 0.61257194\n",
      "Iteration 3, loss = 0.56427042\n",
      "Iteration 4, loss = 0.49163604\n",
      "Iteration 5, loss = 0.48831042\n",
      "Iteration 6, loss = 0.48821668\n",
      "Iteration 7, loss = 0.45707429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.45118406\n",
      "Iteration 9, loss = 0.46011999\n",
      "Iteration 10, loss = 0.45566241\n",
      "Iteration 11, loss = 0.45787276\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77408045\n",
      "Iteration 2, loss = 0.59741628\n",
      "Iteration 3, loss = 0.54944411\n",
      "Iteration 4, loss = 0.48974407\n",
      "Iteration 5, loss = 0.48531090\n",
      "Iteration 6, loss = 0.48974799\n",
      "Iteration 7, loss = 0.47508510\n",
      "Iteration 8, loss = 0.47291085\n",
      "Iteration 9, loss = 0.47735556\n",
      "Iteration 10, loss = 0.48203475\n",
      "Iteration 11, loss = 0.46526547\n",
      "Iteration 12, loss = 0.47114419\n",
      "Iteration 13, loss = 0.44879535\n",
      "Iteration 14, loss = 0.46656340\n",
      "Iteration 15, loss = 0.46304265\n",
      "Iteration 16, loss = 0.46918891\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78299738\n",
      "Iteration 2, loss = 0.64711427\n",
      "Iteration 3, loss = 0.57614879\n",
      "Iteration 4, loss = 0.50732407\n",
      "Iteration 5, loss = 0.46848378\n",
      "Iteration 6, loss = 0.46610155\n",
      "Iteration 7, loss = 0.47174062\n",
      "Iteration 8, loss = 0.45641074\n",
      "Iteration 9, loss = 0.44193852\n",
      "Iteration 10, loss = 0.43276289\n",
      "Iteration 11, loss = 0.45145020\n",
      "Iteration 12, loss = 0.47039129\n",
      "Iteration 13, loss = 0.48292463\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82806620\n",
      "Iteration 2, loss = 0.65677256\n",
      "Iteration 3, loss = 0.60038701\n",
      "Iteration 4, loss = 0.56267059\n",
      "Iteration 5, loss = 0.51227761\n",
      "Iteration 6, loss = 0.51201313\n",
      "Iteration 7, loss = 0.48529883\n",
      "Iteration 8, loss = 0.49618926\n",
      "Iteration 9, loss = 0.50784703\n",
      "Iteration 10, loss = 0.47440572\n",
      "Iteration 11, loss = 0.47526353\n",
      "Iteration 12, loss = 0.47366361\n",
      "Iteration 13, loss = 0.46768833\n",
      "Iteration 14, loss = 0.47748187\n",
      "Iteration 15, loss = 0.48062417\n",
      "Iteration 16, loss = 0.48318896\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80719868\n",
      "Iteration 2, loss = 0.61746716\n",
      "Iteration 3, loss = 0.52230207\n",
      "Iteration 4, loss = 0.49843986\n",
      "Iteration 5, loss = 0.49312180\n",
      "Iteration 6, loss = 0.45830536\n",
      "Iteration 7, loss = 0.46379728\n",
      "Iteration 8, loss = 0.46102398\n",
      "Iteration 9, loss = 0.49547788\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81975550\n",
      "Iteration 2, loss = 0.65894880\n",
      "Iteration 3, loss = 0.61463581\n",
      "Iteration 4, loss = 0.56245318\n",
      "Iteration 5, loss = 0.52569430\n",
      "Iteration 6, loss = 0.51350512\n",
      "Iteration 7, loss = 0.47916123\n",
      "Iteration 8, loss = 0.49237426\n",
      "Iteration 9, loss = 0.48630128\n",
      "Iteration 10, loss = 0.47824446\n",
      "Iteration 11, loss = 0.46153475\n",
      "Iteration 12, loss = 0.47982884\n",
      "Iteration 13, loss = 0.50858617\n",
      "Iteration 14, loss = 0.48339194\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81406037\n",
      "Iteration 2, loss = 0.64833088\n",
      "Iteration 3, loss = 0.56869035\n",
      "Iteration 4, loss = 0.49350194\n",
      "Iteration 5, loss = 0.48253182\n",
      "Iteration 6, loss = 0.49327704\n",
      "Iteration 7, loss = 0.47971280\n",
      "Iteration 8, loss = 0.46647906\n",
      "Iteration 9, loss = 0.49830060\n",
      "Iteration 10, loss = 0.48864046\n",
      "Iteration 11, loss = 0.47989673\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80377201\n",
      "Iteration 2, loss = 0.62413034\n",
      "Iteration 3, loss = 0.52270728\n",
      "Iteration 4, loss = 0.45450494\n",
      "Iteration 5, loss = 0.43701945\n",
      "Iteration 6, loss = 0.42133150\n",
      "Iteration 7, loss = 0.40480126\n",
      "Iteration 8, loss = 0.40875937\n",
      "Iteration 9, loss = 0.41188022\n",
      "Iteration 10, loss = 0.40738083\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72507341\n",
      "Iteration 2, loss = 0.55416186\n",
      "Iteration 3, loss = 0.49876965\n",
      "Iteration 4, loss = 0.48164763\n",
      "Iteration 5, loss = 0.47221912\n",
      "Iteration 6, loss = 0.47471107\n",
      "Iteration 7, loss = 0.47658883\n",
      "Iteration 8, loss = 0.45620244\n",
      "Iteration 9, loss = 0.47094533\n",
      "Iteration 10, loss = 0.45677174\n",
      "Iteration 11, loss = 0.44376719\n",
      "Iteration 12, loss = 0.46501031\n",
      "Iteration 13, loss = 0.48276873\n",
      "Iteration 14, loss = 0.47760961\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73383870\n",
      "Iteration 2, loss = 0.61780849\n",
      "Iteration 3, loss = 0.55109611\n",
      "Iteration 4, loss = 0.50558993\n",
      "Iteration 5, loss = 0.49227481\n",
      "Iteration 6, loss = 0.49502316\n",
      "Iteration 7, loss = 0.46885552\n",
      "Iteration 8, loss = 0.46898557\n",
      "Iteration 9, loss = 0.44598997\n",
      "Iteration 10, loss = 0.46217111\n",
      "Iteration 11, loss = 0.47005163\n",
      "Iteration 12, loss = 0.46716246\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76165469\n",
      "Iteration 2, loss = 0.62255746\n",
      "Iteration 3, loss = 0.54767026\n",
      "Iteration 4, loss = 0.50192930\n",
      "Iteration 5, loss = 0.47826518\n",
      "Iteration 6, loss = 0.45628523\n",
      "Iteration 7, loss = 0.45957999\n",
      "Iteration 8, loss = 0.45256792\n",
      "Iteration 9, loss = 0.45327506\n",
      "Iteration 10, loss = 0.46332011\n",
      "Iteration 11, loss = 0.45292892\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76495415\n",
      "Iteration 2, loss = 0.59013124\n",
      "Iteration 3, loss = 0.50032096\n",
      "Iteration 4, loss = 0.47833513\n",
      "Iteration 5, loss = 0.47590882\n",
      "Iteration 6, loss = 0.46620216\n",
      "Iteration 7, loss = 0.46324849\n",
      "Iteration 8, loss = 0.45726504\n",
      "Iteration 9, loss = 0.47423098\n",
      "Iteration 10, loss = 0.51765244\n",
      "Iteration 11, loss = 0.50078024\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78962314\n",
      "Iteration 2, loss = 0.63509835\n",
      "Iteration 3, loss = 0.53778410\n",
      "Iteration 4, loss = 0.49131707\n",
      "Iteration 5, loss = 0.50355893\n",
      "Iteration 6, loss = 0.46659958\n",
      "Iteration 7, loss = 0.45422063\n",
      "Iteration 8, loss = 0.47545525\n",
      "Iteration 9, loss = 0.46672370\n",
      "Iteration 10, loss = 0.46671165\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76038356\n",
      "Iteration 2, loss = 0.63352200\n",
      "Iteration 3, loss = 0.55941858\n",
      "Iteration 4, loss = 0.50757469\n",
      "Iteration 5, loss = 0.52407704\n",
      "Iteration 6, loss = 0.49142632\n",
      "Iteration 7, loss = 0.48767312\n",
      "Iteration 8, loss = 0.49161764\n",
      "Iteration 9, loss = 0.50347287\n",
      "Iteration 10, loss = 0.50848031\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79781695\n",
      "Iteration 2, loss = 0.63579286\n",
      "Iteration 3, loss = 0.56877187\n",
      "Iteration 4, loss = 0.49166114\n",
      "Iteration 5, loss = 0.49071813\n",
      "Iteration 6, loss = 0.45102026\n",
      "Iteration 7, loss = 0.47298500\n",
      "Iteration 8, loss = 0.47070050\n",
      "Iteration 9, loss = 0.48186941\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79615993\n",
      "Iteration 2, loss = 0.61960952\n",
      "Iteration 3, loss = 0.52742578\n",
      "Iteration 4, loss = 0.48765850\n",
      "Iteration 5, loss = 0.49550747\n",
      "Iteration 6, loss = 0.46971261\n",
      "Iteration 7, loss = 0.46938446\n",
      "Iteration 8, loss = 0.48768128\n",
      "Iteration 9, loss = 0.46443301\n",
      "Iteration 10, loss = 0.48072004\n",
      "Iteration 11, loss = 0.46030831\n",
      "Iteration 12, loss = 0.47203889\n",
      "Iteration 13, loss = 0.46864276\n",
      "Iteration 14, loss = 0.50516238\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78342372\n",
      "Iteration 2, loss = 0.64366181\n",
      "Iteration 3, loss = 0.55618888\n",
      "Iteration 4, loss = 0.50846474\n",
      "Iteration 5, loss = 0.50453685\n",
      "Iteration 6, loss = 0.47312018\n",
      "Iteration 7, loss = 0.47154646\n",
      "Iteration 8, loss = 0.49306980\n",
      "Iteration 9, loss = 0.49138311\n",
      "Iteration 10, loss = 0.48774787\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77752078\n",
      "Iteration 2, loss = 0.67914483\n",
      "Iteration 3, loss = 0.62589875\n",
      "Iteration 4, loss = 0.54909208\n",
      "Iteration 5, loss = 0.48801838\n",
      "Iteration 6, loss = 0.46080728\n",
      "Iteration 7, loss = 0.44899934\n",
      "Iteration 8, loss = 0.43844005\n",
      "Iteration 9, loss = 0.42037200\n",
      "Iteration 10, loss = 0.47056579\n",
      "Iteration 11, loss = 0.45849199\n",
      "Iteration 12, loss = 0.42496112\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75784555\n",
      "Iteration 2, loss = 0.60423586\n",
      "Iteration 3, loss = 0.54468187\n",
      "Iteration 4, loss = 0.52089252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.48242827\n",
      "Iteration 6, loss = 0.46328985\n",
      "Iteration 7, loss = 0.44510961\n",
      "Iteration 8, loss = 0.47300039\n",
      "Iteration 9, loss = 0.48099241\n",
      "Iteration 10, loss = 0.47549300\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76672909\n",
      "Iteration 2, loss = 0.60415034\n",
      "Iteration 3, loss = 0.54488692\n",
      "Iteration 4, loss = 0.52439387\n",
      "Iteration 5, loss = 0.48501830\n",
      "Iteration 6, loss = 0.46571548\n",
      "Iteration 7, loss = 0.48555267\n",
      "Iteration 8, loss = 0.49056161\n",
      "Iteration 9, loss = 0.46828465\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75520054\n",
      "Iteration 2, loss = 0.60906655\n",
      "Iteration 3, loss = 0.54260379\n",
      "Iteration 4, loss = 0.53682234\n",
      "Iteration 5, loss = 0.50849041\n",
      "Iteration 6, loss = 0.46899763\n",
      "Iteration 7, loss = 0.47298837\n",
      "Iteration 8, loss = 0.47713429\n",
      "Iteration 9, loss = 0.47108949\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75380741\n",
      "Iteration 2, loss = 0.63395110\n",
      "Iteration 3, loss = 0.57472197\n",
      "Iteration 4, loss = 0.52786794\n",
      "Iteration 5, loss = 0.49741046\n",
      "Iteration 6, loss = 0.47678365\n",
      "Iteration 7, loss = 0.47490582\n",
      "Iteration 8, loss = 0.50352762\n",
      "Iteration 9, loss = 0.48423288\n",
      "Iteration 10, loss = 0.49091493\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75911374\n",
      "Iteration 2, loss = 0.62313973\n",
      "Iteration 3, loss = 0.55104324\n",
      "Iteration 4, loss = 0.50260245\n",
      "Iteration 5, loss = 0.48459342\n",
      "Iteration 6, loss = 0.44924397\n",
      "Iteration 7, loss = 0.45887651\n",
      "Iteration 8, loss = 0.45820682\n",
      "Iteration 9, loss = 0.47139864\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75875283\n",
      "Iteration 2, loss = 0.64555366\n",
      "Iteration 3, loss = 0.61663875\n",
      "Iteration 4, loss = 0.54096485\n",
      "Iteration 5, loss = 0.51131944\n",
      "Iteration 6, loss = 0.51472698\n",
      "Iteration 7, loss = 0.49926505\n",
      "Iteration 8, loss = 0.48754800\n",
      "Iteration 9, loss = 0.49778075\n",
      "Iteration 10, loss = 0.48220551\n",
      "Iteration 11, loss = 0.47293975\n",
      "Iteration 12, loss = 0.47172402\n",
      "Iteration 13, loss = 0.49310043\n",
      "Iteration 14, loss = 0.48462000\n",
      "Iteration 15, loss = 0.46632864\n",
      "Iteration 16, loss = 0.47254914\n",
      "Iteration 17, loss = 0.48788105\n",
      "Iteration 18, loss = 0.49281787\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77940961\n",
      "Iteration 2, loss = 0.65419147\n",
      "Iteration 3, loss = 0.58442578\n",
      "Iteration 4, loss = 0.51810873\n",
      "Iteration 5, loss = 0.47403047\n",
      "Iteration 6, loss = 0.45928417\n",
      "Iteration 7, loss = 0.45697183\n",
      "Iteration 8, loss = 0.44565441\n",
      "Iteration 9, loss = 0.43832714\n",
      "Iteration 10, loss = 0.45157420\n",
      "Iteration 11, loss = 0.46912883\n",
      "Iteration 12, loss = 0.45659397\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81068585\n",
      "Iteration 2, loss = 0.67922214\n",
      "Iteration 3, loss = 0.62077094\n",
      "Iteration 4, loss = 0.55722700\n",
      "Iteration 5, loss = 0.48601157\n",
      "Iteration 6, loss = 0.47429060\n",
      "Iteration 7, loss = 0.46464181\n",
      "Iteration 8, loss = 0.48030137\n",
      "Iteration 9, loss = 0.49893967\n",
      "Iteration 10, loss = 0.47990727\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81462743\n",
      "Iteration 2, loss = 0.68546581\n",
      "Iteration 3, loss = 0.62864720\n",
      "Iteration 4, loss = 0.53983723\n",
      "Iteration 5, loss = 0.49293227\n",
      "Iteration 6, loss = 0.48892547\n",
      "Iteration 7, loss = 0.47131088\n",
      "Iteration 8, loss = 0.48241655\n",
      "Iteration 9, loss = 0.50597586\n",
      "Iteration 10, loss = 0.49092898\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76999409\n",
      "Iteration 2, loss = 0.64776123\n",
      "Iteration 3, loss = 0.55905445\n",
      "Iteration 4, loss = 0.46261993\n",
      "Iteration 5, loss = 0.44297867\n",
      "Iteration 6, loss = 0.41514764\n",
      "Iteration 7, loss = 0.40591651\n",
      "Iteration 8, loss = 0.40587540\n",
      "Iteration 9, loss = 0.43702475\n",
      "Iteration 10, loss = 0.43121075\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72178534\n",
      "Iteration 2, loss = 0.59583367\n",
      "Iteration 3, loss = 0.51204687\n",
      "Iteration 4, loss = 0.49406475\n",
      "Iteration 5, loss = 0.46421312\n",
      "Iteration 6, loss = 0.45854310\n",
      "Iteration 7, loss = 0.48063180\n",
      "Iteration 8, loss = 0.50193719\n",
      "Iteration 9, loss = 0.46966498\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73017340\n",
      "Iteration 2, loss = 0.62314257\n",
      "Iteration 3, loss = 0.54881805\n",
      "Iteration 4, loss = 0.49994432\n",
      "Iteration 5, loss = 0.47710492\n",
      "Iteration 6, loss = 0.47126774\n",
      "Iteration 7, loss = 0.45267192\n",
      "Iteration 8, loss = 0.47844979\n",
      "Iteration 9, loss = 0.49488085\n",
      "Iteration 10, loss = 0.47418318\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72433551\n",
      "Iteration 2, loss = 0.59167439\n",
      "Iteration 3, loss = 0.53012427\n",
      "Iteration 4, loss = 0.48501270\n",
      "Iteration 5, loss = 0.45074657\n",
      "Iteration 6, loss = 0.46086023\n",
      "Iteration 7, loss = 0.47130645\n",
      "Iteration 8, loss = 0.46413211\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72769325\n",
      "Iteration 2, loss = 0.60122416\n",
      "Iteration 3, loss = 0.55412412\n",
      "Iteration 4, loss = 0.51078516\n",
      "Iteration 5, loss = 0.48509721\n",
      "Iteration 6, loss = 0.46620512\n",
      "Iteration 7, loss = 0.47544624\n",
      "Iteration 8, loss = 0.46577014\n",
      "Iteration 9, loss = 0.45454952\n",
      "Iteration 10, loss = 0.47057539\n",
      "Iteration 11, loss = 0.49404509\n",
      "Iteration 12, loss = 0.47713450\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72426754\n",
      "Iteration 2, loss = 0.61704641\n",
      "Iteration 3, loss = 0.53196305\n",
      "Iteration 4, loss = 0.50949814\n",
      "Iteration 5, loss = 0.49683629\n",
      "Iteration 6, loss = 0.49202716\n",
      "Iteration 7, loss = 0.48417702\n",
      "Iteration 8, loss = 0.45062123\n",
      "Iteration 9, loss = 0.46124710\n",
      "Iteration 10, loss = 0.46613763\n",
      "Iteration 11, loss = 0.46992716\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72140815\n",
      "Iteration 2, loss = 0.61820762\n",
      "Iteration 3, loss = 0.55350331\n",
      "Iteration 4, loss = 0.51420987\n",
      "Iteration 5, loss = 0.49488382\n",
      "Iteration 6, loss = 0.48843507\n",
      "Iteration 7, loss = 0.47324851\n",
      "Iteration 8, loss = 0.49694507\n",
      "Iteration 9, loss = 0.50599748\n",
      "Iteration 10, loss = 0.48127768\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73237128\n",
      "Iteration 2, loss = 0.60717558\n",
      "Iteration 3, loss = 0.55665530\n",
      "Iteration 4, loss = 0.52311759\n",
      "Iteration 5, loss = 0.50330856\n",
      "Iteration 6, loss = 0.50065766\n",
      "Iteration 7, loss = 0.47074235\n",
      "Iteration 8, loss = 0.48728755\n",
      "Iteration 9, loss = 0.45497198\n",
      "Iteration 10, loss = 0.46038670\n",
      "Iteration 11, loss = 0.45973152\n",
      "Iteration 12, loss = 0.45553141\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74101343\n",
      "Iteration 2, loss = 0.62002822\n",
      "Iteration 3, loss = 0.55793264\n",
      "Iteration 4, loss = 0.52347148\n",
      "Iteration 5, loss = 0.52314092\n",
      "Iteration 6, loss = 0.49744429\n",
      "Iteration 7, loss = 0.49060321\n",
      "Iteration 8, loss = 0.48264625\n",
      "Iteration 9, loss = 0.48804827\n",
      "Iteration 10, loss = 0.47135506\n",
      "Iteration 11, loss = 0.47894997\n",
      "Iteration 12, loss = 0.47883002\n",
      "Iteration 13, loss = 0.48158717\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.72552925\n",
      "Iteration 2, loss = 0.59415123\n",
      "Iteration 3, loss = 0.52834756\n",
      "Iteration 4, loss = 0.49192640\n",
      "Iteration 5, loss = 0.49150639\n",
      "Iteration 6, loss = 0.48262459\n",
      "Iteration 7, loss = 0.46724276\n",
      "Iteration 8, loss = 0.46128559\n",
      "Iteration 9, loss = 0.46943154\n",
      "Iteration 10, loss = 0.48701236\n",
      "Iteration 11, loss = 0.47182292\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71839540\n",
      "Iteration 2, loss = 0.59351904\n",
      "Iteration 3, loss = 0.52495122\n",
      "Iteration 4, loss = 0.45035954\n",
      "Iteration 5, loss = 0.44461692\n",
      "Iteration 6, loss = 0.44315080\n",
      "Iteration 7, loss = 0.43393201\n",
      "Iteration 8, loss = 0.41512896\n",
      "Iteration 9, loss = 0.40806038\n",
      "Iteration 10, loss = 0.42303485\n",
      "Iteration 11, loss = 0.41812428\n",
      "Iteration 12, loss = 0.41319592\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.78986384\n",
      "Iteration 2, loss = 0.63174386\n",
      "Iteration 3, loss = 0.57565342\n",
      "Iteration 4, loss = 0.52113530\n",
      "Iteration 5, loss = 0.49259410\n",
      "Iteration 6, loss = 0.47533126\n",
      "Iteration 7, loss = 0.46589899\n",
      "Iteration 8, loss = 0.46225360\n",
      "Iteration 9, loss = 0.48113457\n",
      "Iteration 10, loss = 0.50079958\n",
      "Iteration 11, loss = 0.47950587\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78085142\n",
      "Iteration 2, loss = 0.62740289\n",
      "Iteration 3, loss = 0.55736594\n",
      "Iteration 4, loss = 0.53447998\n",
      "Iteration 5, loss = 0.51416288\n",
      "Iteration 6, loss = 0.50070115\n",
      "Iteration 7, loss = 0.47230050\n",
      "Iteration 8, loss = 0.47360510\n",
      "Iteration 9, loss = 0.44723311\n",
      "Iteration 10, loss = 0.44388532\n",
      "Iteration 11, loss = 0.46642296\n",
      "Iteration 12, loss = 0.48689974\n",
      "Iteration 13, loss = 0.49847645\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76232670\n",
      "Iteration 2, loss = 0.62828555\n",
      "Iteration 3, loss = 0.56087335\n",
      "Iteration 4, loss = 0.52949448\n",
      "Iteration 5, loss = 0.52285250\n",
      "Iteration 6, loss = 0.49382933\n",
      "Iteration 7, loss = 0.48651410\n",
      "Iteration 8, loss = 0.47451649\n",
      "Iteration 9, loss = 0.46520666\n",
      "Iteration 10, loss = 0.46980561\n",
      "Iteration 11, loss = 0.46290604\n",
      "Iteration 12, loss = 0.47692760\n",
      "Iteration 13, loss = 0.48791736\n",
      "Iteration 14, loss = 0.46441658\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77651333\n",
      "Iteration 2, loss = 0.61572560\n",
      "Iteration 3, loss = 0.52819864\n",
      "Iteration 4, loss = 0.50385819\n",
      "Iteration 5, loss = 0.46974814\n",
      "Iteration 6, loss = 0.47286437\n",
      "Iteration 7, loss = 0.47335323\n",
      "Iteration 8, loss = 0.46570552\n",
      "Iteration 9, loss = 0.47287073\n",
      "Iteration 10, loss = 0.46472690\n",
      "Iteration 11, loss = 0.49405863\n",
      "Iteration 12, loss = 0.48149994\n",
      "Iteration 13, loss = 0.49551011\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77655064\n",
      "Iteration 2, loss = 0.62268901\n",
      "Iteration 3, loss = 0.54902766\n",
      "Iteration 4, loss = 0.49701078\n",
      "Iteration 5, loss = 0.46988595\n",
      "Iteration 6, loss = 0.47078398\n",
      "Iteration 7, loss = 0.48269866\n",
      "Iteration 8, loss = 0.47016100\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78657096\n",
      "Iteration 2, loss = 0.62095404\n",
      "Iteration 3, loss = 0.54302769\n",
      "Iteration 4, loss = 0.49986713\n",
      "Iteration 5, loss = 0.47321471\n",
      "Iteration 6, loss = 0.50013232\n",
      "Iteration 7, loss = 0.47331789\n",
      "Iteration 8, loss = 0.45924474\n",
      "Iteration 9, loss = 0.47595752\n",
      "Iteration 10, loss = 0.47777412\n",
      "Iteration 11, loss = 0.45566733\n",
      "Iteration 12, loss = 0.45428136\n",
      "Iteration 13, loss = 0.46229738\n",
      "Iteration 14, loss = 0.45830343\n",
      "Iteration 15, loss = 0.47374062\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79649742\n",
      "Iteration 2, loss = 0.65687363\n",
      "Iteration 3, loss = 0.60646659\n",
      "Iteration 4, loss = 0.53643813\n",
      "Iteration 5, loss = 0.49300658\n",
      "Iteration 6, loss = 0.46501049\n",
      "Iteration 7, loss = 0.45715525\n",
      "Iteration 8, loss = 0.46801052\n",
      "Iteration 9, loss = 0.52192835\n",
      "Iteration 10, loss = 0.51485754\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78112509\n",
      "Iteration 2, loss = 0.64531706\n",
      "Iteration 3, loss = 0.56873889\n",
      "Iteration 4, loss = 0.52325984\n",
      "Iteration 5, loss = 0.49068973\n",
      "Iteration 6, loss = 0.46826789\n",
      "Iteration 7, loss = 0.45161304\n",
      "Iteration 8, loss = 0.44457125\n",
      "Iteration 9, loss = 0.46055106\n",
      "Iteration 10, loss = 0.48549370\n",
      "Iteration 11, loss = 0.50266859\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78552197\n",
      "Iteration 2, loss = 0.62998905\n",
      "Iteration 3, loss = 0.52702435\n",
      "Iteration 4, loss = 0.49219180\n",
      "Iteration 5, loss = 0.49547784\n",
      "Iteration 6, loss = 0.46820243\n",
      "Iteration 7, loss = 0.46715605\n",
      "Iteration 8, loss = 0.47537040\n",
      "Iteration 9, loss = 0.48868519\n",
      "Iteration 10, loss = 0.49081620\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76467928\n",
      "Iteration 2, loss = 0.63773725\n",
      "Iteration 3, loss = 0.53999764\n",
      "Iteration 4, loss = 0.46719471\n",
      "Iteration 5, loss = 0.43254017\n",
      "Iteration 6, loss = 0.40574215\n",
      "Iteration 7, loss = 0.40026133\n",
      "Iteration 8, loss = 0.42463951\n",
      "Iteration 9, loss = 0.41324463\n",
      "Iteration 10, loss = 0.41866121\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75106127\n",
      "Iteration 2, loss = 0.64649554\n",
      "Iteration 3, loss = 0.59010143\n",
      "Iteration 4, loss = 0.53971852\n",
      "Iteration 5, loss = 0.49197698\n",
      "Iteration 6, loss = 0.48236406\n",
      "Iteration 7, loss = 0.47508231\n",
      "Iteration 8, loss = 0.46693536\n",
      "Iteration 9, loss = 0.45983609\n",
      "Iteration 10, loss = 0.43734116\n",
      "Iteration 11, loss = 0.45312126\n",
      "Iteration 12, loss = 0.44187520\n",
      "Iteration 13, loss = 0.46309849\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75760980\n",
      "Iteration 2, loss = 0.66062053\n",
      "Iteration 3, loss = 0.59419292\n",
      "Iteration 4, loss = 0.54387501\n",
      "Iteration 5, loss = 0.52895793\n",
      "Iteration 6, loss = 0.49359027\n",
      "Iteration 7, loss = 0.48086866\n",
      "Iteration 8, loss = 0.47333466\n",
      "Iteration 9, loss = 0.46454181\n",
      "Iteration 10, loss = 0.47611782\n",
      "Iteration 11, loss = 0.47471541\n",
      "Iteration 12, loss = 0.44771894\n",
      "Iteration 13, loss = 0.48443861\n",
      "Iteration 14, loss = 0.48263363\n",
      "Iteration 15, loss = 0.47794561\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74556655\n",
      "Iteration 2, loss = 0.63627960\n",
      "Iteration 3, loss = 0.56186177\n",
      "Iteration 4, loss = 0.51445270\n",
      "Iteration 5, loss = 0.49505819\n",
      "Iteration 6, loss = 0.46785377\n",
      "Iteration 7, loss = 0.47703540\n",
      "Iteration 8, loss = 0.48132171\n",
      "Iteration 9, loss = 0.47025851\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73326279\n",
      "Iteration 2, loss = 0.61659936\n",
      "Iteration 3, loss = 0.55136006\n",
      "Iteration 4, loss = 0.48605245\n",
      "Iteration 5, loss = 0.48832103\n",
      "Iteration 6, loss = 0.47444907\n",
      "Iteration 7, loss = 0.49848829\n",
      "Iteration 8, loss = 0.50265560\n",
      "Iteration 9, loss = 0.47985765\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73376797\n",
      "Iteration 2, loss = 0.62285467\n",
      "Iteration 3, loss = 0.53505961\n",
      "Iteration 4, loss = 0.48763095\n",
      "Iteration 5, loss = 0.48708094\n",
      "Iteration 6, loss = 0.48970660\n",
      "Iteration 7, loss = 0.46773716\n",
      "Iteration 8, loss = 0.45780859\n",
      "Iteration 9, loss = 0.45633333\n",
      "Iteration 10, loss = 0.46971514\n",
      "Iteration 11, loss = 0.46229747\n",
      "Iteration 12, loss = 0.47494912\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73518741\n",
      "Iteration 2, loss = 0.61510928\n",
      "Iteration 3, loss = 0.54373685\n",
      "Iteration 4, loss = 0.49720332\n",
      "Iteration 5, loss = 0.47682838\n",
      "Iteration 6, loss = 0.48963701\n",
      "Iteration 7, loss = 0.48037939\n",
      "Iteration 8, loss = 0.49250139\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74555550\n",
      "Iteration 2, loss = 0.66771940\n",
      "Iteration 3, loss = 0.58897843\n",
      "Iteration 4, loss = 0.52143567\n",
      "Iteration 5, loss = 0.49070966\n",
      "Iteration 6, loss = 0.49972945\n",
      "Iteration 7, loss = 0.47215820\n",
      "Iteration 8, loss = 0.44920466\n",
      "Iteration 9, loss = 0.48448923\n",
      "Iteration 10, loss = 0.52088222\n",
      "Iteration 11, loss = 0.47316586\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75312080\n",
      "Iteration 2, loss = 0.63297342\n",
      "Iteration 3, loss = 0.56030965\n",
      "Iteration 4, loss = 0.50499442\n",
      "Iteration 5, loss = 0.49866369\n",
      "Iteration 6, loss = 0.49771354\n",
      "Iteration 7, loss = 0.47850926\n",
      "Iteration 8, loss = 0.46510571\n",
      "Iteration 9, loss = 0.47873240\n",
      "Iteration 10, loss = 0.51977508\n",
      "Iteration 11, loss = 0.50361932\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74676957\n",
      "Iteration 2, loss = 0.65701186\n",
      "Iteration 3, loss = 0.57842123\n",
      "Iteration 4, loss = 0.50028650\n",
      "Iteration 5, loss = 0.48435441\n",
      "Iteration 6, loss = 0.49214567\n",
      "Iteration 7, loss = 0.48972551\n",
      "Iteration 8, loss = 0.46843575\n",
      "Iteration 9, loss = 0.47051984\n",
      "Iteration 10, loss = 0.50274435\n",
      "Iteration 11, loss = 0.49448387\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75187124\n",
      "Iteration 2, loss = 0.64524194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.53151542\n",
      "Iteration 4, loss = 0.47532190\n",
      "Iteration 5, loss = 0.42834016\n",
      "Iteration 6, loss = 0.43369142\n",
      "Iteration 7, loss = 0.42162368\n",
      "Iteration 8, loss = 0.43090224\n",
      "Iteration 9, loss = 0.42332995\n",
      "Iteration 10, loss = 0.47085118\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81107793\n",
      "Iteration 2, loss = 0.63803471\n",
      "Iteration 3, loss = 0.55282523\n",
      "Iteration 4, loss = 0.50436793\n",
      "Iteration 5, loss = 0.47102205\n",
      "Iteration 6, loss = 0.48405466\n",
      "Iteration 7, loss = 0.47259097\n",
      "Iteration 8, loss = 0.47756258\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81934830\n",
      "Iteration 2, loss = 0.66276745\n",
      "Iteration 3, loss = 0.59331273\n",
      "Iteration 4, loss = 0.53689825\n",
      "Iteration 5, loss = 0.52944458\n",
      "Iteration 6, loss = 0.48496633\n",
      "Iteration 7, loss = 0.48602831\n",
      "Iteration 8, loss = 0.47864980\n",
      "Iteration 9, loss = 0.50756105\n",
      "Iteration 10, loss = 0.50053560\n",
      "Iteration 11, loss = 0.46715386\n",
      "Iteration 12, loss = 0.48335844\n",
      "Iteration 13, loss = 0.53026273\n",
      "Iteration 14, loss = 0.49420142\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80268635\n",
      "Iteration 2, loss = 0.62568722\n",
      "Iteration 3, loss = 0.53028902\n",
      "Iteration 4, loss = 0.48961268\n",
      "Iteration 5, loss = 0.49692527\n",
      "Iteration 6, loss = 0.47937899\n",
      "Iteration 7, loss = 0.48675794\n",
      "Iteration 8, loss = 0.46519970\n",
      "Iteration 9, loss = 0.50129229\n",
      "Iteration 10, loss = 0.49319915\n",
      "Iteration 11, loss = 0.47341608\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82158369\n",
      "Iteration 2, loss = 0.65491509\n",
      "Iteration 3, loss = 0.58544406\n",
      "Iteration 4, loss = 0.51258688\n",
      "Iteration 5, loss = 0.49412098\n",
      "Iteration 6, loss = 0.47954310\n",
      "Iteration 7, loss = 0.48156644\n",
      "Iteration 8, loss = 0.47121042\n",
      "Iteration 9, loss = 0.46439258\n",
      "Iteration 10, loss = 0.47872733\n",
      "Iteration 11, loss = 0.47579323\n",
      "Iteration 12, loss = 0.48792801\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80072167\n",
      "Iteration 2, loss = 0.63078443\n",
      "Iteration 3, loss = 0.56289574\n",
      "Iteration 4, loss = 0.50182698\n",
      "Iteration 5, loss = 0.48215247\n",
      "Iteration 6, loss = 0.48112245\n",
      "Iteration 7, loss = 0.46836003\n",
      "Iteration 8, loss = 0.47257303\n",
      "Iteration 9, loss = 0.48156502\n",
      "Iteration 10, loss = 0.46554850\n",
      "Iteration 11, loss = 0.47392283\n",
      "Iteration 12, loss = 0.46652264\n",
      "Iteration 13, loss = 0.47076474\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80609770\n",
      "Iteration 2, loss = 0.68075247\n",
      "Iteration 3, loss = 0.60944221\n",
      "Iteration 4, loss = 0.56207665\n",
      "Iteration 5, loss = 0.52508026\n",
      "Iteration 6, loss = 0.52700905\n",
      "Iteration 7, loss = 0.49268604\n",
      "Iteration 8, loss = 0.47941063\n",
      "Iteration 9, loss = 0.49074432\n",
      "Iteration 10, loss = 0.46407274\n",
      "Iteration 11, loss = 0.46711461\n",
      "Iteration 12, loss = 0.46243075\n",
      "Iteration 13, loss = 0.48437379\n",
      "Iteration 14, loss = 0.47761206\n",
      "Iteration 15, loss = 0.46454778\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81830002\n",
      "Iteration 2, loss = 0.67783257\n",
      "Iteration 3, loss = 0.60711855\n",
      "Iteration 4, loss = 0.55537084\n",
      "Iteration 5, loss = 0.50166499\n",
      "Iteration 6, loss = 0.48472305\n",
      "Iteration 7, loss = 0.51525519\n",
      "Iteration 8, loss = 0.50081394\n",
      "Iteration 9, loss = 0.50500715\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81048118\n",
      "Iteration 2, loss = 0.63585773\n",
      "Iteration 3, loss = 0.57760747\n",
      "Iteration 4, loss = 0.54097063\n",
      "Iteration 5, loss = 0.49521781\n",
      "Iteration 6, loss = 0.48332083\n",
      "Iteration 7, loss = 0.47442093\n",
      "Iteration 8, loss = 0.48889451\n",
      "Iteration 9, loss = 0.49768070\n",
      "Iteration 10, loss = 0.48492254\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81187823\n",
      "Iteration 2, loss = 0.66561468\n",
      "Iteration 3, loss = 0.62813201\n",
      "Iteration 4, loss = 0.57254952\n",
      "Iteration 5, loss = 0.53086196\n",
      "Iteration 6, loss = 0.50802909\n",
      "Iteration 7, loss = 0.51889150\n",
      "Iteration 8, loss = 0.49895143\n",
      "Iteration 9, loss = 0.49965785\n",
      "Iteration 10, loss = 0.50350172\n",
      "Iteration 11, loss = 0.49307721\n",
      "Iteration 12, loss = 0.47904611\n",
      "Iteration 13, loss = 0.48780775\n",
      "Iteration 14, loss = 0.52568565\n",
      "Iteration 15, loss = 0.55208064\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82615838\n",
      "Iteration 2, loss = 0.67112729\n",
      "Iteration 3, loss = 0.60225902\n",
      "Iteration 4, loss = 0.51715384\n",
      "Iteration 5, loss = 0.45433754\n",
      "Iteration 6, loss = 0.41319189\n",
      "Iteration 7, loss = 0.44206970\n",
      "Iteration 8, loss = 0.44201352\n",
      "Iteration 9, loss = 0.42399628\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77530596\n",
      "Iteration 2, loss = 0.63494933\n",
      "Iteration 3, loss = 0.55313490\n",
      "Iteration 4, loss = 0.52725710\n",
      "Iteration 5, loss = 0.50105912\n",
      "Iteration 6, loss = 0.48496320\n",
      "Iteration 7, loss = 0.47013701\n",
      "Iteration 8, loss = 0.45600865\n",
      "Iteration 9, loss = 0.47735934\n",
      "Iteration 10, loss = 0.51033591\n",
      "Iteration 11, loss = 0.50833524\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78310292\n",
      "Iteration 2, loss = 0.63534462\n",
      "Iteration 3, loss = 0.55455889\n",
      "Iteration 4, loss = 0.50548120\n",
      "Iteration 5, loss = 0.47698054\n",
      "Iteration 6, loss = 0.48960895\n",
      "Iteration 7, loss = 0.49565788\n",
      "Iteration 8, loss = 0.49888549\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78444739\n",
      "Iteration 2, loss = 0.67300388\n",
      "Iteration 3, loss = 0.61063499\n",
      "Iteration 4, loss = 0.55304371\n",
      "Iteration 5, loss = 0.50966138\n",
      "Iteration 6, loss = 0.50741681\n",
      "Iteration 7, loss = 0.49736599\n",
      "Iteration 8, loss = 0.46814257\n",
      "Iteration 9, loss = 0.48122201\n",
      "Iteration 10, loss = 0.46299444\n",
      "Iteration 11, loss = 0.48272560\n",
      "Iteration 12, loss = 0.46256495\n",
      "Iteration 13, loss = 0.46605276\n",
      "Iteration 14, loss = 0.47945052\n",
      "Iteration 15, loss = 0.47047520\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81601331\n",
      "Iteration 2, loss = 0.68443459\n",
      "Iteration 3, loss = 0.66549905\n",
      "Iteration 4, loss = 0.61422813\n",
      "Iteration 5, loss = 0.57501634\n",
      "Iteration 6, loss = 0.56872806\n",
      "Iteration 7, loss = 0.53297790\n",
      "Iteration 8, loss = 0.49939635\n",
      "Iteration 9, loss = 0.50363705\n",
      "Iteration 10, loss = 0.49065492\n",
      "Iteration 11, loss = 0.50788882\n",
      "Iteration 12, loss = 0.50605940\n",
      "Iteration 13, loss = 0.47949315\n",
      "Iteration 14, loss = 0.48489269\n",
      "Iteration 15, loss = 0.48360135\n",
      "Iteration 16, loss = 0.49812199\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81482380\n",
      "Iteration 2, loss = 0.66292209\n",
      "Iteration 3, loss = 0.61872426\n",
      "Iteration 4, loss = 0.55624322\n",
      "Iteration 5, loss = 0.52808301\n",
      "Iteration 6, loss = 0.52464512\n",
      "Iteration 7, loss = 0.50608787\n",
      "Iteration 8, loss = 0.47366442\n",
      "Iteration 9, loss = 0.47385223\n",
      "Iteration 10, loss = 0.44306582\n",
      "Iteration 11, loss = 0.45309638\n",
      "Iteration 12, loss = 0.44923334\n",
      "Iteration 13, loss = 0.44837288\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82796344\n",
      "Iteration 2, loss = 0.68114600\n",
      "Iteration 3, loss = 0.61770943\n",
      "Iteration 4, loss = 0.59105995\n",
      "Iteration 5, loss = 0.54233012\n",
      "Iteration 6, loss = 0.52978990\n",
      "Iteration 7, loss = 0.50287796\n",
      "Iteration 8, loss = 0.51913440\n",
      "Iteration 9, loss = 0.53921560\n",
      "Iteration 10, loss = 0.55548026\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81704391\n",
      "Iteration 2, loss = 0.68793882\n",
      "Iteration 3, loss = 0.64748586\n",
      "Iteration 4, loss = 0.58884448\n",
      "Iteration 5, loss = 0.56587711\n",
      "Iteration 6, loss = 0.55841195\n",
      "Iteration 7, loss = 0.53644001\n",
      "Iteration 8, loss = 0.50606776\n",
      "Iteration 9, loss = 0.48831213\n",
      "Iteration 10, loss = 0.47009362\n",
      "Iteration 11, loss = 0.47072108\n",
      "Iteration 12, loss = 0.48577898\n",
      "Iteration 13, loss = 0.48782324\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79775394\n",
      "Iteration 2, loss = 0.67413055\n",
      "Iteration 3, loss = 0.60299464\n",
      "Iteration 4, loss = 0.52649371\n",
      "Iteration 5, loss = 0.51208975\n",
      "Iteration 6, loss = 0.48300410\n",
      "Iteration 7, loss = 0.48944360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.47635437\n",
      "Iteration 9, loss = 0.47769923\n",
      "Iteration 10, loss = 0.45209901\n",
      "Iteration 11, loss = 0.46475274\n",
      "Iteration 12, loss = 0.45952920\n",
      "Iteration 13, loss = 0.48098511\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78591685\n",
      "Iteration 2, loss = 0.65089609\n",
      "Iteration 3, loss = 0.62302879\n",
      "Iteration 4, loss = 0.54576791\n",
      "Iteration 5, loss = 0.51389729\n",
      "Iteration 6, loss = 0.50180447\n",
      "Iteration 7, loss = 0.49133003\n",
      "Iteration 8, loss = 0.49162848\n",
      "Iteration 9, loss = 0.49609951\n",
      "Iteration 10, loss = 0.47788872\n",
      "Iteration 11, loss = 0.46822895\n",
      "Iteration 12, loss = 0.47303338\n",
      "Iteration 13, loss = 0.48890931\n",
      "Iteration 14, loss = 0.51482946\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81156298\n",
      "Iteration 2, loss = 0.64008977\n",
      "Iteration 3, loss = 0.54307108\n",
      "Iteration 4, loss = 0.47906403\n",
      "Iteration 5, loss = 0.45042624\n",
      "Iteration 6, loss = 0.42195068\n",
      "Iteration 7, loss = 0.41980816\n",
      "Iteration 8, loss = 0.40954651\n",
      "Iteration 9, loss = 0.45955836\n",
      "Iteration 10, loss = 0.42516842\n",
      "Iteration 11, loss = 0.41132616\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81167795\n",
      "Iteration 2, loss = 0.66627777\n",
      "Iteration 3, loss = 0.60566492\n",
      "Iteration 4, loss = 0.56645198\n",
      "Iteration 5, loss = 0.51003925\n",
      "Iteration 6, loss = 0.49065709\n",
      "Iteration 7, loss = 0.47941877\n",
      "Iteration 8, loss = 0.49535442\n",
      "Iteration 9, loss = 0.50129491\n",
      "Iteration 10, loss = 0.51342530\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82358759\n",
      "Iteration 2, loss = 0.66133690\n",
      "Iteration 3, loss = 0.61260157\n",
      "Iteration 4, loss = 0.57065968\n",
      "Iteration 5, loss = 0.52768214\n",
      "Iteration 6, loss = 0.50557609\n",
      "Iteration 7, loss = 0.49714676\n",
      "Iteration 8, loss = 0.47385763\n",
      "Iteration 9, loss = 0.49527227\n",
      "Iteration 10, loss = 0.49429287\n",
      "Iteration 11, loss = 0.49852497\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75169881\n",
      "Iteration 2, loss = 0.64024988\n",
      "Iteration 3, loss = 0.57064459\n",
      "Iteration 4, loss = 0.52728674\n",
      "Iteration 5, loss = 0.48576637\n",
      "Iteration 6, loss = 0.46954244\n",
      "Iteration 7, loss = 0.46488485\n",
      "Iteration 8, loss = 0.46218987\n",
      "Iteration 9, loss = 0.47802962\n",
      "Iteration 10, loss = 0.46009226\n",
      "Iteration 11, loss = 0.45409961\n",
      "Iteration 12, loss = 0.45151134\n",
      "Iteration 13, loss = 0.45869268\n",
      "Iteration 14, loss = 0.45420679\n",
      "Iteration 15, loss = 0.46660639\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76915204\n",
      "Iteration 2, loss = 0.64116505\n",
      "Iteration 3, loss = 0.55312924\n",
      "Iteration 4, loss = 0.50085359\n",
      "Iteration 5, loss = 0.49133108\n",
      "Iteration 6, loss = 0.47950956\n",
      "Iteration 7, loss = 0.46923507\n",
      "Iteration 8, loss = 0.46054466\n",
      "Iteration 9, loss = 0.48995727\n",
      "Iteration 10, loss = 0.46088034\n",
      "Iteration 11, loss = 0.45808758\n",
      "Iteration 12, loss = 0.47237277\n",
      "Iteration 13, loss = 0.47830969\n",
      "Iteration 14, loss = 0.46125478\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82599089\n",
      "Iteration 2, loss = 0.70840077\n",
      "Iteration 3, loss = 0.67386445\n",
      "Iteration 4, loss = 0.62536544\n",
      "Iteration 5, loss = 0.57673287\n",
      "Iteration 6, loss = 0.51919428\n",
      "Iteration 7, loss = 0.47750187\n",
      "Iteration 8, loss = 0.47878000\n",
      "Iteration 9, loss = 0.50467144\n",
      "Iteration 10, loss = 0.49630548\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79138628\n",
      "Iteration 2, loss = 0.66840802\n",
      "Iteration 3, loss = 0.61289202\n",
      "Iteration 4, loss = 0.55113198\n",
      "Iteration 5, loss = 0.52762913\n",
      "Iteration 6, loss = 0.50098921\n",
      "Iteration 7, loss = 0.49833278\n",
      "Iteration 8, loss = 0.53039047\n",
      "Iteration 9, loss = 0.50025340\n",
      "Iteration 10, loss = 0.48693362\n",
      "Iteration 11, loss = 0.48544524\n",
      "Iteration 12, loss = 0.47164194\n",
      "Iteration 13, loss = 0.48022009\n",
      "Iteration 14, loss = 0.48318052\n",
      "Iteration 15, loss = 0.49593075\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80650698\n",
      "Iteration 2, loss = 0.66876840\n",
      "Iteration 3, loss = 0.63291566\n",
      "Iteration 4, loss = 0.56437061\n",
      "Iteration 5, loss = 0.51983267\n",
      "Iteration 6, loss = 0.48277856\n",
      "Iteration 7, loss = 0.48989613\n",
      "Iteration 8, loss = 0.48825060\n",
      "Iteration 9, loss = 0.48556065\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81819145\n",
      "Iteration 2, loss = 0.69167970\n",
      "Iteration 3, loss = 0.69365518\n",
      "Iteration 4, loss = 0.65000546\n",
      "Iteration 5, loss = 0.59335028\n",
      "Iteration 6, loss = 0.55247619\n",
      "Iteration 7, loss = 0.51898764\n",
      "Iteration 8, loss = 0.49237797\n",
      "Iteration 9, loss = 0.46325252\n",
      "Iteration 10, loss = 0.48368943\n",
      "Iteration 11, loss = 0.50328310\n",
      "Iteration 12, loss = 0.50370943\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77732286\n",
      "Iteration 2, loss = 0.65951521\n",
      "Iteration 3, loss = 0.61098615\n",
      "Iteration 4, loss = 0.55512968\n",
      "Iteration 5, loss = 0.51164160\n",
      "Iteration 6, loss = 0.48885318\n",
      "Iteration 7, loss = 0.48588709\n",
      "Iteration 8, loss = 0.49100338\n",
      "Iteration 9, loss = 0.50138492\n",
      "Iteration 10, loss = 0.47666678\n",
      "Iteration 11, loss = 0.49049315\n",
      "Iteration 12, loss = 0.47111280\n",
      "Iteration 13, loss = 0.46649147\n",
      "Iteration 14, loss = 0.50851758\n",
      "Iteration 15, loss = 0.49714263\n",
      "Iteration 16, loss = 0.49090819\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76088789\n",
      "Iteration 2, loss = 0.66362546\n",
      "Iteration 3, loss = 0.62426003\n",
      "Iteration 4, loss = 0.54480687\n",
      "Iteration 5, loss = 0.48119299\n",
      "Iteration 6, loss = 0.45593870\n",
      "Iteration 7, loss = 0.46544891\n",
      "Iteration 8, loss = 0.44977365\n",
      "Iteration 9, loss = 0.43173982\n",
      "Iteration 10, loss = 0.41604607\n",
      "Iteration 11, loss = 0.42122897\n",
      "Iteration 12, loss = 0.42051388\n",
      "Iteration 13, loss = 0.42571649\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77943216\n",
      "Iteration 2, loss = 0.66253905\n",
      "Iteration 3, loss = 0.57910498\n",
      "Iteration 4, loss = 0.51764468\n",
      "Iteration 5, loss = 0.48908450\n",
      "Iteration 6, loss = 0.48707932\n",
      "Iteration 7, loss = 0.48818852\n",
      "Iteration 8, loss = 0.48782696\n",
      "Iteration 9, loss = 0.47580975\n",
      "Iteration 10, loss = 0.47511524\n",
      "Iteration 11, loss = 0.51553837\n",
      "Iteration 12, loss = 0.51208964\n",
      "Iteration 13, loss = 0.48594830\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76403751\n",
      "Iteration 2, loss = 0.68941089\n",
      "Iteration 3, loss = 0.64590679\n",
      "Iteration 4, loss = 0.58910995\n",
      "Iteration 5, loss = 0.54487152\n",
      "Iteration 6, loss = 0.51132121\n",
      "Iteration 7, loss = 0.51480430\n",
      "Iteration 8, loss = 0.49148123\n",
      "Iteration 9, loss = 0.50814260\n",
      "Iteration 10, loss = 0.50252945\n",
      "Iteration 11, loss = 0.50326741\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80460171\n",
      "Iteration 2, loss = 0.67120044\n",
      "Iteration 3, loss = 0.59197624\n",
      "Iteration 4, loss = 0.51818478\n",
      "Iteration 5, loss = 0.52161370\n",
      "Iteration 6, loss = 0.49145214\n",
      "Iteration 7, loss = 0.48132278\n",
      "Iteration 8, loss = 0.48320679\n",
      "Iteration 9, loss = 0.45457112\n",
      "Iteration 10, loss = 0.49765676\n",
      "Iteration 11, loss = 0.51796180\n",
      "Iteration 12, loss = 0.51649769\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78683038\n",
      "Iteration 2, loss = 0.68574343\n",
      "Iteration 3, loss = 0.61600226\n",
      "Iteration 4, loss = 0.53735270\n",
      "Iteration 5, loss = 0.48339289\n",
      "Iteration 6, loss = 0.49019146\n",
      "Iteration 7, loss = 0.47512284\n",
      "Iteration 8, loss = 0.46142644\n",
      "Iteration 9, loss = 0.44542002\n",
      "Iteration 10, loss = 0.47148980\n",
      "Iteration 11, loss = 0.49951850\n",
      "Iteration 12, loss = 0.50043609\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81298696\n",
      "Iteration 2, loss = 0.71218392\n",
      "Iteration 3, loss = 0.67657183\n",
      "Iteration 4, loss = 0.63593093\n",
      "Iteration 5, loss = 0.59210636\n",
      "Iteration 6, loss = 0.53083937\n",
      "Iteration 7, loss = 0.51126590\n",
      "Iteration 8, loss = 0.49011502\n",
      "Iteration 9, loss = 0.47262567\n",
      "Iteration 10, loss = 0.46928386\n",
      "Iteration 11, loss = 0.52726682\n",
      "Iteration 12, loss = 0.55541069\n",
      "Iteration 13, loss = 0.55251513\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.79275980\n",
      "Iteration 2, loss = 0.69038517\n",
      "Iteration 3, loss = 0.64705056\n",
      "Iteration 4, loss = 0.58633357\n",
      "Iteration 5, loss = 0.55956986\n",
      "Iteration 6, loss = 0.56172000\n",
      "Iteration 7, loss = 0.55713846\n",
      "Iteration 8, loss = 0.53251635\n",
      "Iteration 9, loss = 0.52406354\n",
      "Iteration 10, loss = 0.50984766\n",
      "Iteration 11, loss = 0.52068077\n",
      "Iteration 12, loss = 0.52992155\n",
      "Iteration 13, loss = 0.53744653\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80818617\n",
      "Iteration 2, loss = 0.72445397\n",
      "Iteration 3, loss = 0.64375435\n",
      "Iteration 4, loss = 0.57504525\n",
      "Iteration 5, loss = 0.51950801\n",
      "Iteration 6, loss = 0.54320019\n",
      "Iteration 7, loss = 0.50771495\n",
      "Iteration 8, loss = 0.49995981\n",
      "Iteration 9, loss = 0.49327482\n",
      "Iteration 10, loss = 0.46511650\n",
      "Iteration 11, loss = 0.47197677\n",
      "Iteration 12, loss = 0.47245334\n",
      "Iteration 13, loss = 0.48388199\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80693213\n",
      "Iteration 2, loss = 0.68662943\n",
      "Iteration 3, loss = 0.60538113\n",
      "Iteration 4, loss = 0.53351493\n",
      "Iteration 5, loss = 0.49678750\n",
      "Iteration 6, loss = 0.49154252\n",
      "Iteration 7, loss = 0.50486589\n",
      "Iteration 8, loss = 0.47195837\n",
      "Iteration 9, loss = 0.46791782\n",
      "Iteration 10, loss = 0.46154948\n",
      "Iteration 11, loss = 0.46913010\n",
      "Iteration 12, loss = 0.46890962\n",
      "Iteration 13, loss = 0.47738288\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78690864\n",
      "Iteration 2, loss = 0.69278293\n",
      "Iteration 3, loss = 0.63039247\n",
      "Iteration 4, loss = 0.55605569\n",
      "Iteration 5, loss = 0.50476184\n",
      "Iteration 6, loss = 0.50772338\n",
      "Iteration 7, loss = 0.48644971\n",
      "Iteration 8, loss = 0.49160051\n",
      "Iteration 9, loss = 0.47100930\n",
      "Iteration 10, loss = 0.49721889\n",
      "Iteration 11, loss = 0.47816658\n",
      "Iteration 12, loss = 0.46580062\n",
      "Iteration 13, loss = 0.47293967\n",
      "Iteration 14, loss = 0.47537527\n",
      "Iteration 15, loss = 0.49346699\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78091314\n",
      "Iteration 2, loss = 0.65964157\n",
      "Iteration 3, loss = 0.58425889\n",
      "Iteration 4, loss = 0.51287264\n",
      "Iteration 5, loss = 0.47797701\n",
      "Iteration 6, loss = 0.46187415\n",
      "Iteration 7, loss = 0.47788195\n",
      "Iteration 8, loss = 0.46683661\n",
      "Iteration 9, loss = 0.47063740\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76043790\n",
      "Iteration 2, loss = 0.64622748\n",
      "Iteration 3, loss = 0.58008610\n",
      "Iteration 4, loss = 0.55708316\n",
      "Iteration 5, loss = 0.51967242\n",
      "Iteration 6, loss = 0.49731924\n",
      "Iteration 7, loss = 0.47761064\n",
      "Iteration 8, loss = 0.47921113\n",
      "Iteration 9, loss = 0.46822852\n",
      "Iteration 10, loss = 0.47940096\n",
      "Iteration 11, loss = 0.49956025\n",
      "Iteration 12, loss = 0.49006745\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77065984\n",
      "Iteration 2, loss = 0.64126710\n",
      "Iteration 3, loss = 0.58392065\n",
      "Iteration 4, loss = 0.51762497\n",
      "Iteration 5, loss = 0.49882167\n",
      "Iteration 6, loss = 0.49234408\n",
      "Iteration 7, loss = 0.48333719\n",
      "Iteration 8, loss = 0.48884433\n",
      "Iteration 9, loss = 0.46732440\n",
      "Iteration 10, loss = 0.50524594\n",
      "Iteration 11, loss = 0.50492911\n",
      "Iteration 12, loss = 0.51067008\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73589277\n",
      "Iteration 2, loss = 0.60712720\n",
      "Iteration 3, loss = 0.54478564\n",
      "Iteration 4, loss = 0.50006686\n",
      "Iteration 5, loss = 0.49888210\n",
      "Iteration 6, loss = 0.48783877\n",
      "Iteration 7, loss = 0.48860098\n",
      "Iteration 8, loss = 0.48516618\n",
      "Iteration 9, loss = 0.46021104\n",
      "Iteration 10, loss = 0.47233950\n",
      "Iteration 11, loss = 0.46320442\n",
      "Iteration 12, loss = 0.45640458\n",
      "Iteration 13, loss = 0.46889566\n",
      "Iteration 14, loss = 0.50693313\n",
      "Iteration 15, loss = 0.47586936\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74976498\n",
      "Iteration 2, loss = 0.64129427\n",
      "Iteration 3, loss = 0.59040078\n",
      "Iteration 4, loss = 0.52290110\n",
      "Iteration 5, loss = 0.49146507\n",
      "Iteration 6, loss = 0.49671913\n",
      "Iteration 7, loss = 0.47516030\n",
      "Iteration 8, loss = 0.50360512\n",
      "Iteration 9, loss = 0.48302023\n",
      "Iteration 10, loss = 0.47476277\n",
      "Iteration 11, loss = 0.49196592\n",
      "Iteration 12, loss = 0.46861908\n",
      "Iteration 13, loss = 0.49854737\n",
      "Iteration 14, loss = 0.49615077\n",
      "Iteration 15, loss = 0.48779766\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75773993\n",
      "Iteration 2, loss = 0.64349954\n",
      "Iteration 3, loss = 0.58907741\n",
      "Iteration 4, loss = 0.52805700\n",
      "Iteration 5, loss = 0.50912688\n",
      "Iteration 6, loss = 0.48892734\n",
      "Iteration 7, loss = 0.48295473\n",
      "Iteration 8, loss = 0.47774483\n",
      "Iteration 9, loss = 0.50517592\n",
      "Iteration 10, loss = 0.52026836\n",
      "Iteration 11, loss = 0.52342189\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80604878\n",
      "Iteration 2, loss = 0.65170811\n",
      "Iteration 3, loss = 0.60299637\n",
      "Iteration 4, loss = 0.54214828\n",
      "Iteration 5, loss = 0.52304596\n",
      "Iteration 6, loss = 0.51664934\n",
      "Iteration 7, loss = 0.49081177\n",
      "Iteration 8, loss = 0.47788295\n",
      "Iteration 9, loss = 0.49366132\n",
      "Iteration 10, loss = 0.49992653\n",
      "Iteration 11, loss = 0.47557330\n",
      "Iteration 12, loss = 0.50188495\n",
      "Iteration 13, loss = 0.50785087\n",
      "Iteration 14, loss = 0.49556676\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81337687\n",
      "Iteration 2, loss = 0.68410984\n",
      "Iteration 3, loss = 0.58879582\n",
      "Iteration 4, loss = 0.55536886\n",
      "Iteration 5, loss = 0.50618936\n",
      "Iteration 6, loss = 0.48791536\n",
      "Iteration 7, loss = 0.48680098\n",
      "Iteration 8, loss = 0.47879684\n",
      "Iteration 9, loss = 0.48810556\n",
      "Iteration 10, loss = 0.48423557\n",
      "Iteration 11, loss = 0.46761877\n",
      "Iteration 12, loss = 0.45787812\n",
      "Iteration 13, loss = 0.47350082\n",
      "Iteration 14, loss = 0.44584171\n",
      "Iteration 15, loss = 0.48087926\n",
      "Iteration 16, loss = 0.48718179\n",
      "Iteration 17, loss = 0.50301377\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80468593\n",
      "Iteration 2, loss = 0.68871735\n",
      "Iteration 3, loss = 0.65368481\n",
      "Iteration 4, loss = 0.62398452\n",
      "Iteration 5, loss = 0.58858122\n",
      "Iteration 6, loss = 0.53942283\n",
      "Iteration 7, loss = 0.51733660\n",
      "Iteration 8, loss = 0.50436557\n",
      "Iteration 9, loss = 0.51018336\n",
      "Iteration 10, loss = 0.46267945\n",
      "Iteration 11, loss = 0.47279277\n",
      "Iteration 12, loss = 0.49802540\n",
      "Iteration 13, loss = 0.48650162\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79754345\n",
      "Iteration 2, loss = 0.67380985\n",
      "Iteration 3, loss = 0.62178436\n",
      "Iteration 4, loss = 0.58807199\n",
      "Iteration 5, loss = 0.54105938\n",
      "Iteration 6, loss = 0.54057865\n",
      "Iteration 7, loss = 0.51756660\n",
      "Iteration 8, loss = 0.53038404\n",
      "Iteration 9, loss = 0.52655555\n",
      "Iteration 10, loss = 0.49581706\n",
      "Iteration 11, loss = 0.48073897\n",
      "Iteration 12, loss = 0.47864896\n",
      "Iteration 13, loss = 0.48305760\n",
      "Iteration 14, loss = 0.48525766\n",
      "Iteration 15, loss = 0.48413725\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75756441\n",
      "Iteration 2, loss = 0.62773529\n",
      "Iteration 3, loss = 0.56592637\n",
      "Iteration 4, loss = 0.52016404\n",
      "Iteration 5, loss = 0.45319398\n",
      "Iteration 6, loss = 0.46684817\n",
      "Iteration 7, loss = 0.46457114\n",
      "Iteration 8, loss = 0.43025466\n",
      "Iteration 9, loss = 0.44460802\n",
      "Iteration 10, loss = 0.41385144\n",
      "Iteration 11, loss = 0.41049760\n",
      "Iteration 12, loss = 0.40985868\n",
      "Iteration 13, loss = 0.40044774\n",
      "Iteration 14, loss = 0.42199953\n",
      "Iteration 15, loss = 0.41676430\n",
      "Iteration 16, loss = 0.42151557\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75983903\n",
      "Iteration 2, loss = 0.64609759\n",
      "Iteration 3, loss = 0.56296327\n",
      "Iteration 4, loss = 0.49425696\n",
      "Iteration 5, loss = 0.46238103\n",
      "Iteration 6, loss = 0.47315199\n",
      "Iteration 7, loss = 0.45883167\n",
      "Iteration 8, loss = 0.47332711\n",
      "Iteration 9, loss = 0.46576398\n",
      "Iteration 10, loss = 0.47429707\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74748791\n",
      "Iteration 2, loss = 0.60125018\n",
      "Iteration 3, loss = 0.52773892\n",
      "Iteration 4, loss = 0.47357518\n",
      "Iteration 5, loss = 0.47363242\n",
      "Iteration 6, loss = 0.50446763\n",
      "Iteration 7, loss = 0.49367906\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75181089\n",
      "Iteration 2, loss = 0.62313030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.53536674\n",
      "Iteration 4, loss = 0.49779576\n",
      "Iteration 5, loss = 0.46938736\n",
      "Iteration 6, loss = 0.46804171\n",
      "Iteration 7, loss = 0.46093939\n",
      "Iteration 8, loss = 0.46875093\n",
      "Iteration 9, loss = 0.48503892\n",
      "Iteration 10, loss = 0.47825179\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76589165\n",
      "Iteration 2, loss = 0.65681052\n",
      "Iteration 3, loss = 0.54094057\n",
      "Iteration 4, loss = 0.47936542\n",
      "Iteration 5, loss = 0.47314345\n",
      "Iteration 6, loss = 0.47843230\n",
      "Iteration 7, loss = 0.48061058\n",
      "Iteration 8, loss = 0.48821275\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76139847\n",
      "Iteration 2, loss = 0.61809332\n",
      "Iteration 3, loss = 0.52177936\n",
      "Iteration 4, loss = 0.47046021\n",
      "Iteration 5, loss = 0.47428958\n",
      "Iteration 6, loss = 0.47871237\n",
      "Iteration 7, loss = 0.49530305\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77138860\n",
      "Iteration 2, loss = 0.65541763\n",
      "Iteration 3, loss = 0.57150832\n",
      "Iteration 4, loss = 0.53247913\n",
      "Iteration 5, loss = 0.49606474\n",
      "Iteration 6, loss = 0.47887454\n",
      "Iteration 7, loss = 0.48938951\n",
      "Iteration 8, loss = 0.48279049\n",
      "Iteration 9, loss = 0.47289432\n",
      "Iteration 10, loss = 0.48169408\n",
      "Iteration 11, loss = 0.49888898\n",
      "Iteration 12, loss = 0.47176246\n",
      "Iteration 13, loss = 0.47247057\n",
      "Iteration 14, loss = 0.47170723\n",
      "Iteration 15, loss = 0.46924708\n",
      "Iteration 16, loss = 0.46186193\n",
      "Iteration 17, loss = 0.50003623\n",
      "Iteration 18, loss = 0.48662477\n",
      "Iteration 19, loss = 0.53276396\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76256506\n",
      "Iteration 2, loss = 0.60442461\n",
      "Iteration 3, loss = 0.51485340\n",
      "Iteration 4, loss = 0.50880113\n",
      "Iteration 5, loss = 0.49356461\n",
      "Iteration 6, loss = 0.47866238\n",
      "Iteration 7, loss = 0.47411344\n",
      "Iteration 8, loss = 0.48026208\n",
      "Iteration 9, loss = 0.47912963\n",
      "Iteration 10, loss = 0.45850668\n",
      "Iteration 11, loss = 0.45806977\n",
      "Iteration 12, loss = 0.46172244\n",
      "Iteration 13, loss = 0.46104783\n",
      "Iteration 14, loss = 0.44938810\n",
      "Iteration 15, loss = 0.46622317\n",
      "Iteration 16, loss = 0.47581440\n",
      "Iteration 17, loss = 0.46075081\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77776479\n",
      "Iteration 2, loss = 0.62523421\n",
      "Iteration 3, loss = 0.53542464\n",
      "Iteration 4, loss = 0.50491868\n",
      "Iteration 5, loss = 0.51668248\n",
      "Iteration 6, loss = 0.48336634\n",
      "Iteration 7, loss = 0.47252902\n",
      "Iteration 8, loss = 0.46909690\n",
      "Iteration 9, loss = 0.49505988\n",
      "Iteration 10, loss = 0.46751004\n",
      "Iteration 11, loss = 0.48119521\n",
      "Iteration 12, loss = 0.45844416\n",
      "Iteration 13, loss = 0.46687123\n",
      "Iteration 14, loss = 0.44682007\n",
      "Iteration 15, loss = 0.44546337\n",
      "Iteration 16, loss = 0.44059313\n",
      "Iteration 17, loss = 0.44485939\n",
      "Iteration 18, loss = 0.44474068\n",
      "Iteration 19, loss = 0.45667554\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75404457\n",
      "Iteration 2, loss = 0.60610798\n",
      "Iteration 3, loss = 0.51446885\n",
      "Iteration 4, loss = 0.48043011\n",
      "Iteration 5, loss = 0.49898195\n",
      "Iteration 6, loss = 0.49704874\n",
      "Iteration 7, loss = 0.49488213\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75553872\n",
      "Iteration 2, loss = 0.57740205\n",
      "Iteration 3, loss = 0.47243259\n",
      "Iteration 4, loss = 0.45712140\n",
      "Iteration 5, loss = 0.47180227\n",
      "Iteration 6, loss = 0.45904454\n",
      "Iteration 7, loss = 0.42550958\n",
      "Iteration 8, loss = 0.43470705\n",
      "Iteration 9, loss = 0.42429158\n",
      "Iteration 10, loss = 0.43398830\n",
      "Iteration 11, loss = 0.41098229\n",
      "Iteration 12, loss = 0.42428520\n",
      "Iteration 13, loss = 0.44276240\n",
      "Iteration 14, loss = 0.48144240\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86337877\n",
      "Iteration 2, loss = 0.70941669\n",
      "Iteration 3, loss = 0.67871478\n",
      "Iteration 4, loss = 0.62717412\n",
      "Iteration 5, loss = 0.58471694\n",
      "Iteration 6, loss = 0.56956937\n",
      "Iteration 7, loss = 0.52818087\n",
      "Iteration 8, loss = 0.49410017\n",
      "Iteration 9, loss = 0.49953614\n",
      "Iteration 10, loss = 0.51501886\n",
      "Iteration 11, loss = 0.49155251\n",
      "Iteration 12, loss = 0.51251653\n",
      "Iteration 13, loss = 0.48274564\n",
      "Iteration 14, loss = 0.48039719\n",
      "Iteration 15, loss = 0.49375723\n",
      "Iteration 16, loss = 0.48347567\n",
      "Iteration 17, loss = 0.49661307\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86364557\n",
      "Iteration 2, loss = 0.65515648\n",
      "Iteration 3, loss = 0.59361546\n",
      "Iteration 4, loss = 0.54129670\n",
      "Iteration 5, loss = 0.51985174\n",
      "Iteration 6, loss = 0.51166383\n",
      "Iteration 7, loss = 0.50641575\n",
      "Iteration 8, loss = 0.50223587\n",
      "Iteration 9, loss = 0.48869820\n",
      "Iteration 10, loss = 0.48731294\n",
      "Iteration 11, loss = 0.51792941\n",
      "Iteration 12, loss = 0.50602516\n",
      "Iteration 13, loss = 0.48297659\n",
      "Iteration 14, loss = 0.48703596\n",
      "Iteration 15, loss = 0.49125864\n",
      "Iteration 16, loss = 0.49538304\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82403291\n",
      "Iteration 2, loss = 0.68305679\n",
      "Iteration 3, loss = 0.60742995\n",
      "Iteration 4, loss = 0.53062787\n",
      "Iteration 5, loss = 0.51037735\n",
      "Iteration 6, loss = 0.48558960\n",
      "Iteration 7, loss = 0.49748907\n",
      "Iteration 8, loss = 0.49901457\n",
      "Iteration 9, loss = 0.47640068\n",
      "Iteration 10, loss = 0.45940899\n",
      "Iteration 11, loss = 0.46471297\n",
      "Iteration 12, loss = 0.45138813\n",
      "Iteration 13, loss = 0.45528725\n",
      "Iteration 14, loss = 0.46205951\n",
      "Iteration 15, loss = 0.46828782\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85963719\n",
      "Iteration 2, loss = 0.72412512\n",
      "Iteration 3, loss = 0.67884862\n",
      "Iteration 4, loss = 0.63345229\n",
      "Iteration 5, loss = 0.60813853\n",
      "Iteration 6, loss = 0.57701256\n",
      "Iteration 7, loss = 0.53297557\n",
      "Iteration 8, loss = 0.50486431\n",
      "Iteration 9, loss = 0.49510815\n",
      "Iteration 10, loss = 0.49621676\n",
      "Iteration 11, loss = 0.47758868\n",
      "Iteration 12, loss = 0.49152435\n",
      "Iteration 13, loss = 0.47454568\n",
      "Iteration 14, loss = 0.46069572\n",
      "Iteration 15, loss = 0.47253239\n",
      "Iteration 16, loss = 0.47958554\n",
      "Iteration 17, loss = 0.46434213\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82112711\n",
      "Iteration 2, loss = 0.71437321\n",
      "Iteration 3, loss = 0.64459179\n",
      "Iteration 4, loss = 0.58464938\n",
      "Iteration 5, loss = 0.53109932\n",
      "Iteration 6, loss = 0.51417010\n",
      "Iteration 7, loss = 0.49325257\n",
      "Iteration 8, loss = 0.48119909\n",
      "Iteration 9, loss = 0.45588422\n",
      "Iteration 10, loss = 0.47934802\n",
      "Iteration 11, loss = 0.50808610\n",
      "Iteration 12, loss = 0.49795285\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84110174\n",
      "Iteration 2, loss = 0.70722616\n",
      "Iteration 3, loss = 0.63722490\n",
      "Iteration 4, loss = 0.58020931\n",
      "Iteration 5, loss = 0.52443179\n",
      "Iteration 6, loss = 0.52169011\n",
      "Iteration 7, loss = 0.50130545\n",
      "Iteration 8, loss = 0.52966018\n",
      "Iteration 9, loss = 0.50025662\n",
      "Iteration 10, loss = 0.48955250\n",
      "Iteration 11, loss = 0.49317441\n",
      "Iteration 12, loss = 0.53134228\n",
      "Iteration 13, loss = 0.49282815\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88132287\n",
      "Iteration 2, loss = 0.71747568\n",
      "Iteration 3, loss = 0.67108898\n",
      "Iteration 4, loss = 0.63663458\n",
      "Iteration 5, loss = 0.59520374\n",
      "Iteration 6, loss = 0.56452960\n",
      "Iteration 7, loss = 0.55259762\n",
      "Iteration 8, loss = 0.51760351\n",
      "Iteration 9, loss = 0.51024449\n",
      "Iteration 10, loss = 0.51257542\n",
      "Iteration 11, loss = 0.48836551\n",
      "Iteration 12, loss = 0.47833745\n",
      "Iteration 13, loss = 0.50293970\n",
      "Iteration 14, loss = 0.50362150\n",
      "Iteration 15, loss = 0.48302980\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81307919\n",
      "Iteration 2, loss = 0.71613480\n",
      "Iteration 3, loss = 0.67878082\n",
      "Iteration 4, loss = 0.61076128\n",
      "Iteration 5, loss = 0.53609744\n",
      "Iteration 6, loss = 0.51008329\n",
      "Iteration 7, loss = 0.47278533\n",
      "Iteration 8, loss = 0.49900487\n",
      "Iteration 9, loss = 0.49210458\n",
      "Iteration 10, loss = 0.48516215\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84070216\n",
      "Iteration 2, loss = 0.71118843\n",
      "Iteration 3, loss = 0.64826898\n",
      "Iteration 4, loss = 0.57573449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.53375077\n",
      "Iteration 6, loss = 0.53066509\n",
      "Iteration 7, loss = 0.52624545\n",
      "Iteration 8, loss = 0.55455452\n",
      "Iteration 9, loss = 0.49535489\n",
      "Iteration 10, loss = 0.48376058\n",
      "Iteration 11, loss = 0.48779599\n",
      "Iteration 12, loss = 0.47566945\n",
      "Iteration 13, loss = 0.49310513\n",
      "Iteration 14, loss = 0.51314743\n",
      "Iteration 15, loss = 0.51519542\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77105268\n",
      "Iteration 2, loss = 0.61316151\n",
      "Iteration 3, loss = 0.51172377\n",
      "Iteration 4, loss = 0.45321510\n",
      "Iteration 5, loss = 0.42434163\n",
      "Iteration 6, loss = 0.45211622\n",
      "Iteration 7, loss = 0.46076401\n",
      "Iteration 8, loss = 0.45772559\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78207440\n",
      "Iteration 2, loss = 0.56399184\n",
      "Iteration 3, loss = 0.48409850\n",
      "Iteration 4, loss = 0.46592769\n",
      "Iteration 5, loss = 0.51073597\n",
      "Iteration 6, loss = 0.49090327\n",
      "Iteration 7, loss = 0.46809216\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78975839\n",
      "Iteration 2, loss = 0.60597357\n",
      "Iteration 3, loss = 0.53181442\n",
      "Iteration 4, loss = 0.49470163\n",
      "Iteration 5, loss = 0.50355101\n",
      "Iteration 6, loss = 0.52535375\n",
      "Iteration 7, loss = 0.52583863\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77135735\n",
      "Iteration 2, loss = 0.58581286\n",
      "Iteration 3, loss = 0.50547139\n",
      "Iteration 4, loss = 0.47987921\n",
      "Iteration 5, loss = 0.49434860\n",
      "Iteration 6, loss = 0.51545486\n",
      "Iteration 7, loss = 0.52666602\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78708588\n",
      "Iteration 2, loss = 0.62245610\n",
      "Iteration 3, loss = 0.54234689\n",
      "Iteration 4, loss = 0.49783228\n",
      "Iteration 5, loss = 0.49706781\n",
      "Iteration 6, loss = 0.49122255\n",
      "Iteration 7, loss = 0.46881074\n",
      "Iteration 8, loss = 0.47692188\n",
      "Iteration 9, loss = 0.48377956\n",
      "Iteration 10, loss = 0.46251075\n",
      "Iteration 11, loss = 0.47893929\n",
      "Iteration 12, loss = 0.49749249\n",
      "Iteration 13, loss = 0.48190451\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.79051512\n",
      "Iteration 2, loss = 0.63540893\n",
      "Iteration 3, loss = 0.55012563\n",
      "Iteration 4, loss = 0.50776558\n",
      "Iteration 5, loss = 0.48987222\n",
      "Iteration 6, loss = 0.48656424\n",
      "Iteration 7, loss = 0.46877900\n",
      "Iteration 8, loss = 0.47889509\n",
      "Iteration 9, loss = 0.46382317\n",
      "Iteration 10, loss = 0.47667981\n",
      "Iteration 11, loss = 0.50684557\n",
      "Iteration 12, loss = 0.50826220\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80772144\n",
      "Iteration 2, loss = 0.67006376\n",
      "Iteration 3, loss = 0.60320954\n",
      "Iteration 4, loss = 0.56089408\n",
      "Iteration 5, loss = 0.52800975\n",
      "Iteration 6, loss = 0.53628832\n",
      "Iteration 7, loss = 0.53694621\n",
      "Iteration 8, loss = 0.49590979\n",
      "Iteration 9, loss = 0.51777527\n",
      "Iteration 10, loss = 0.53508816\n",
      "Iteration 11, loss = 0.48852974\n",
      "Iteration 12, loss = 0.49627176\n",
      "Iteration 13, loss = 0.51795875\n",
      "Iteration 14, loss = 0.51332642\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78939785\n",
      "Iteration 2, loss = 0.60628460\n",
      "Iteration 3, loss = 0.52945015\n",
      "Iteration 4, loss = 0.49445825\n",
      "Iteration 5, loss = 0.49433255\n",
      "Iteration 6, loss = 0.49854494\n",
      "Iteration 7, loss = 0.50441128\n",
      "Iteration 8, loss = 0.52661467\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81210703\n",
      "Iteration 2, loss = 0.60288730\n",
      "Iteration 3, loss = 0.52085594\n",
      "Iteration 4, loss = 0.49190555\n",
      "Iteration 5, loss = 0.49497199\n",
      "Iteration 6, loss = 0.51917502\n",
      "Iteration 7, loss = 0.51101450\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81607023\n",
      "Iteration 2, loss = 0.62322286\n",
      "Iteration 3, loss = 0.55137776\n",
      "Iteration 4, loss = 0.50584500\n",
      "Iteration 5, loss = 0.50204889\n",
      "Iteration 6, loss = 0.51474020\n",
      "Iteration 7, loss = 0.48402105\n",
      "Iteration 8, loss = 0.47831182\n",
      "Iteration 9, loss = 0.49521902\n",
      "Iteration 10, loss = 0.49253364\n",
      "Iteration 11, loss = 0.48847860\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77399771\n",
      "Iteration 2, loss = 0.56586848\n",
      "Iteration 3, loss = 0.48160085\n",
      "Iteration 4, loss = 0.44554070\n",
      "Iteration 5, loss = 0.43706337\n",
      "Iteration 6, loss = 0.42890499\n",
      "Iteration 7, loss = 0.42389271\n",
      "Iteration 8, loss = 0.41563451\n",
      "Iteration 9, loss = 0.42485281\n",
      "Iteration 10, loss = 0.40873412\n",
      "Iteration 11, loss = 0.41170984\n",
      "Iteration 12, loss = 0.45259720\n",
      "Iteration 13, loss = 0.44729953\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.93837096\n",
      "Iteration 2, loss = 0.69865038\n",
      "Iteration 3, loss = 0.65534280\n",
      "Iteration 4, loss = 0.58810455\n",
      "Iteration 5, loss = 0.52435768\n",
      "Iteration 6, loss = 0.49341353\n",
      "Iteration 7, loss = 0.51049188\n",
      "Iteration 8, loss = 0.48963931\n",
      "Iteration 9, loss = 0.46360594\n",
      "Iteration 10, loss = 0.43272566\n",
      "Iteration 11, loss = 0.47670568\n",
      "Iteration 12, loss = 0.45699566\n",
      "Iteration 13, loss = 0.47402774\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91331817\n",
      "Iteration 2, loss = 0.68424501\n",
      "Iteration 3, loss = 0.63389914\n",
      "Iteration 4, loss = 0.59977351\n",
      "Iteration 5, loss = 0.54404685\n",
      "Iteration 6, loss = 0.52490047\n",
      "Iteration 7, loss = 0.50928947\n",
      "Iteration 8, loss = 0.51896823\n",
      "Iteration 9, loss = 0.51981904\n",
      "Iteration 10, loss = 0.48973466\n",
      "Iteration 11, loss = 0.51638120\n",
      "Iteration 12, loss = 0.51518380\n",
      "Iteration 13, loss = 0.51786142\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89832069\n",
      "Iteration 2, loss = 0.70329267\n",
      "Iteration 3, loss = 0.64277044\n",
      "Iteration 4, loss = 0.60161184\n",
      "Iteration 5, loss = 0.56726548\n",
      "Iteration 6, loss = 0.54352601\n",
      "Iteration 7, loss = 0.49921084\n",
      "Iteration 8, loss = 0.49783506\n",
      "Iteration 9, loss = 0.49715766\n",
      "Iteration 10, loss = 0.48569920\n",
      "Iteration 11, loss = 0.52763575\n",
      "Iteration 12, loss = 0.50700014\n",
      "Iteration 13, loss = 0.50909215\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87877785\n",
      "Iteration 2, loss = 0.69343876\n",
      "Iteration 3, loss = 0.65612723\n",
      "Iteration 4, loss = 0.63968489\n",
      "Iteration 5, loss = 0.61257034\n",
      "Iteration 6, loss = 0.57940755\n",
      "Iteration 7, loss = 0.54876921\n",
      "Iteration 8, loss = 0.52734015\n",
      "Iteration 9, loss = 0.55538952\n",
      "Iteration 10, loss = 0.54098251\n",
      "Iteration 11, loss = 0.53669663\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86765118\n",
      "Iteration 2, loss = 0.67292274\n",
      "Iteration 3, loss = 0.63197944\n",
      "Iteration 4, loss = 0.57187979\n",
      "Iteration 5, loss = 0.53683998\n",
      "Iteration 6, loss = 0.52063870\n",
      "Iteration 7, loss = 0.50477648\n",
      "Iteration 8, loss = 0.49346911\n",
      "Iteration 9, loss = 0.47041522\n",
      "Iteration 10, loss = 0.47658982\n",
      "Iteration 11, loss = 0.46566975\n",
      "Iteration 12, loss = 0.47250363\n",
      "Iteration 13, loss = 0.48131258\n",
      "Iteration 14, loss = 0.47272973\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91792667\n",
      "Iteration 2, loss = 0.68452485\n",
      "Iteration 3, loss = 0.62344499\n",
      "Iteration 4, loss = 0.59329072\n",
      "Iteration 5, loss = 0.54969716\n",
      "Iteration 6, loss = 0.54934076\n",
      "Iteration 7, loss = 0.54211504\n",
      "Iteration 8, loss = 0.53432755\n",
      "Iteration 9, loss = 0.51381782\n",
      "Iteration 10, loss = 0.51368716\n",
      "Iteration 11, loss = 0.49356117\n",
      "Iteration 12, loss = 0.49058612\n",
      "Iteration 13, loss = 0.48627178\n",
      "Iteration 14, loss = 0.51937490\n",
      "Iteration 15, loss = 0.50765866\n",
      "Iteration 16, loss = 0.50515325\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89691535\n",
      "Iteration 2, loss = 0.65917458\n",
      "Iteration 3, loss = 0.59581237\n",
      "Iteration 4, loss = 0.54843012\n",
      "Iteration 5, loss = 0.49940996\n",
      "Iteration 6, loss = 0.48966987\n",
      "Iteration 7, loss = 0.50838073\n",
      "Iteration 8, loss = 0.51175280\n",
      "Iteration 9, loss = 0.50001609\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.90215743\n",
      "Iteration 2, loss = 0.68413758\n",
      "Iteration 3, loss = 0.62900351\n",
      "Iteration 4, loss = 0.56132937\n",
      "Iteration 5, loss = 0.53284614\n",
      "Iteration 6, loss = 0.50270648\n",
      "Iteration 7, loss = 0.50518957\n",
      "Iteration 8, loss = 0.48828164\n",
      "Iteration 9, loss = 0.48122266\n",
      "Iteration 10, loss = 0.48157714\n",
      "Iteration 11, loss = 0.49136038\n",
      "Iteration 12, loss = 0.47149769\n",
      "Iteration 13, loss = 0.46291137\n",
      "Iteration 14, loss = 0.45720160\n",
      "Iteration 15, loss = 0.49777328\n",
      "Iteration 16, loss = 0.54529423\n",
      "Iteration 17, loss = 0.47537099\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86610659\n",
      "Iteration 2, loss = 0.65631900\n",
      "Iteration 3, loss = 0.57962733\n",
      "Iteration 4, loss = 0.53429441\n",
      "Iteration 5, loss = 0.54278314\n",
      "Iteration 6, loss = 0.51958595\n",
      "Iteration 7, loss = 0.52629185\n",
      "Iteration 8, loss = 0.50535755\n",
      "Iteration 9, loss = 0.48923670\n",
      "Iteration 10, loss = 0.48391349\n",
      "Iteration 11, loss = 0.46998054\n",
      "Iteration 12, loss = 0.46800114\n",
      "Iteration 13, loss = 0.48696449\n",
      "Iteration 14, loss = 0.49618321\n",
      "Iteration 15, loss = 0.49055734\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89480607\n",
      "Iteration 2, loss = 0.65987124\n",
      "Iteration 3, loss = 0.57409812\n",
      "Iteration 4, loss = 0.48547398\n",
      "Iteration 5, loss = 0.47277065\n",
      "Iteration 6, loss = 0.42666334\n",
      "Iteration 7, loss = 0.45514872\n",
      "Iteration 8, loss = 0.45872645\n",
      "Iteration 9, loss = 0.44686223\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86746646\n",
      "Iteration 2, loss = 0.65980567\n",
      "Iteration 3, loss = 0.57680713\n",
      "Iteration 4, loss = 0.51370876\n",
      "Iteration 5, loss = 0.48342243\n",
      "Iteration 6, loss = 0.46637244\n",
      "Iteration 7, loss = 0.50608037\n",
      "Iteration 8, loss = 0.47563228\n",
      "Iteration 9, loss = 0.46248776\n",
      "Iteration 10, loss = 0.46584420\n",
      "Iteration 11, loss = 0.47616889\n",
      "Iteration 12, loss = 0.46654087\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86678415\n",
      "Iteration 2, loss = 0.66983122\n",
      "Iteration 3, loss = 0.63193432\n",
      "Iteration 4, loss = 0.58956549\n",
      "Iteration 5, loss = 0.53525846\n",
      "Iteration 6, loss = 0.51640424\n",
      "Iteration 7, loss = 0.50803506\n",
      "Iteration 8, loss = 0.47939714\n",
      "Iteration 9, loss = 0.50119632\n",
      "Iteration 10, loss = 0.49395323\n",
      "Iteration 11, loss = 0.49938514\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87011145\n",
      "Iteration 2, loss = 0.68007566\n",
      "Iteration 3, loss = 0.60043744\n",
      "Iteration 4, loss = 0.54087905\n",
      "Iteration 5, loss = 0.49786919\n",
      "Iteration 6, loss = 0.49116694\n",
      "Iteration 7, loss = 0.48759441\n",
      "Iteration 8, loss = 0.49843930\n",
      "Iteration 9, loss = 0.51536206\n",
      "Iteration 10, loss = 0.49680452\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89684780\n",
      "Iteration 2, loss = 0.68883590\n",
      "Iteration 3, loss = 0.64064350\n",
      "Iteration 4, loss = 0.55524335\n",
      "Iteration 5, loss = 0.53566372\n",
      "Iteration 6, loss = 0.53225149\n",
      "Iteration 7, loss = 0.49957815\n",
      "Iteration 8, loss = 0.52104319\n",
      "Iteration 9, loss = 0.52871344\n",
      "Iteration 10, loss = 0.47778343\n",
      "Iteration 11, loss = 0.47130538\n",
      "Iteration 12, loss = 0.48674760\n",
      "Iteration 13, loss = 0.47206911\n",
      "Iteration 14, loss = 0.47597918\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87572442\n",
      "Iteration 2, loss = 0.69025115\n",
      "Iteration 3, loss = 0.64178428\n",
      "Iteration 4, loss = 0.58370583\n",
      "Iteration 5, loss = 0.54299741\n",
      "Iteration 6, loss = 0.56404858\n",
      "Iteration 7, loss = 0.58565225\n",
      "Iteration 8, loss = 0.56515934\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85158664\n",
      "Iteration 2, loss = 0.66065877\n",
      "Iteration 3, loss = 0.58761718\n",
      "Iteration 4, loss = 0.51579831\n",
      "Iteration 5, loss = 0.50352279\n",
      "Iteration 6, loss = 0.49815819\n",
      "Iteration 7, loss = 0.48297040\n",
      "Iteration 8, loss = 0.49025163\n",
      "Iteration 9, loss = 0.47974226\n",
      "Iteration 10, loss = 0.46099339\n",
      "Iteration 11, loss = 0.46247923\n",
      "Iteration 12, loss = 0.47007459\n",
      "Iteration 13, loss = 0.47638889\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84973649\n",
      "Iteration 2, loss = 0.68078743\n",
      "Iteration 3, loss = 0.63761945\n",
      "Iteration 4, loss = 0.57827744\n",
      "Iteration 5, loss = 0.52418169\n",
      "Iteration 6, loss = 0.53012139\n",
      "Iteration 7, loss = 0.49852862\n",
      "Iteration 8, loss = 0.48151967\n",
      "Iteration 9, loss = 0.53048120\n",
      "Iteration 10, loss = 0.49881483\n",
      "Iteration 11, loss = 0.48745750\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84754792\n",
      "Iteration 2, loss = 0.64438849\n",
      "Iteration 3, loss = 0.59182439\n",
      "Iteration 4, loss = 0.52349816\n",
      "Iteration 5, loss = 0.50571230\n",
      "Iteration 6, loss = 0.48771351\n",
      "Iteration 7, loss = 0.50049461\n",
      "Iteration 8, loss = 0.49339561\n",
      "Iteration 9, loss = 0.49381100\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83448544\n",
      "Iteration 2, loss = 0.63001332\n",
      "Iteration 3, loss = 0.56057941\n",
      "Iteration 4, loss = 0.51459177\n",
      "Iteration 5, loss = 0.50920262\n",
      "Iteration 6, loss = 0.48153726\n",
      "Iteration 7, loss = 0.49167454\n",
      "Iteration 8, loss = 0.50074087\n",
      "Iteration 9, loss = 0.52987910\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86766301\n",
      "Iteration 2, loss = 0.65608805\n",
      "Iteration 3, loss = 0.57936569\n",
      "Iteration 4, loss = 0.50713881\n",
      "Iteration 5, loss = 0.47593170\n",
      "Iteration 6, loss = 0.43384512\n",
      "Iteration 7, loss = 0.42221944\n",
      "Iteration 8, loss = 0.43720139\n",
      "Iteration 9, loss = 0.45341235\n",
      "Iteration 10, loss = 0.44853107\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90752724\n",
      "Iteration 2, loss = 0.68728381\n",
      "Iteration 3, loss = 0.63051934\n",
      "Iteration 4, loss = 0.60699600\n",
      "Iteration 5, loss = 0.55306989\n",
      "Iteration 6, loss = 0.53887137\n",
      "Iteration 7, loss = 0.51544917\n",
      "Iteration 8, loss = 0.49998421\n",
      "Iteration 9, loss = 0.50402125\n",
      "Iteration 10, loss = 0.46826589\n",
      "Iteration 11, loss = 0.47498831\n",
      "Iteration 12, loss = 0.46668517\n",
      "Iteration 13, loss = 0.47069011\n",
      "Iteration 14, loss = 0.47271593\n",
      "Iteration 15, loss = 0.47410427\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90226171\n",
      "Iteration 2, loss = 0.69422593\n",
      "Iteration 3, loss = 0.64884626\n",
      "Iteration 4, loss = 0.58845206\n",
      "Iteration 5, loss = 0.53202799\n",
      "Iteration 6, loss = 0.52914206\n",
      "Iteration 7, loss = 0.48575984\n",
      "Iteration 8, loss = 0.48678458\n",
      "Iteration 9, loss = 0.47427480\n",
      "Iteration 10, loss = 0.48257259\n",
      "Iteration 11, loss = 0.47254256\n",
      "Iteration 12, loss = 0.47857882\n",
      "Iteration 13, loss = 0.46243480\n",
      "Iteration 14, loss = 0.45788663\n",
      "Iteration 15, loss = 0.47874749\n",
      "Iteration 16, loss = 0.45381064\n",
      "Iteration 17, loss = 0.46028163\n",
      "Iteration 18, loss = 0.45645779\n",
      "Iteration 19, loss = 0.47203508\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89033876\n",
      "Iteration 2, loss = 0.68931679\n",
      "Iteration 3, loss = 0.61885654\n",
      "Iteration 4, loss = 0.56927340\n",
      "Iteration 5, loss = 0.52593599\n",
      "Iteration 6, loss = 0.50485873\n",
      "Iteration 7, loss = 0.49816650\n",
      "Iteration 8, loss = 0.48788007\n",
      "Iteration 9, loss = 0.48358166\n",
      "Iteration 10, loss = 0.48716401\n",
      "Iteration 11, loss = 0.49207485\n",
      "Iteration 12, loss = 0.49749589\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87379675\n",
      "Iteration 2, loss = 0.68844104\n",
      "Iteration 3, loss = 0.62562253\n",
      "Iteration 4, loss = 0.60502359\n",
      "Iteration 5, loss = 0.54532855\n",
      "Iteration 6, loss = 0.52379133\n",
      "Iteration 7, loss = 0.51782693\n",
      "Iteration 8, loss = 0.49718328\n",
      "Iteration 9, loss = 0.50890398\n",
      "Iteration 10, loss = 0.51709949\n",
      "Iteration 11, loss = 0.53115145\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88899071\n",
      "Iteration 2, loss = 0.65122044\n",
      "Iteration 3, loss = 0.59693908\n",
      "Iteration 4, loss = 0.55021865\n",
      "Iteration 5, loss = 0.53789478\n",
      "Iteration 6, loss = 0.55488383\n",
      "Iteration 7, loss = 0.50814716\n",
      "Iteration 8, loss = 0.51161684\n",
      "Iteration 9, loss = 0.51906837\n",
      "Iteration 10, loss = 0.49119125\n",
      "Iteration 11, loss = 0.50183803\n",
      "Iteration 12, loss = 0.48545190\n",
      "Iteration 13, loss = 0.47773519\n",
      "Iteration 14, loss = 0.49262204\n",
      "Iteration 15, loss = 0.53095072\n",
      "Iteration 16, loss = 0.50378124\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.90779861\n",
      "Iteration 2, loss = 0.72671527\n",
      "Iteration 3, loss = 0.66402968\n",
      "Iteration 4, loss = 0.60679901\n",
      "Iteration 5, loss = 0.55478698\n",
      "Iteration 6, loss = 0.52069006\n",
      "Iteration 7, loss = 0.53819417\n",
      "Iteration 8, loss = 0.51375017\n",
      "Iteration 9, loss = 0.52644584\n",
      "Iteration 10, loss = 0.54473958\n",
      "Iteration 11, loss = 0.54017592\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89949643\n",
      "Iteration 2, loss = 0.70579599\n",
      "Iteration 3, loss = 0.65787794\n",
      "Iteration 4, loss = 0.62521910\n",
      "Iteration 5, loss = 0.55645089\n",
      "Iteration 6, loss = 0.51343817\n",
      "Iteration 7, loss = 0.50833450\n",
      "Iteration 8, loss = 0.53146838\n",
      "Iteration 9, loss = 0.50038928\n",
      "Iteration 10, loss = 0.47890397\n",
      "Iteration 11, loss = 0.49649402\n",
      "Iteration 12, loss = 0.47625368\n",
      "Iteration 13, loss = 0.46259943\n",
      "Iteration 14, loss = 0.50519490\n",
      "Iteration 15, loss = 0.50946064\n",
      "Iteration 16, loss = 0.49154478\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88349346\n",
      "Iteration 2, loss = 0.67547169\n",
      "Iteration 3, loss = 0.62156052\n",
      "Iteration 4, loss = 0.63253871\n",
      "Iteration 5, loss = 0.55137046\n",
      "Iteration 6, loss = 0.50506726\n",
      "Iteration 7, loss = 0.52011087\n",
      "Iteration 8, loss = 0.47539535\n",
      "Iteration 9, loss = 0.46683841\n",
      "Iteration 10, loss = 0.46729130\n",
      "Iteration 11, loss = 0.49385702\n",
      "Iteration 12, loss = 0.48127776\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87015531\n",
      "Iteration 2, loss = 0.67405342\n",
      "Iteration 3, loss = 0.61884794\n",
      "Iteration 4, loss = 0.58539937\n",
      "Iteration 5, loss = 0.53850080\n",
      "Iteration 6, loss = 0.50101194\n",
      "Iteration 7, loss = 0.48468358\n",
      "Iteration 8, loss = 0.48064260\n",
      "Iteration 9, loss = 0.49175505\n",
      "Iteration 10, loss = 0.49367227\n",
      "Iteration 11, loss = 0.49247538\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89013813\n",
      "Iteration 2, loss = 0.67166229\n",
      "Iteration 3, loss = 0.60274394\n",
      "Iteration 4, loss = 0.54391241\n",
      "Iteration 5, loss = 0.48978276\n",
      "Iteration 6, loss = 0.47469971\n",
      "Iteration 7, loss = 0.46458160\n",
      "Iteration 8, loss = 0.45037092\n",
      "Iteration 9, loss = 0.46100189\n",
      "Iteration 10, loss = 0.43851248\n",
      "Iteration 11, loss = 0.41022363\n",
      "Iteration 12, loss = 0.41541437\n",
      "Iteration 13, loss = 0.41785621\n",
      "Iteration 14, loss = 0.45524304\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81936863\n",
      "Iteration 2, loss = 0.68085971\n",
      "Iteration 3, loss = 0.63518601\n",
      "Iteration 4, loss = 0.57953429\n",
      "Iteration 5, loss = 0.50301655\n",
      "Iteration 6, loss = 0.48307079\n",
      "Iteration 7, loss = 0.47104767\n",
      "Iteration 8, loss = 0.45737127\n",
      "Iteration 9, loss = 0.47500221\n",
      "Iteration 10, loss = 0.47495887\n",
      "Iteration 11, loss = 0.46108815\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84927127\n",
      "Iteration 2, loss = 0.69388484\n",
      "Iteration 3, loss = 0.62193111\n",
      "Iteration 4, loss = 0.53580233\n",
      "Iteration 5, loss = 0.52490796\n",
      "Iteration 6, loss = 0.50476402\n",
      "Iteration 7, loss = 0.49998180\n",
      "Iteration 8, loss = 0.47122817\n",
      "Iteration 9, loss = 0.47414978\n",
      "Iteration 10, loss = 0.48533783\n",
      "Iteration 11, loss = 0.53025759\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83682595\n",
      "Iteration 2, loss = 0.68640721\n",
      "Iteration 3, loss = 0.62397567\n",
      "Iteration 4, loss = 0.55136941\n",
      "Iteration 5, loss = 0.52156821\n",
      "Iteration 6, loss = 0.49490180\n",
      "Iteration 7, loss = 0.49751824\n",
      "Iteration 8, loss = 0.48180521\n",
      "Iteration 9, loss = 0.50002927\n",
      "Iteration 10, loss = 0.51392377\n",
      "Iteration 11, loss = 0.50977411\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85927072\n",
      "Iteration 2, loss = 0.69748111\n",
      "Iteration 3, loss = 0.63395786\n",
      "Iteration 4, loss = 0.55407621\n",
      "Iteration 5, loss = 0.51324648\n",
      "Iteration 6, loss = 0.50042636\n",
      "Iteration 7, loss = 0.48275843\n",
      "Iteration 8, loss = 0.49867786\n",
      "Iteration 9, loss = 0.48853776\n",
      "Iteration 10, loss = 0.50811882\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84547696\n",
      "Iteration 2, loss = 0.65711375\n",
      "Iteration 3, loss = 0.58744984\n",
      "Iteration 4, loss = 0.53300111\n",
      "Iteration 5, loss = 0.53937245\n",
      "Iteration 6, loss = 0.51605170\n",
      "Iteration 7, loss = 0.48580401\n",
      "Iteration 8, loss = 0.47872541\n",
      "Iteration 9, loss = 0.49460117\n",
      "Iteration 10, loss = 0.51011547\n",
      "Iteration 11, loss = 0.48490098\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82536031\n",
      "Iteration 2, loss = 0.67307686\n",
      "Iteration 3, loss = 0.57938443\n",
      "Iteration 4, loss = 0.52967293\n",
      "Iteration 5, loss = 0.51418156\n",
      "Iteration 6, loss = 0.49905114\n",
      "Iteration 7, loss = 0.49219739\n",
      "Iteration 8, loss = 0.50470870\n",
      "Iteration 9, loss = 0.52507163\n",
      "Iteration 10, loss = 0.53505830\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86245944\n",
      "Iteration 2, loss = 0.68872974\n",
      "Iteration 3, loss = 0.61219585\n",
      "Iteration 4, loss = 0.55603574\n",
      "Iteration 5, loss = 0.54529828\n",
      "Iteration 6, loss = 0.51396477\n",
      "Iteration 7, loss = 0.50905170\n",
      "Iteration 8, loss = 0.52262783\n",
      "Iteration 9, loss = 0.50301804\n",
      "Iteration 10, loss = 0.49252753\n",
      "Iteration 11, loss = 0.50578547\n",
      "Iteration 12, loss = 0.50744371\n",
      "Iteration 13, loss = 0.50192934\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88094881\n",
      "Iteration 2, loss = 0.69994376\n",
      "Iteration 3, loss = 0.62903956\n",
      "Iteration 4, loss = 0.56806257\n",
      "Iteration 5, loss = 0.53556995\n",
      "Iteration 6, loss = 0.52387362\n",
      "Iteration 7, loss = 0.50847975\n",
      "Iteration 8, loss = 0.49268880\n",
      "Iteration 9, loss = 0.48615172\n",
      "Iteration 10, loss = 0.49412840\n",
      "Iteration 11, loss = 0.48153759\n",
      "Iteration 12, loss = 0.48276377\n",
      "Iteration 13, loss = 0.53051863\n",
      "Iteration 14, loss = 0.51945702\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88615943\n",
      "Iteration 2, loss = 0.70361974\n",
      "Iteration 3, loss = 0.61982929\n",
      "Iteration 4, loss = 0.54268215\n",
      "Iteration 5, loss = 0.52469091\n",
      "Iteration 6, loss = 0.52771476\n",
      "Iteration 7, loss = 0.50116174\n",
      "Iteration 8, loss = 0.52785516\n",
      "Iteration 9, loss = 0.49654997\n",
      "Iteration 10, loss = 0.48389460\n",
      "Iteration 11, loss = 0.51195124\n",
      "Iteration 12, loss = 0.51107966\n",
      "Iteration 13, loss = 0.50705770\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84737433\n",
      "Iteration 2, loss = 0.71688373\n",
      "Iteration 3, loss = 0.63835709\n",
      "Iteration 4, loss = 0.55623318\n",
      "Iteration 5, loss = 0.49342950\n",
      "Iteration 6, loss = 0.46969786\n",
      "Iteration 7, loss = 0.43959247\n",
      "Iteration 8, loss = 0.43832618\n",
      "Iteration 9, loss = 0.46373561\n",
      "Iteration 10, loss = 0.44507909\n",
      "Iteration 11, loss = 0.46240932\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85143298\n",
      "Iteration 2, loss = 0.67325912\n",
      "Iteration 3, loss = 0.61002649\n",
      "Iteration 4, loss = 0.52700879\n",
      "Iteration 5, loss = 0.51042891\n",
      "Iteration 6, loss = 0.47916972\n",
      "Iteration 7, loss = 0.51247346\n",
      "Iteration 8, loss = 0.50110210\n",
      "Iteration 9, loss = 0.48985489\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80124058\n",
      "Iteration 2, loss = 0.66319253\n",
      "Iteration 3, loss = 0.56599296\n",
      "Iteration 4, loss = 0.52371287\n",
      "Iteration 5, loss = 0.51395337\n",
      "Iteration 6, loss = 0.51603466\n",
      "Iteration 7, loss = 0.49950388\n",
      "Iteration 8, loss = 0.47661319\n",
      "Iteration 9, loss = 0.47306045\n",
      "Iteration 10, loss = 0.52060428\n",
      "Iteration 11, loss = 0.49163370\n",
      "Iteration 12, loss = 0.50134929\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80535696\n",
      "Iteration 2, loss = 0.66690353\n",
      "Iteration 3, loss = 0.58794347\n",
      "Iteration 4, loss = 0.52830945\n",
      "Iteration 5, loss = 0.50882356\n",
      "Iteration 6, loss = 0.50179771\n",
      "Iteration 7, loss = 0.49666136\n",
      "Iteration 8, loss = 0.49274468\n",
      "Iteration 9, loss = 0.49948251\n",
      "Iteration 10, loss = 0.51006820\n",
      "Iteration 11, loss = 0.50676382\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.83377778\n",
      "Iteration 2, loss = 0.68806233\n",
      "Iteration 3, loss = 0.58608264\n",
      "Iteration 4, loss = 0.52025704\n",
      "Iteration 5, loss = 0.51003035\n",
      "Iteration 6, loss = 0.50424508\n",
      "Iteration 7, loss = 0.50812437\n",
      "Iteration 8, loss = 0.49228474\n",
      "Iteration 9, loss = 0.48359809\n",
      "Iteration 10, loss = 0.49677814\n",
      "Iteration 11, loss = 0.47729706\n",
      "Iteration 12, loss = 0.50518106\n",
      "Iteration 13, loss = 0.50305412\n",
      "Iteration 14, loss = 0.51121809\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83085158\n",
      "Iteration 2, loss = 0.70353533\n",
      "Iteration 3, loss = 0.64270798\n",
      "Iteration 4, loss = 0.56120027\n",
      "Iteration 5, loss = 0.50175460\n",
      "Iteration 6, loss = 0.48981452\n",
      "Iteration 7, loss = 0.50278572\n",
      "Iteration 8, loss = 0.48194263\n",
      "Iteration 9, loss = 0.49189486\n",
      "Iteration 10, loss = 0.48444052\n",
      "Iteration 11, loss = 0.49358083\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82341587\n",
      "Iteration 2, loss = 0.66259983\n",
      "Iteration 3, loss = 0.61696392\n",
      "Iteration 4, loss = 0.56168257\n",
      "Iteration 5, loss = 0.53053213\n",
      "Iteration 6, loss = 0.50399897\n",
      "Iteration 7, loss = 0.49394896\n",
      "Iteration 8, loss = 0.47716630\n",
      "Iteration 9, loss = 0.48262915\n",
      "Iteration 10, loss = 0.46060223\n",
      "Iteration 11, loss = 0.50226980\n",
      "Iteration 12, loss = 0.50926628\n",
      "Iteration 13, loss = 0.51798068\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84646057\n",
      "Iteration 2, loss = 0.66267744\n",
      "Iteration 3, loss = 0.60927659\n",
      "Iteration 4, loss = 0.52405447\n",
      "Iteration 5, loss = 0.51523921\n",
      "Iteration 6, loss = 0.49671866\n",
      "Iteration 7, loss = 0.51310503\n",
      "Iteration 8, loss = 0.50005270\n",
      "Iteration 9, loss = 0.51484877\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80969501\n",
      "Iteration 2, loss = 0.69920971\n",
      "Iteration 3, loss = 0.73249813\n",
      "Iteration 4, loss = 0.63537377\n",
      "Iteration 5, loss = 0.59231688\n",
      "Iteration 6, loss = 0.56661006\n",
      "Iteration 7, loss = 0.55476619\n",
      "Iteration 8, loss = 0.51428516\n",
      "Iteration 9, loss = 0.60032006\n",
      "Iteration 10, loss = 0.51109509\n",
      "Iteration 11, loss = 0.48115047\n",
      "Iteration 12, loss = 0.48465883\n",
      "Iteration 13, loss = 0.49249026\n",
      "Iteration 14, loss = 0.48943926\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88278477\n",
      "Iteration 2, loss = 0.68155652\n",
      "Iteration 3, loss = 0.62902599\n",
      "Iteration 4, loss = 0.57590566\n",
      "Iteration 5, loss = 0.53964673\n",
      "Iteration 6, loss = 0.49903784\n",
      "Iteration 7, loss = 0.49353469\n",
      "Iteration 8, loss = 0.49266647\n",
      "Iteration 9, loss = 0.49338098\n",
      "Iteration 10, loss = 0.48678080\n",
      "Iteration 11, loss = 0.48103251\n",
      "Iteration 12, loss = 0.47231537\n",
      "Iteration 13, loss = 0.48543426\n",
      "Iteration 14, loss = 0.48966957\n",
      "Iteration 15, loss = 0.46587392\n",
      "Iteration 16, loss = 0.47679174\n",
      "Iteration 17, loss = 0.50068470\n",
      "Iteration 18, loss = 0.52140398\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.77065786\n",
      "Iteration 2, loss = 0.58370136\n",
      "Iteration 3, loss = 0.48632384\n",
      "Iteration 4, loss = 0.43626802\n",
      "Iteration 5, loss = 0.40731669\n",
      "Iteration 6, loss = 0.41888829\n",
      "Iteration 7, loss = 0.43247934\n",
      "Iteration 8, loss = 0.44088202\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81432276\n",
      "Iteration 2, loss = 0.66600036\n",
      "Iteration 3, loss = 0.57709440\n",
      "Iteration 4, loss = 0.52797989\n",
      "Iteration 5, loss = 0.51998011\n",
      "Iteration 6, loss = 0.49844694\n",
      "Iteration 7, loss = 0.49662744\n",
      "Iteration 8, loss = 0.49989557\n",
      "Iteration 9, loss = 0.48094214\n",
      "Iteration 10, loss = 0.47214650\n",
      "Iteration 11, loss = 0.48382408\n",
      "Iteration 12, loss = 0.49825557\n",
      "Iteration 13, loss = 0.47663881\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83730680\n",
      "Iteration 2, loss = 0.66510874\n",
      "Iteration 3, loss = 0.60284995\n",
      "Iteration 4, loss = 0.55310176\n",
      "Iteration 5, loss = 0.52990598\n",
      "Iteration 6, loss = 0.53138043\n",
      "Iteration 7, loss = 0.49525925\n",
      "Iteration 8, loss = 0.47177015\n",
      "Iteration 9, loss = 0.47527899\n",
      "Iteration 10, loss = 0.47029197\n",
      "Iteration 11, loss = 0.46738949\n",
      "Iteration 12, loss = 0.46871953\n",
      "Iteration 13, loss = 0.46086720\n",
      "Iteration 14, loss = 0.46719292\n",
      "Iteration 15, loss = 0.47908619\n",
      "Iteration 16, loss = 0.45426922\n",
      "Iteration 17, loss = 0.48771597\n",
      "Iteration 18, loss = 0.47601672\n",
      "Iteration 19, loss = 0.46812718\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83203483\n",
      "Iteration 2, loss = 0.66359628\n",
      "Iteration 3, loss = 0.57732205\n",
      "Iteration 4, loss = 0.51600132\n",
      "Iteration 5, loss = 0.49077383\n",
      "Iteration 6, loss = 0.50647006\n",
      "Iteration 7, loss = 0.49874158\n",
      "Iteration 8, loss = 0.49634012\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82146017\n",
      "Iteration 2, loss = 0.66896380\n",
      "Iteration 3, loss = 0.58093328\n",
      "Iteration 4, loss = 0.53611924\n",
      "Iteration 5, loss = 0.51692421\n",
      "Iteration 6, loss = 0.50197995\n",
      "Iteration 7, loss = 0.49652141\n",
      "Iteration 8, loss = 0.49219649\n",
      "Iteration 9, loss = 0.46565584\n",
      "Iteration 10, loss = 0.48494322\n",
      "Iteration 11, loss = 0.47151173\n",
      "Iteration 12, loss = 0.45486972\n",
      "Iteration 13, loss = 0.47394458\n",
      "Iteration 14, loss = 0.48294572\n",
      "Iteration 15, loss = 0.50285658\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83898798\n",
      "Iteration 2, loss = 0.66427633\n",
      "Iteration 3, loss = 0.57532188\n",
      "Iteration 4, loss = 0.49926410\n",
      "Iteration 5, loss = 0.49034388\n",
      "Iteration 6, loss = 0.49852742\n",
      "Iteration 7, loss = 0.49140268\n",
      "Iteration 8, loss = 0.46482718\n",
      "Iteration 9, loss = 0.45395116\n",
      "Iteration 10, loss = 0.48374272\n",
      "Iteration 11, loss = 0.46338145\n",
      "Iteration 12, loss = 0.45122174\n",
      "Iteration 13, loss = 0.45589569\n",
      "Iteration 14, loss = 0.47314110\n",
      "Iteration 15, loss = 0.45334497\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88537118\n",
      "Iteration 2, loss = 0.71095178\n",
      "Iteration 3, loss = 0.65780144\n",
      "Iteration 4, loss = 0.59251032\n",
      "Iteration 5, loss = 0.53646228\n",
      "Iteration 6, loss = 0.52574343\n",
      "Iteration 7, loss = 0.51528102\n",
      "Iteration 8, loss = 0.51893097\n",
      "Iteration 9, loss = 0.51955483\n",
      "Iteration 10, loss = 0.50761751\n",
      "Iteration 11, loss = 0.51698476\n",
      "Iteration 12, loss = 0.52101862\n",
      "Iteration 13, loss = 0.50746781\n",
      "Iteration 14, loss = 0.53194617\n",
      "Iteration 15, loss = 0.48510774\n",
      "Iteration 16, loss = 0.49874954\n",
      "Iteration 17, loss = 0.49580564\n",
      "Iteration 18, loss = 0.51103951\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.92158966\n",
      "Iteration 2, loss = 0.70466616\n",
      "Iteration 3, loss = 0.65789723\n",
      "Iteration 4, loss = 0.61573759\n",
      "Iteration 5, loss = 0.57217746\n",
      "Iteration 6, loss = 0.56472052\n",
      "Iteration 7, loss = 0.53196319\n",
      "Iteration 8, loss = 0.54169615\n",
      "Iteration 9, loss = 0.51971847\n",
      "Iteration 10, loss = 0.51742049\n",
      "Iteration 11, loss = 0.52372561\n",
      "Iteration 12, loss = 0.52449914\n",
      "Iteration 13, loss = 0.52149811\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87560144\n",
      "Iteration 2, loss = 0.67859391\n",
      "Iteration 3, loss = 0.62381713\n",
      "Iteration 4, loss = 0.58174145\n",
      "Iteration 5, loss = 0.54506514\n",
      "Iteration 6, loss = 0.51675150\n",
      "Iteration 7, loss = 0.52509619\n",
      "Iteration 8, loss = 0.50352752\n",
      "Iteration 9, loss = 0.50355451\n",
      "Iteration 10, loss = 0.50102841\n",
      "Iteration 11, loss = 0.46796272\n",
      "Iteration 12, loss = 0.50089231\n",
      "Iteration 13, loss = 0.48781069\n",
      "Iteration 14, loss = 0.48363367\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88060940\n",
      "Iteration 2, loss = 0.69793574\n",
      "Iteration 3, loss = 0.63209097\n",
      "Iteration 4, loss = 0.57649427\n",
      "Iteration 5, loss = 0.52569321\n",
      "Iteration 6, loss = 0.51485543\n",
      "Iteration 7, loss = 0.52559178\n",
      "Iteration 8, loss = 0.57058065\n",
      "Iteration 9, loss = 0.54969331\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85925426\n",
      "Iteration 2, loss = 0.62061646\n",
      "Iteration 3, loss = 0.50849441\n",
      "Iteration 4, loss = 0.47057569\n",
      "Iteration 5, loss = 0.43689485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.44949728\n",
      "Iteration 7, loss = 0.44409379\n",
      "Iteration 8, loss = 0.44263502\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76864982\n",
      "Iteration 2, loss = 0.65966466\n",
      "Iteration 3, loss = 0.57660998\n",
      "Iteration 4, loss = 0.49419997\n",
      "Iteration 5, loss = 0.48597116\n",
      "Iteration 6, loss = 0.45893595\n",
      "Iteration 7, loss = 0.48912121\n",
      "Iteration 8, loss = 0.53608508\n",
      "Iteration 9, loss = 0.53221528\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.73752448\n",
      "Iteration 2, loss = 0.66947704\n",
      "Iteration 3, loss = 0.61219735\n",
      "Iteration 4, loss = 0.57591136\n",
      "Iteration 5, loss = 0.53433293\n",
      "Iteration 6, loss = 0.49702019\n",
      "Iteration 7, loss = 0.49905355\n",
      "Iteration 8, loss = 0.50133602\n",
      "Iteration 9, loss = 0.49281601\n",
      "Iteration 10, loss = 0.48559427\n",
      "Iteration 11, loss = 0.46755299\n",
      "Iteration 12, loss = 0.46257216\n",
      "Iteration 13, loss = 0.48033518\n",
      "Iteration 14, loss = 0.46135605\n",
      "Iteration 15, loss = 0.47232062\n",
      "Iteration 16, loss = 0.49293117\n",
      "Iteration 17, loss = 0.54349055\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.75834824\n",
      "Iteration 2, loss = 0.64866913\n",
      "Iteration 3, loss = 0.54062519\n",
      "Iteration 4, loss = 0.49461634\n",
      "Iteration 5, loss = 0.50413410\n",
      "Iteration 6, loss = 0.48472248\n",
      "Iteration 7, loss = 0.49251734\n",
      "Iteration 8, loss = 0.48695953\n",
      "Iteration 9, loss = 0.45717804\n",
      "Iteration 10, loss = 0.48759915\n",
      "Iteration 11, loss = 0.46706605\n",
      "Iteration 12, loss = 0.46462766\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76516197\n",
      "Iteration 2, loss = 0.63661982\n",
      "Iteration 3, loss = 0.54068700\n",
      "Iteration 4, loss = 0.48969050\n",
      "Iteration 5, loss = 0.52090854\n",
      "Iteration 6, loss = 0.50865739\n",
      "Iteration 7, loss = 0.50766422\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.78606887\n",
      "Iteration 2, loss = 0.65592604\n",
      "Iteration 3, loss = 0.58823705\n",
      "Iteration 4, loss = 0.50932670\n",
      "Iteration 5, loss = 0.50341813\n",
      "Iteration 6, loss = 0.47849527\n",
      "Iteration 7, loss = 0.46569736\n",
      "Iteration 8, loss = 0.47086958\n",
      "Iteration 9, loss = 0.49174747\n",
      "Iteration 10, loss = 0.45940301\n",
      "Iteration 11, loss = 0.48254287\n",
      "Iteration 12, loss = 0.50546509\n",
      "Iteration 13, loss = 0.51350199\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80271010\n",
      "Iteration 2, loss = 0.69421328\n",
      "Iteration 3, loss = 0.66170943\n",
      "Iteration 4, loss = 0.60972946\n",
      "Iteration 5, loss = 0.55903384\n",
      "Iteration 6, loss = 0.50720653\n",
      "Iteration 7, loss = 0.49895082\n",
      "Iteration 8, loss = 0.50831368\n",
      "Iteration 9, loss = 0.50363284\n",
      "Iteration 10, loss = 0.53223092\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.80285991\n",
      "Iteration 2, loss = 0.65930803\n",
      "Iteration 3, loss = 0.60395899\n",
      "Iteration 4, loss = 0.52785463\n",
      "Iteration 5, loss = 0.50825700\n",
      "Iteration 6, loss = 0.47798671\n",
      "Iteration 7, loss = 0.47836608\n",
      "Iteration 8, loss = 0.48823165\n",
      "Iteration 9, loss = 0.47939814\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83150431\n",
      "Iteration 2, loss = 0.69266037\n",
      "Iteration 3, loss = 0.66347710\n",
      "Iteration 4, loss = 0.57763313\n",
      "Iteration 5, loss = 0.52060625\n",
      "Iteration 6, loss = 0.50718746\n",
      "Iteration 7, loss = 0.50424886\n",
      "Iteration 8, loss = 0.49314326\n",
      "Iteration 9, loss = 0.50398756\n",
      "Iteration 10, loss = 0.50608292\n",
      "Iteration 11, loss = 0.48860623\n",
      "Iteration 12, loss = 0.48221912\n",
      "Iteration 13, loss = 0.48591981\n",
      "Iteration 14, loss = 0.48360166\n",
      "Iteration 15, loss = 0.52229475\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84730409\n",
      "Iteration 2, loss = 0.69937432\n",
      "Iteration 3, loss = 0.65257949\n",
      "Iteration 4, loss = 0.59536372\n",
      "Iteration 5, loss = 0.54191665\n",
      "Iteration 6, loss = 0.53033270\n",
      "Iteration 7, loss = 0.51335179\n",
      "Iteration 8, loss = 0.50732876\n",
      "Iteration 9, loss = 0.53143805\n",
      "Iteration 10, loss = 0.54978365\n",
      "Iteration 11, loss = 0.52028525\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.81169330\n",
      "Iteration 2, loss = 0.69594320\n",
      "Iteration 3, loss = 0.60916585\n",
      "Iteration 4, loss = 0.52090742\n",
      "Iteration 5, loss = 0.47753434\n",
      "Iteration 6, loss = 0.46085221\n",
      "Iteration 7, loss = 0.46914526\n",
      "Iteration 8, loss = 0.50589662\n",
      "Iteration 9, loss = 0.51917004\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83644577\n",
      "Iteration 2, loss = 0.68081943\n",
      "Iteration 3, loss = 0.61869867\n",
      "Iteration 4, loss = 0.54878102\n",
      "Iteration 5, loss = 0.50255278\n",
      "Iteration 6, loss = 0.47145287\n",
      "Iteration 7, loss = 0.45784011\n",
      "Iteration 8, loss = 0.47539760\n",
      "Iteration 9, loss = 0.47268484\n",
      "Iteration 10, loss = 0.46875381\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83950662\n",
      "Iteration 2, loss = 0.69550447\n",
      "Iteration 3, loss = 0.64039516\n",
      "Iteration 4, loss = 0.57500645\n",
      "Iteration 5, loss = 0.59818849\n",
      "Iteration 6, loss = 0.54843942\n",
      "Iteration 7, loss = 0.50040374\n",
      "Iteration 8, loss = 0.48022447\n",
      "Iteration 9, loss = 0.48608561\n",
      "Iteration 10, loss = 0.51636100\n",
      "Iteration 11, loss = 0.51333362\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85346624\n",
      "Iteration 2, loss = 0.67174625\n",
      "Iteration 3, loss = 0.60693553\n",
      "Iteration 4, loss = 0.55064426\n",
      "Iteration 5, loss = 0.52220282\n",
      "Iteration 6, loss = 0.52484437\n",
      "Iteration 7, loss = 0.50298404\n",
      "Iteration 8, loss = 0.48318017\n",
      "Iteration 9, loss = 0.54419183\n",
      "Iteration 10, loss = 0.55389601\n",
      "Iteration 11, loss = 0.51725234\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.82678162\n",
      "Iteration 2, loss = 0.65781739\n",
      "Iteration 3, loss = 0.57691642\n",
      "Iteration 4, loss = 0.50547174\n",
      "Iteration 5, loss = 0.52763533\n",
      "Iteration 6, loss = 0.52411587\n",
      "Iteration 7, loss = 0.47251964\n",
      "Iteration 8, loss = 0.46508921\n",
      "Iteration 9, loss = 0.48477877\n",
      "Iteration 10, loss = 0.49400131\n",
      "Iteration 11, loss = 0.48983829\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83651366\n",
      "Iteration 2, loss = 0.64797550\n",
      "Iteration 3, loss = 0.58815067\n",
      "Iteration 4, loss = 0.55098307\n",
      "Iteration 5, loss = 0.50315195\n",
      "Iteration 6, loss = 0.49128220\n",
      "Iteration 7, loss = 0.49314537\n",
      "Iteration 8, loss = 0.48839514\n",
      "Iteration 9, loss = 0.53196281\n",
      "Iteration 10, loss = 0.52667112\n",
      "Iteration 11, loss = 0.51840396\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84495204\n",
      "Iteration 2, loss = 0.64834118\n",
      "Iteration 3, loss = 0.59105870\n",
      "Iteration 4, loss = 0.52770555\n",
      "Iteration 5, loss = 0.51895668\n",
      "Iteration 6, loss = 0.51832235\n",
      "Iteration 7, loss = 0.49927814\n",
      "Iteration 8, loss = 0.48366482\n",
      "Iteration 9, loss = 0.50835514\n",
      "Iteration 10, loss = 0.54140149\n",
      "Iteration 11, loss = 0.54176643\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85087627\n",
      "Iteration 2, loss = 0.65818732\n",
      "Iteration 3, loss = 0.61125120\n",
      "Iteration 4, loss = 0.54900675\n",
      "Iteration 5, loss = 0.51708863\n",
      "Iteration 6, loss = 0.50415692\n",
      "Iteration 7, loss = 0.49280212\n",
      "Iteration 8, loss = 0.47261710\n",
      "Iteration 9, loss = 0.47765090\n",
      "Iteration 10, loss = 0.51311289\n",
      "Iteration 11, loss = 0.50495392\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87495328\n",
      "Iteration 2, loss = 0.68609529\n",
      "Iteration 3, loss = 0.63806547\n",
      "Iteration 4, loss = 0.55867528\n",
      "Iteration 5, loss = 0.53877257\n",
      "Iteration 6, loss = 0.51738213\n",
      "Iteration 7, loss = 0.53161766\n",
      "Iteration 8, loss = 0.52531555\n",
      "Iteration 9, loss = 0.50090232\n",
      "Iteration 10, loss = 0.58188933\n",
      "Iteration 11, loss = 0.56233934\n",
      "Iteration 12, loss = 0.53799475\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.85298232\n",
      "Iteration 2, loss = 0.67775410\n",
      "Iteration 3, loss = 0.61712147\n",
      "Iteration 4, loss = 0.55590221\n",
      "Iteration 5, loss = 0.51949815\n",
      "Iteration 6, loss = 0.52991611\n",
      "Iteration 7, loss = 0.52443714\n",
      "Iteration 8, loss = 0.53051350\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.84937015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.69541423\n",
      "Iteration 3, loss = 0.62343597\n",
      "Iteration 4, loss = 0.54839423\n",
      "Iteration 5, loss = 0.49397769\n",
      "Iteration 6, loss = 0.47148464\n",
      "Iteration 7, loss = 0.45892863\n",
      "Iteration 8, loss = 0.43324306\n",
      "Iteration 9, loss = 0.47629523\n",
      "Iteration 10, loss = 0.52286131\n",
      "Iteration 11, loss = 0.51907572\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.92525190\n",
      "Iteration 2, loss = 0.69278564\n",
      "Iteration 3, loss = 0.63328410\n",
      "Iteration 4, loss = 0.55684758\n",
      "Iteration 5, loss = 0.51489829\n",
      "Iteration 6, loss = 0.49706875\n",
      "Iteration 7, loss = 0.52560224\n",
      "Iteration 8, loss = 0.53893483\n",
      "Iteration 9, loss = 0.54676191\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.94182290\n",
      "Iteration 2, loss = 0.70086048\n",
      "Iteration 3, loss = 0.64311991\n",
      "Iteration 4, loss = 0.57980117\n",
      "Iteration 5, loss = 0.52273948\n",
      "Iteration 6, loss = 0.49897879\n",
      "Iteration 7, loss = 0.47651545\n",
      "Iteration 8, loss = 0.48421001\n",
      "Iteration 9, loss = 0.49917307\n",
      "Iteration 10, loss = 0.49480181\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95611629\n",
      "Iteration 2, loss = 0.70433593\n",
      "Iteration 3, loss = 0.67472168\n",
      "Iteration 4, loss = 0.62077175\n",
      "Iteration 5, loss = 0.57576027\n",
      "Iteration 6, loss = 0.53995404\n",
      "Iteration 7, loss = 0.52766194\n",
      "Iteration 8, loss = 0.53078082\n",
      "Iteration 9, loss = 0.50601354\n",
      "Iteration 10, loss = 0.48212396\n",
      "Iteration 11, loss = 0.48563889\n",
      "Iteration 12, loss = 0.50211784\n",
      "Iteration 13, loss = 0.46894613\n",
      "Iteration 14, loss = 0.47263298\n",
      "Iteration 15, loss = 0.47687152\n",
      "Iteration 16, loss = 0.45739979\n",
      "Iteration 17, loss = 0.45265495\n",
      "Iteration 18, loss = 0.45781809\n",
      "Iteration 19, loss = 0.45716724\n",
      "Iteration 20, loss = 0.46057764\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95193721\n",
      "Iteration 2, loss = 0.69247576\n",
      "Iteration 3, loss = 0.65983398\n",
      "Iteration 4, loss = 0.58075312\n",
      "Iteration 5, loss = 0.52848149\n",
      "Iteration 6, loss = 0.48835342\n",
      "Iteration 7, loss = 0.48791193\n",
      "Iteration 8, loss = 0.47198727\n",
      "Iteration 9, loss = 0.47698082\n",
      "Iteration 10, loss = 0.46476072\n",
      "Iteration 11, loss = 0.48044322\n",
      "Iteration 12, loss = 0.46853734\n",
      "Iteration 13, loss = 0.50866860\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.01988883\n",
      "Iteration 2, loss = 0.71244535\n",
      "Iteration 3, loss = 0.71057784\n",
      "Iteration 4, loss = 0.67101952\n",
      "Iteration 5, loss = 0.62451799\n",
      "Iteration 6, loss = 0.54655058\n",
      "Iteration 7, loss = 0.52266429\n",
      "Iteration 8, loss = 0.52857269\n",
      "Iteration 9, loss = 0.52921591\n",
      "Iteration 10, loss = 0.48281550\n",
      "Iteration 11, loss = 0.47305879\n",
      "Iteration 12, loss = 0.47209031\n",
      "Iteration 13, loss = 0.50526066\n",
      "Iteration 14, loss = 0.52170616\n",
      "Iteration 15, loss = 0.46950681\n",
      "Iteration 16, loss = 0.47102656\n",
      "Iteration 17, loss = 0.44595891\n",
      "Iteration 18, loss = 0.46660250\n",
      "Iteration 19, loss = 0.44349031\n",
      "Iteration 20, loss = 0.45226295\n",
      "Iteration 21, loss = 0.49369995\n",
      "Iteration 22, loss = 0.50324189\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.88711815\n",
      "Iteration 2, loss = 0.68802016\n",
      "Iteration 3, loss = 0.64178552\n",
      "Iteration 4, loss = 0.56901884\n",
      "Iteration 5, loss = 0.53264211\n",
      "Iteration 6, loss = 0.51281822\n",
      "Iteration 7, loss = 0.52535680\n",
      "Iteration 8, loss = 0.49720724\n",
      "Iteration 9, loss = 0.47993538\n",
      "Iteration 10, loss = 0.48565583\n",
      "Iteration 11, loss = 0.49609673\n",
      "Iteration 12, loss = 0.52897530\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86323858\n",
      "Iteration 2, loss = 0.65151929\n",
      "Iteration 3, loss = 0.57331742\n",
      "Iteration 4, loss = 0.53698789\n",
      "Iteration 5, loss = 0.50471854\n",
      "Iteration 6, loss = 0.49426498\n",
      "Iteration 7, loss = 0.49182916\n",
      "Iteration 8, loss = 0.51009201\n",
      "Iteration 9, loss = 0.49187896\n",
      "Iteration 10, loss = 0.47992992\n",
      "Iteration 11, loss = 0.48370306\n",
      "Iteration 12, loss = 0.52263620\n",
      "Iteration 13, loss = 0.53784835\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.87199549\n",
      "Iteration 2, loss = 0.68954032\n",
      "Iteration 3, loss = 0.65279034\n",
      "Iteration 4, loss = 0.60801867\n",
      "Iteration 5, loss = 0.53694055\n",
      "Iteration 6, loss = 0.49221577\n",
      "Iteration 7, loss = 0.49296316\n",
      "Iteration 8, loss = 0.49856730\n",
      "Iteration 9, loss = 0.47543412\n",
      "Iteration 10, loss = 0.46654008\n",
      "Iteration 11, loss = 0.49148354\n",
      "Iteration 12, loss = 0.47458867\n",
      "Iteration 13, loss = 0.47892993\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.99215510\n",
      "Iteration 2, loss = 0.73573182\n",
      "Iteration 3, loss = 0.68651560\n",
      "Iteration 4, loss = 0.62574650\n",
      "Iteration 5, loss = 0.56541964\n",
      "Iteration 6, loss = 0.56422668\n",
      "Iteration 7, loss = 0.55547822\n",
      "Iteration 8, loss = 0.54961819\n",
      "Iteration 9, loss = 0.52441194\n",
      "Iteration 10, loss = 0.52580518\n",
      "Iteration 11, loss = 0.54435317\n",
      "Iteration 12, loss = 0.54571192\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.86455243\n",
      "Iteration 2, loss = 0.64487595\n",
      "Iteration 3, loss = 0.55709276\n",
      "Iteration 4, loss = 0.51040173\n",
      "Iteration 5, loss = 0.46002858\n",
      "Iteration 6, loss = 0.44407002\n",
      "Iteration 7, loss = 0.45992765\n",
      "Iteration 8, loss = 0.45109672\n",
      "Iteration 9, loss = 0.43628821\n",
      "Iteration 10, loss = 0.41240906\n",
      "Iteration 11, loss = 0.42432026\n",
      "Iteration 12, loss = 0.48536399\n",
      "Iteration 13, loss = 0.47862929\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.94498627\n",
      "Iteration 2, loss = 0.69888600\n",
      "Iteration 3, loss = 0.64963173\n",
      "Iteration 4, loss = 0.60447249\n",
      "Iteration 5, loss = 0.58534024\n",
      "Iteration 6, loss = 0.52439408\n",
      "Iteration 7, loss = 0.48704331\n",
      "Iteration 8, loss = 0.50470558\n",
      "Iteration 9, loss = 0.52935372\n",
      "Iteration 10, loss = 0.52896830\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.93495711\n",
      "Iteration 2, loss = 0.69799393\n",
      "Iteration 3, loss = 0.64250794\n",
      "Iteration 4, loss = 0.58065381\n",
      "Iteration 5, loss = 0.52774684\n",
      "Iteration 6, loss = 0.53576327\n",
      "Iteration 7, loss = 0.57588886\n",
      "Iteration 8, loss = 0.55330809\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98048601\n",
      "Iteration 2, loss = 0.69703299\n",
      "Iteration 3, loss = 0.63439189\n",
      "Iteration 4, loss = 0.55991867\n",
      "Iteration 5, loss = 0.52259199\n",
      "Iteration 6, loss = 0.51390076\n",
      "Iteration 7, loss = 0.52693394\n",
      "Iteration 8, loss = 0.52307678\n",
      "Iteration 9, loss = 0.48065460\n",
      "Iteration 10, loss = 0.49753268\n",
      "Iteration 11, loss = 0.47570255\n",
      "Iteration 12, loss = 0.46528230\n",
      "Iteration 13, loss = 0.47955317\n",
      "Iteration 14, loss = 0.50417710\n",
      "Iteration 15, loss = 0.50337223\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95999509\n",
      "Iteration 2, loss = 0.71656763\n",
      "Iteration 3, loss = 0.70994933\n",
      "Iteration 4, loss = 0.63505859\n",
      "Iteration 5, loss = 0.59411927\n",
      "Iteration 6, loss = 0.56514011\n",
      "Iteration 7, loss = 0.54173195\n",
      "Iteration 8, loss = 0.52087401\n",
      "Iteration 9, loss = 0.51970985\n",
      "Iteration 10, loss = 0.51126538\n",
      "Iteration 11, loss = 0.48511356\n",
      "Iteration 12, loss = 0.46551161\n",
      "Iteration 13, loss = 0.47076172\n",
      "Iteration 14, loss = 0.45599684\n",
      "Iteration 15, loss = 0.46370504\n",
      "Iteration 16, loss = 0.47914434\n",
      "Iteration 17, loss = 0.46244294\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.94205157\n",
      "Iteration 2, loss = 0.66277935\n",
      "Iteration 3, loss = 0.59627741\n",
      "Iteration 4, loss = 0.54075275\n",
      "Iteration 5, loss = 0.50271221\n",
      "Iteration 6, loss = 0.50747455\n",
      "Iteration 7, loss = 0.52360850\n",
      "Iteration 8, loss = 0.47709004\n",
      "Iteration 9, loss = 0.52771838\n",
      "Iteration 10, loss = 0.52157923\n",
      "Iteration 11, loss = 0.49812522\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.99564829\n",
      "Iteration 2, loss = 0.73125098\n",
      "Iteration 3, loss = 0.68892387\n",
      "Iteration 4, loss = 0.64652882\n",
      "Iteration 5, loss = 0.59869137\n",
      "Iteration 6, loss = 0.52851448\n",
      "Iteration 7, loss = 0.50845519\n",
      "Iteration 8, loss = 0.53123595\n",
      "Iteration 9, loss = 0.50682834\n",
      "Iteration 10, loss = 0.48878044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 0.49669152\n",
      "Iteration 12, loss = 0.48375993\n",
      "Iteration 13, loss = 0.48052626\n",
      "Iteration 14, loss = 0.50710353\n",
      "Iteration 15, loss = 0.50719112\n",
      "Iteration 16, loss = 0.50129459\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.99942107\n",
      "Iteration 2, loss = 0.71302513\n",
      "Iteration 3, loss = 0.67077514\n",
      "Iteration 4, loss = 0.60075415\n",
      "Iteration 5, loss = 0.56239951\n",
      "Iteration 6, loss = 0.57436477\n",
      "Iteration 7, loss = 0.54244898\n",
      "Iteration 8, loss = 0.55384087\n",
      "Iteration 9, loss = 0.50354904\n",
      "Iteration 10, loss = 0.48785789\n",
      "Iteration 11, loss = 0.49494332\n",
      "Iteration 12, loss = 0.49294947\n",
      "Iteration 13, loss = 0.54206939\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.01422479\n",
      "Iteration 2, loss = 0.72219088\n",
      "Iteration 3, loss = 0.69009302\n",
      "Iteration 4, loss = 0.64737796\n",
      "Iteration 5, loss = 0.62620616\n",
      "Iteration 6, loss = 0.64783916\n",
      "Iteration 7, loss = 0.59145785\n",
      "Iteration 8, loss = 0.55499671\n",
      "Iteration 9, loss = 0.57424254\n",
      "Iteration 10, loss = 0.55364184\n",
      "Iteration 11, loss = 0.52883572\n",
      "Iteration 12, loss = 0.53589955\n",
      "Iteration 13, loss = 0.54763154\n",
      "Iteration 14, loss = 0.54483974\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.06606639\n",
      "Iteration 2, loss = 0.73801928\n",
      "Iteration 3, loss = 0.71184934\n",
      "Iteration 4, loss = 0.66541763\n",
      "Iteration 5, loss = 0.63804198\n",
      "Iteration 6, loss = 0.58547872\n",
      "Iteration 7, loss = 0.56855207\n",
      "Iteration 8, loss = 0.53929293\n",
      "Iteration 9, loss = 0.52492475\n",
      "Iteration 10, loss = 0.51659817\n",
      "Iteration 11, loss = 0.50407177\n",
      "Iteration 12, loss = 0.52280943\n",
      "Iteration 13, loss = 0.52069126\n",
      "Iteration 14, loss = 0.54745831\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.04923109\n",
      "Iteration 2, loss = 0.78120661\n",
      "Iteration 3, loss = 0.67505335\n",
      "Iteration 4, loss = 0.61263286\n",
      "Iteration 5, loss = 0.54908153\n",
      "Iteration 6, loss = 0.48956010\n",
      "Iteration 7, loss = 0.46638930\n",
      "Iteration 8, loss = 0.45092979\n",
      "Iteration 9, loss = 0.44773394\n",
      "Iteration 10, loss = 0.46287106\n",
      "Iteration 11, loss = 0.46611859\n",
      "Iteration 12, loss = 0.44762684\n",
      "Iteration 13, loss = 0.42887086\n",
      "Iteration 14, loss = 0.47593348\n",
      "Iteration 15, loss = 0.46208009\n",
      "Iteration 16, loss = 0.46824764\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95966961\n",
      "Iteration 2, loss = 0.68564651\n",
      "Iteration 3, loss = 0.61505813\n",
      "Iteration 4, loss = 0.55112925\n",
      "Iteration 5, loss = 0.54993904\n",
      "Iteration 6, loss = 0.50457666\n",
      "Iteration 7, loss = 0.47997503\n",
      "Iteration 8, loss = 0.46833449\n",
      "Iteration 9, loss = 0.45902566\n",
      "Iteration 10, loss = 0.45540014\n",
      "Iteration 11, loss = 0.48399621\n",
      "Iteration 12, loss = 0.52641513\n",
      "Iteration 13, loss = 0.52264636\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.93715926\n",
      "Iteration 2, loss = 0.70865359\n",
      "Iteration 3, loss = 0.65489193\n",
      "Iteration 4, loss = 0.59008964\n",
      "Iteration 5, loss = 0.55899781\n",
      "Iteration 6, loss = 0.52481214\n",
      "Iteration 7, loss = 0.52042192\n",
      "Iteration 8, loss = 0.51259448\n",
      "Iteration 9, loss = 0.51158755\n",
      "Iteration 10, loss = 0.49239926\n",
      "Iteration 11, loss = 0.50787172\n",
      "Iteration 12, loss = 0.49325406\n",
      "Iteration 13, loss = 0.48259183\n",
      "Iteration 14, loss = 0.48928814\n",
      "Iteration 15, loss = 0.50184888\n",
      "Iteration 16, loss = 0.49777965\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.93058336\n",
      "Iteration 2, loss = 0.70647263\n",
      "Iteration 3, loss = 0.64834196\n",
      "Iteration 4, loss = 0.61364985\n",
      "Iteration 5, loss = 0.60785700\n",
      "Iteration 6, loss = 0.56138427\n",
      "Iteration 7, loss = 0.53201898\n",
      "Iteration 8, loss = 0.50613558\n",
      "Iteration 9, loss = 0.52190888\n",
      "Iteration 10, loss = 0.52309930\n",
      "Iteration 11, loss = 0.51298400\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.97331792\n",
      "Iteration 2, loss = 0.72933582\n",
      "Iteration 3, loss = 0.65315362\n",
      "Iteration 4, loss = 0.61784079\n",
      "Iteration 5, loss = 0.58401167\n",
      "Iteration 6, loss = 0.54356786\n",
      "Iteration 7, loss = 0.52843363\n",
      "Iteration 8, loss = 0.50283352\n",
      "Iteration 9, loss = 0.50044013\n",
      "Iteration 10, loss = 0.56698704\n",
      "Iteration 11, loss = 0.56349296\n",
      "Iteration 12, loss = 0.50918466\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95458203\n",
      "Iteration 2, loss = 0.72559671\n",
      "Iteration 3, loss = 0.66471003\n",
      "Iteration 4, loss = 0.56996060\n",
      "Iteration 5, loss = 0.52122718\n",
      "Iteration 6, loss = 0.51574013\n",
      "Iteration 7, loss = 0.50192055\n",
      "Iteration 8, loss = 0.49522554\n",
      "Iteration 9, loss = 0.49863756\n",
      "Iteration 10, loss = 0.50486483\n",
      "Iteration 11, loss = 0.50261123\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90574299\n",
      "Iteration 2, loss = 0.74097158\n",
      "Iteration 3, loss = 0.69603817\n",
      "Iteration 4, loss = 0.64893896\n",
      "Iteration 5, loss = 0.60459625\n",
      "Iteration 6, loss = 0.55824778\n",
      "Iteration 7, loss = 0.53705927\n",
      "Iteration 8, loss = 0.51947833\n",
      "Iteration 9, loss = 0.52522701\n",
      "Iteration 10, loss = 0.50676947\n",
      "Iteration 11, loss = 0.49636302\n",
      "Iteration 12, loss = 0.50118872\n",
      "Iteration 13, loss = 0.49158406\n",
      "Iteration 14, loss = 0.49982216\n",
      "Iteration 15, loss = 0.50437738\n",
      "Iteration 16, loss = 0.49891412\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.92215742\n",
      "Iteration 2, loss = 0.71703549\n",
      "Iteration 3, loss = 0.65215963\n",
      "Iteration 4, loss = 0.60514265\n",
      "Iteration 5, loss = 0.56705738\n",
      "Iteration 6, loss = 0.54067636\n",
      "Iteration 7, loss = 0.55151958\n",
      "Iteration 8, loss = 0.51864555\n",
      "Iteration 9, loss = 0.50405843\n",
      "Iteration 10, loss = 0.51323453\n",
      "Iteration 11, loss = 0.50654114\n",
      "Iteration 12, loss = 0.51397949\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95834982\n",
      "Iteration 2, loss = 0.73288141\n",
      "Iteration 3, loss = 0.69864704\n",
      "Iteration 4, loss = 0.66489208\n",
      "Iteration 5, loss = 0.63612004\n",
      "Iteration 6, loss = 0.59053281\n",
      "Iteration 7, loss = 0.60018998\n",
      "Iteration 8, loss = 0.56681228\n",
      "Iteration 9, loss = 0.58432558\n",
      "Iteration 10, loss = 0.57246293\n",
      "Iteration 11, loss = 0.48986947\n",
      "Iteration 12, loss = 0.48383277\n",
      "Iteration 13, loss = 0.49209555\n",
      "Iteration 14, loss = 0.52266756\n",
      "Iteration 15, loss = 0.52770923\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95745593\n",
      "Iteration 2, loss = 0.71530287\n",
      "Iteration 3, loss = 0.66416312\n",
      "Iteration 4, loss = 0.61670919\n",
      "Iteration 5, loss = 0.58291699\n",
      "Iteration 6, loss = 0.54463242\n",
      "Iteration 7, loss = 0.54793887\n",
      "Iteration 8, loss = 0.50627402\n",
      "Iteration 9, loss = 0.51553050\n",
      "Iteration 10, loss = 0.51823888\n",
      "Iteration 11, loss = 0.51967643\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91486565\n",
      "Iteration 2, loss = 0.70585693\n",
      "Iteration 3, loss = 0.65045596\n",
      "Iteration 4, loss = 0.56634661\n",
      "Iteration 5, loss = 0.48808385\n",
      "Iteration 6, loss = 0.46826644\n",
      "Iteration 7, loss = 0.46280680\n",
      "Iteration 8, loss = 0.46294194\n",
      "Iteration 9, loss = 0.46533018\n",
      "Iteration 10, loss = 0.43819670\n",
      "Iteration 11, loss = 0.43437222\n",
      "Iteration 12, loss = 0.42041020\n",
      "Iteration 13, loss = 0.44178981\n",
      "Iteration 14, loss = 0.42993006\n",
      "Iteration 15, loss = 0.43445711\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.02789860\n",
      "Iteration 2, loss = 0.71140474\n",
      "Iteration 3, loss = 0.65815693\n",
      "Iteration 4, loss = 0.61022403\n",
      "Iteration 5, loss = 0.56249662\n",
      "Iteration 6, loss = 0.53661028\n",
      "Iteration 7, loss = 0.50592056\n",
      "Iteration 8, loss = 0.50136812\n",
      "Iteration 9, loss = 0.48220050\n",
      "Iteration 10, loss = 0.47377177\n",
      "Iteration 11, loss = 0.51093442\n",
      "Iteration 12, loss = 0.55933859\n",
      "Iteration 13, loss = 0.49364117\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.01368827\n",
      "Iteration 2, loss = 0.74167807\n",
      "Iteration 3, loss = 0.70845387\n",
      "Iteration 4, loss = 0.66060724\n",
      "Iteration 5, loss = 0.59970182\n",
      "Iteration 6, loss = 0.56091041\n",
      "Iteration 7, loss = 0.52223458\n",
      "Iteration 8, loss = 0.52973073\n",
      "Iteration 9, loss = 0.50928462\n",
      "Iteration 10, loss = 0.48503949\n",
      "Iteration 11, loss = 0.49189108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.50448576\n",
      "Iteration 13, loss = 0.50331258\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.06175015\n",
      "Iteration 2, loss = 0.78597423\n",
      "Iteration 3, loss = 0.72446507\n",
      "Iteration 4, loss = 0.65786785\n",
      "Iteration 5, loss = 0.57953034\n",
      "Iteration 6, loss = 0.54734552\n",
      "Iteration 7, loss = 0.50708699\n",
      "Iteration 8, loss = 0.51680597\n",
      "Iteration 9, loss = 0.52452036\n",
      "Iteration 10, loss = 0.50449708\n",
      "Iteration 11, loss = 0.49429607\n",
      "Iteration 12, loss = 0.51193237\n",
      "Iteration 13, loss = 0.50973859\n",
      "Iteration 14, loss = 0.50299500\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.99425777\n",
      "Iteration 2, loss = 0.74651583\n",
      "Iteration 3, loss = 0.69658147\n",
      "Iteration 4, loss = 0.64758128\n",
      "Iteration 5, loss = 0.57290378\n",
      "Iteration 6, loss = 0.53577314\n",
      "Iteration 7, loss = 0.51278619\n",
      "Iteration 8, loss = 0.49282060\n",
      "Iteration 9, loss = 0.50712241\n",
      "Iteration 10, loss = 0.52311418\n",
      "Iteration 11, loss = 0.51200740\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98536525\n",
      "Iteration 2, loss = 0.75525685\n",
      "Iteration 3, loss = 0.72093622\n",
      "Iteration 4, loss = 0.70058963\n",
      "Iteration 5, loss = 0.65393396\n",
      "Iteration 6, loss = 0.63257285\n",
      "Iteration 7, loss = 0.59031821\n",
      "Iteration 8, loss = 0.54991590\n",
      "Iteration 9, loss = 0.52715258\n",
      "Iteration 10, loss = 0.49699351\n",
      "Iteration 11, loss = 0.50241815\n",
      "Iteration 12, loss = 0.49977880\n",
      "Iteration 13, loss = 0.48857894\n",
      "Iteration 14, loss = 0.49585238\n",
      "Iteration 15, loss = 0.49164747\n",
      "Iteration 16, loss = 0.45958916\n",
      "Iteration 17, loss = 0.49084732\n",
      "Iteration 18, loss = 0.49043850\n",
      "Iteration 19, loss = 0.49608766\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.98382030\n",
      "Iteration 2, loss = 0.73430837\n",
      "Iteration 3, loss = 0.68449725\n",
      "Iteration 4, loss = 0.63659642\n",
      "Iteration 5, loss = 0.59563731\n",
      "Iteration 6, loss = 0.57377760\n",
      "Iteration 7, loss = 0.54290392\n",
      "Iteration 8, loss = 0.52546903\n",
      "Iteration 9, loss = 0.53873277\n",
      "Iteration 10, loss = 0.53742076\n",
      "Iteration 11, loss = 0.52060100\n",
      "Iteration 12, loss = 0.51704970\n",
      "Iteration 13, loss = 0.53987415\n",
      "Iteration 14, loss = 0.56605234\n",
      "Iteration 15, loss = 0.51905064\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.94712200\n",
      "Iteration 2, loss = 0.73340361\n",
      "Iteration 3, loss = 0.70933892\n",
      "Iteration 4, loss = 0.65478547\n",
      "Iteration 5, loss = 0.60278270\n",
      "Iteration 6, loss = 0.57131061\n",
      "Iteration 7, loss = 0.57195793\n",
      "Iteration 8, loss = 0.52576696\n",
      "Iteration 9, loss = 0.50356940\n",
      "Iteration 10, loss = 0.48367431\n",
      "Iteration 11, loss = 0.50079549\n",
      "Iteration 12, loss = 0.48380303\n",
      "Iteration 13, loss = 0.49444208\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.92831467\n",
      "Iteration 2, loss = 0.72697777\n",
      "Iteration 3, loss = 0.70176888\n",
      "Iteration 4, loss = 0.68208362\n",
      "Iteration 5, loss = 0.65478827\n",
      "Iteration 6, loss = 0.58383125\n",
      "Iteration 7, loss = 0.54455381\n",
      "Iteration 8, loss = 0.54606901\n",
      "Iteration 9, loss = 0.50980901\n",
      "Iteration 10, loss = 0.49702001\n",
      "Iteration 11, loss = 0.48330472\n",
      "Iteration 12, loss = 0.48371604\n",
      "Iteration 13, loss = 0.50247982\n",
      "Iteration 14, loss = 0.48380422\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.97887437\n",
      "Iteration 2, loss = 0.71993971\n",
      "Iteration 3, loss = 0.67993873\n",
      "Iteration 4, loss = 0.61906470\n",
      "Iteration 5, loss = 0.58263371\n",
      "Iteration 6, loss = 0.55459408\n",
      "Iteration 7, loss = 0.53052564\n",
      "Iteration 8, loss = 0.51985989\n",
      "Iteration 9, loss = 0.51352871\n",
      "Iteration 10, loss = 0.50484236\n",
      "Iteration 11, loss = 0.51788602\n",
      "Iteration 12, loss = 0.51161542\n",
      "Iteration 13, loss = 0.52371080\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.94826143\n",
      "Iteration 2, loss = 0.72885003\n",
      "Iteration 3, loss = 0.66405785\n",
      "Iteration 4, loss = 0.59591889\n",
      "Iteration 5, loss = 0.52768518\n",
      "Iteration 6, loss = 0.49984219\n",
      "Iteration 7, loss = 0.48333831\n",
      "Iteration 8, loss = 0.46111183\n",
      "Iteration 9, loss = 0.44361843\n",
      "Iteration 10, loss = 0.43720753\n",
      "Iteration 11, loss = 0.44779341\n",
      "Iteration 12, loss = 0.45146879\n",
      "Iteration 13, loss = 0.45927853\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.93290589\n",
      "Iteration 2, loss = 0.71494147\n",
      "Iteration 3, loss = 0.67871730\n",
      "Iteration 4, loss = 0.60841479\n",
      "Iteration 5, loss = 0.51788502\n",
      "Iteration 6, loss = 0.48889897\n",
      "Iteration 7, loss = 0.46909521\n",
      "Iteration 8, loss = 0.50365805\n",
      "Iteration 9, loss = 0.51021864\n",
      "Iteration 10, loss = 0.50364180\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.96449970\n",
      "Iteration 2, loss = 0.71019714\n",
      "Iteration 3, loss = 0.66060624\n",
      "Iteration 4, loss = 0.61725417\n",
      "Iteration 5, loss = 0.58093795\n",
      "Iteration 6, loss = 0.53434379\n",
      "Iteration 7, loss = 0.50873636\n",
      "Iteration 8, loss = 0.49954406\n",
      "Iteration 9, loss = 0.49643765\n",
      "Iteration 10, loss = 0.48539473\n",
      "Iteration 11, loss = 0.47802720\n",
      "Iteration 12, loss = 0.48214597\n",
      "Iteration 13, loss = 0.47093479\n",
      "Iteration 14, loss = 0.48608449\n",
      "Iteration 15, loss = 0.47451774\n",
      "Iteration 16, loss = 0.49331343\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.94058190\n",
      "Iteration 2, loss = 0.70806871\n",
      "Iteration 3, loss = 0.65825825\n",
      "Iteration 4, loss = 0.58431130\n",
      "Iteration 5, loss = 0.52281991\n",
      "Iteration 6, loss = 0.50536306\n",
      "Iteration 7, loss = 0.53524088\n",
      "Iteration 8, loss = 0.50927053\n",
      "Iteration 9, loss = 0.48782178\n",
      "Iteration 10, loss = 0.49724027\n",
      "Iteration 11, loss = 0.48787945\n",
      "Iteration 12, loss = 0.48777048\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.90423532\n",
      "Iteration 2, loss = 0.71420507\n",
      "Iteration 3, loss = 0.67817734\n",
      "Iteration 4, loss = 0.64911494\n",
      "Iteration 5, loss = 0.56457730\n",
      "Iteration 6, loss = 0.51355832\n",
      "Iteration 7, loss = 0.49319978\n",
      "Iteration 8, loss = 0.51597523\n",
      "Iteration 9, loss = 0.50851367\n",
      "Iteration 10, loss = 0.49468963\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.91010738\n",
      "Iteration 2, loss = 0.73058337\n",
      "Iteration 3, loss = 0.69473773\n",
      "Iteration 4, loss = 0.64821565\n",
      "Iteration 5, loss = 0.59865761\n",
      "Iteration 6, loss = 0.55094491\n",
      "Iteration 7, loss = 0.52478320\n",
      "Iteration 8, loss = 0.57426302\n",
      "Iteration 9, loss = 0.51529311\n",
      "Iteration 10, loss = 0.49472783\n",
      "Iteration 11, loss = 0.47260538\n",
      "Iteration 12, loss = 0.50938950\n",
      "Iteration 13, loss = 0.50296796\n",
      "Iteration 14, loss = 0.54595997\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.92828083\n",
      "Iteration 2, loss = 0.74213308\n",
      "Iteration 3, loss = 0.69607041\n",
      "Iteration 4, loss = 0.62477404\n",
      "Iteration 5, loss = 0.55899406\n",
      "Iteration 6, loss = 0.52443252\n",
      "Iteration 7, loss = 0.51893109\n",
      "Iteration 8, loss = 0.52020589\n",
      "Iteration 9, loss = 0.53219168\n",
      "Iteration 10, loss = 0.52720206\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.96762674\n",
      "Iteration 2, loss = 0.75630795\n",
      "Iteration 3, loss = 0.68795162\n",
      "Iteration 4, loss = 0.64749343\n",
      "Iteration 5, loss = 0.59054375\n",
      "Iteration 6, loss = 0.57557127\n",
      "Iteration 7, loss = 0.55484904\n",
      "Iteration 8, loss = 0.53233782\n",
      "Iteration 9, loss = 0.53473076\n",
      "Iteration 10, loss = 0.52550123\n",
      "Iteration 11, loss = 0.49919246\n",
      "Iteration 12, loss = 0.49787258\n",
      "Iteration 13, loss = 0.51320163\n",
      "Iteration 14, loss = 0.49889400\n",
      "Iteration 15, loss = 0.51935028\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95558219\n",
      "Iteration 2, loss = 0.74215008\n",
      "Iteration 3, loss = 0.67543552\n",
      "Iteration 4, loss = 0.61040200\n",
      "Iteration 5, loss = 0.61264317\n",
      "Iteration 6, loss = 0.56693350\n",
      "Iteration 7, loss = 0.52539129\n",
      "Iteration 8, loss = 0.49889065\n",
      "Iteration 9, loss = 0.48308136\n",
      "Iteration 10, loss = 0.47949552\n",
      "Iteration 11, loss = 0.48033926\n",
      "Iteration 12, loss = 0.48941606\n",
      "Iteration 13, loss = 0.50127721\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.95905756\n",
      "Iteration 2, loss = 0.72369227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.64333026\n",
      "Iteration 4, loss = 0.60487303\n",
      "Iteration 5, loss = 0.56105780\n",
      "Iteration 6, loss = 0.51601435\n",
      "Iteration 7, loss = 0.49655199\n",
      "Iteration 8, loss = 0.49726909\n",
      "Iteration 9, loss = 0.49850349\n",
      "Iteration 10, loss = 0.49668267\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.89293801\n",
      "Iteration 2, loss = 0.69756782\n",
      "Iteration 3, loss = 0.61607776\n",
      "Iteration 4, loss = 0.53245399\n",
      "Iteration 5, loss = 0.46814829\n",
      "Iteration 6, loss = 0.45598958\n",
      "Iteration 7, loss = 0.43607409\n",
      "Iteration 8, loss = 0.43450925\n",
      "Iteration 9, loss = 0.44992526\n",
      "Iteration 10, loss = 0.44672172\n",
      "Iteration 11, loss = 0.43973079\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.76657541\n",
      "Iteration 2, loss = 0.65424751\n",
      "Iteration 3, loss = 0.56419653\n",
      "Iteration 4, loss = 0.50156779\n",
      "Iteration 5, loss = 0.48487999\n",
      "Iteration 6, loss = 0.48827569\n",
      "Iteration 7, loss = 0.50357082\n",
      "Iteration 8, loss = 0.48091201\n",
      "Iteration 9, loss = 0.45510033\n",
      "Iteration 10, loss = 0.44873335\n",
      "Iteration 11, loss = 0.46302053\n",
      "Iteration 12, loss = 0.44794955\n",
      "Iteration 13, loss = 0.46525341\n",
      "Iteration 14, loss = 0.46383727\n",
      "Iteration 15, loss = 0.45675468\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "       learning_rate_init=0.02, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'hidden_layer_sizes': [(5,), (10,), (15,), (20,), (25,), (30,), (35,), (40,), (45,), (50,), (55,), (60,), (65,), (70,), (75,), (80,), (85,), (90,), (95,), (100,), (105,), (110,), (115,), (120,), (125,), (130,), (135,), (140,), (145,), (150,), (155,), (160,), (165,), (170,), (175,), (180,), (185,), (190,), (195,), (200,), (205,), (210,), (215,), (220,), (225,), (230,), (235,), (240,), (245,)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "neuron=[(i,)for i in range(5,250,5)]\n",
    "param_grid = dict(hidden_layer_sizes = neuron)\n",
    "\n",
    "grid_ann=MLPClassifier(activation='logistic', solver='adam', \n",
    "                                         alpha=1, random_state=1, \n",
    "                                           learning_rate_init = 0.02)\n",
    "grid=GridSearchCV(ANN, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8396048918156162\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (120,)}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_olivetti_faces \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f0cbc3d7b8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image=img.imread(\"./Face Data/120.jpg\")\n",
    "plt.imshow(image,cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 4096)\n"
     ]
    }
   ],
   "source": [
    "image_csv=pd.read_csv(\"./Face Data/label.csv\")\n",
    "face_d=fetch_olivetti_faces()\n",
    "face=face_d.data\n",
    "print(face.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.49990347 -0.35118142 -0.3029615  ... -0.8982754  -0.8315195\n",
      "  -0.85045695]\n",
      " [ 0.30149916  0.19463976  0.18568613 ... -0.8982754  -0.87658525\n",
      "  -0.8733619 ]\n",
      " [-0.4541091  -0.17651856  0.07945846 ... -0.9643534  -0.8991181\n",
      "  -0.8733619 ]\n",
      " ...\n",
      " [ 0.5533685   0.5221326   0.67433375 ... -0.76611936 -0.8991181\n",
      "  -0.66721827]\n",
      " [-1.0265394  -1.1371639  -1.3227477  ...  1.3483768   1.5118996\n",
      "   1.6232663 ]\n",
      " [ 0.64495724  0.15097412 -1.0040644  ...  0.20302469  0.22752574\n",
      "   0.40930957]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "prepro_face=preprocessing.scale(face)\n",
    "print(prepro_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4096) (300, 1) (100, 4096) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(face,image_csv,test_size=0.25,random_state=5)\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "X_train_new = pca. fit_transform(X_train)\n",
    "X_test_new = pca. transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0005, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(C=1, kernel='rbf', gamma=0.0005, random_state=1)\n",
    "svc.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 13 13 16 11 16 36 16 11 11 13 13 13 13 13 16 11 13 16 11 13 11 16\n",
      " 13 13 13 11 13 13 13 16 11 16 11 13 11 11 36 13 11 13 11 13 16 13 36 16\n",
      " 13 11 11 13 13 16 16 13 13 36 11 13 13 11 13 13 11 11 13 13 13 11 11 13\n",
      " 13 11 13 13 16 13 11 13 13 11 11 13 13 13 11 13 13 11 11 13 16 13 36 13\n",
      " 13 13 11 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_predict = svc.predict(X_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized_pca = pca.fit_transform(prepro_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Abhilash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.1, 1, 10, 100, 1e3, 5e3, 1e4, 5e4, 1e5]\n",
    "gammas = [0.0005]\n",
    "svc = svm.SVC(C=Cs, kernel='rbf', gamma=gammas, random_state=1)\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "grid = GridSearchCV(estimator=svc, param_grid=param_grid, cv=10, scoring='accuracy')\n",
    "grid_result = grid.fit(X_normalized_pca, image_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0425 {'C': 0.1, 'gamma': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_score_, grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
